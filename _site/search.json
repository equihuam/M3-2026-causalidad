[
  {
    "objectID": "presentaciones.html",
    "href": "presentaciones.html",
    "title": "M3-Presentaciones",
    "section": "",
    "text": "Biodiversidad\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInfraestructura de Experimentación\n\n\nalgunos ejemplos\n\n\n\npresentación\n\n\n\n\n\n\n\n\n\n6 feb 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nModelo Estadístico Lineal\n\n\nmodelación y prueba de hipótesis\n\n\n\npresentación\n\n\n\n\n\n\n\n\n\n28 ene 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducción a Diagramas Causales\n\n\n\n\n\n\npresentación\n\n\n\n\n\n\n\n\n\n28 ene 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nContraste de epistemologías\n\n\nDiseño de estudios y experimentos\n\n\n\npresentación\n\n\n\n\n\n\n\n\n\n28 ene 2026\n\n\nMiguel Equihua\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "presentaciones/2026-01-28-modelo-lineal/index.html#el-modelo-estadístico-lineal-general",
    "href": "presentaciones/2026-01-28-modelo-lineal/index.html#el-modelo-estadístico-lineal-general",
    "title": "Modelo Estadístico Lineal",
    "section": "El modelo estadístico lineal general",
    "text": "El modelo estadístico lineal general\nEstructura general"
  },
  {
    "objectID": "presentaciones/2026-01-28-modelo-lineal/index.html#ejemplo-de-modelo-lineal",
    "href": "presentaciones/2026-01-28-modelo-lineal/index.html#ejemplo-de-modelo-lineal",
    "title": "Modelo Estadístico Lineal",
    "section": "Ejemplo de modelo lineal",
    "text": "Ejemplo de modelo lineal\n\nGanancia de peso en un grupo de orugas que declina conforme se incrementa el contenido de taninos en la dieta.\nEsta condición puede describirse en forma abreviada así:\n\nganancia de peso de cada oruga=ganancia de peso base en general+efecto del contenido de taninos en la dieta+efecto de otros factores que fluctuan aleatoriamente\nComo modelo lineal se puede escribir así :\n\\[\ny_{ij} = \\beta_0 x_0j + \\sum_{i=1}^{k}\\beta_i x_{ij} + \\varepsilon_{j(i)}  \n\\]"
  },
  {
    "objectID": "presentaciones/2026-01-28-modelo-lineal/index.html#interpretación-de-términos",
    "href": "presentaciones/2026-01-28-modelo-lineal/index.html#interpretación-de-términos",
    "title": "Modelo Estadístico Lineal",
    "section": "Interpretación de términos",
    "text": "Interpretación de términos\n\nlas X ’s proporcionan información sobre el nivel del individuo i en los factores que estamos considerando.\nLas β son incógnitas que debemos estimar (en eso consiste ajustar el modelo).\nLa primera incógnita y la variable \\(X_0\\) que la acompaña, típicamente juegan el papel especial de reflejar el efecto de los factores constantes. Esto es, los factores que son comunes a todas las unidades experimentales. Para esto, usualmente \\(X_0\\) toma simplemente el valor de 1 para todas las unidades experimentales observadas."
  },
  {
    "objectID": "presentaciones/2026-01-28-modelo-lineal/index.html#modelos-con-variables-explicativas-cualitativas",
    "href": "presentaciones/2026-01-28-modelo-lineal/index.html#modelos-con-variables-explicativas-cualitativas",
    "title": "Modelo Estadístico Lineal",
    "section": "Modelos con variables explicativas cualitativas",
    "text": "Modelos con variables explicativas cualitativas\n\n\n\nUn agrónomo planea estudiar las tasas de producción de cuatro híbridos de trigo en tres regiones geográficas representantes de diferentes condiciones de sequía. Los sitios se escogen según la cantidad de lluvia como normal climatológica y la respuesta es el rendimiento por hectárea. Las semillas de los híbridos son asignadas aleatoriamente a los sitios.\n\n\n¿cómo piensas que se podría hacer esta aleatorización.\n\n\n\n\n¿cual sería el modelo lineal que lo podría describir?\n\n\n\n\\[\ny_{ijk} = \\mu + R_i + H_j + RH_{ij} +  \\varepsilon_{k(ij)}\n\\]"
  },
  {
    "objectID": "presentaciones/2026-01-28-modelo-lineal/index.html#el-modelo-en-todo-su-esplendor",
    "href": "presentaciones/2026-01-28-modelo-lineal/index.html#el-modelo-en-todo-su-esplendor",
    "title": "Modelo Estadístico Lineal",
    "section": "El modelo en todo su esplendor",
    "text": "El modelo en todo su esplendor\n\\[\n\\begin{gather*}\ny_{ijk} = \\mu + \\beta_{1k}R_{1k} + \\beta_{2k}R_{2k} + \\beta_{3k}R_{3k} + \\\\\n          \\beta_{4k}H_{1k}   + \\beta_{5k}H_{2k}   + \\beta_{6k}H_{3k}   + \\beta_{7k}H_{ik} + \\\\\n          \\beta_{8k}RH_{1k}  + \\beta_{9k}RH_{2k}  + \\beta_{10k}RH_{3k} + \\beta_{11k}RH_{ik}+ \\\\\n          \\beta_{12k}RH_{1k} + \\beta_{13k}RH_{2k} + \\beta_{14k}RH_{3k} + \\beta_{15k}RH_{ik}+\\\\\n          \\beta_{16k}RH_{1k} + \\beta_{17k}RH_{2k} + \\beta_{18k}RH_{3k} + \\beta_{19k}RH_{ik}+\n          \\varepsilon_{k(ij)}\n\\end{gather*}\n\\]"
  },
  {
    "objectID": "presentaciones/2026-01-28-modelo-lineal/index.html#qué-valores-toman-las-x-las-r-y-las-h",
    "href": "presentaciones/2026-01-28-modelo-lineal/index.html#qué-valores-toman-las-x-las-r-y-las-h",
    "title": "Modelo Estadístico Lineal",
    "section": "¿Qué valores toman las X, las R y las H?",
    "text": "¿Qué valores toman las X, las R y las H?\nLa forma más común de modelar datos cualitativos es:\n\n\n\n\nMediante variables usualmente llamadas factores.\nUn factor es una listas de nombres o códigos de identificación de estados o niveles mutuamente excluyentes.\nEn la modelación se requiere convertir el factor a variables indicadoras o dummy.\nHabrá tantas variables dummy como estados o niveles tenga el factor\nCada variable se construye anotando la presencia/ausencia de la condición del factor.\n\n\n\n\n\\[\nH_1 = \\left\\{\n         \\begin{align*}\n           \\text{si } \\color{red}{sí} \\text{ es híbrido del tipo } a &: 1 \\\\\n           \\text{si } \\color{red}{no} \\text{ es híbrido del tipo } a &: 0\n         \\end{align*}\n      \\right\\}\n\\]"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#la-escalera-de-la-causalidad",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#la-escalera-de-la-causalidad",
    "title": "Introducción a Diagramas Causales",
    "section": "La escalera de la causalidad",
    "text": "La escalera de la causalidad\n\n\n\n\n\n\n\n\n\n\n\nPearl, Judea. The Book of Why: The New Science of Cause and Effect (p. 28). Basic Books."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#terminología-básica-de-un-dag",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#terminología-básica-de-un-dag",
    "title": "Introducción a Diagramas Causales",
    "section": "Terminología básica de un DAG",
    "text": "Terminología básica de un DAG\n\n\n\n\nNodo : una variable\nArista : una relación causal, representada por una flecha\nVariable Explicativa : Es nuestro predictor causal de interés. Aquí es la representada por X . También se le llama variable independiente.\nRespuesta : En el DAG es la representada por Y . También se le llama variable dependiente.\nAncestros : Nodos que están “aguas arriba” de una variable dada. En este DAG A y C son ancestros de X .\nDescendientes : Nodos que están “aguas abajo” de una variable en particular. En este DAG Y y B son descendientes de X ."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#b-es-una-variable-mediadora-del-efecto-de-a",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#b-es-una-variable-mediadora-del-efecto-de-a",
    "title": "Introducción a Diagramas Causales",
    "section": "B es una variable “mediadora” del efecto de A",
    "text": "B es una variable “mediadora” del efecto de A"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#papel-de-las-variables-en-un-dag",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#papel-de-las-variables-en-un-dag",
    "title": "Introducción a Diagramas Causales",
    "section": "Papel de las variables en un DAG",
    "text": "Papel de las variables en un DAG\n\n\n\n\nFactor de Confusión : Es ancestro tanto de la explicativa X como de la respuesta Y . A lo es el DAG .\nMediador : Es al mismo tiempo descendiente de la explicativa y ancestro de la respuesta. F lo es. Parte (o la totalidad) del efecto causal sobre la respuesta se transmite a través de él.\nProxy de un Factor de Confusión : Es descendiente de un factor de confusión y ancestro de la explicativa o de la respuesta (pero no de ambas, pues entonces sería un factor de confusión). El efecto de confusión se transmite a través de esta variable. B es proxy.\nCompetidor de la explicativa : Es un ancestro de la variable de respuesta Y, sin ser ni ancestro ni descendiente de la exposición X . G compite aquí.\nInstrumento : Un instrumento es un ancestro de la explicativa. No tiene ningún camino hacia la respuesta Y que no pase a través de la explicativa X (pues sería un factor de confusión). D es un instrumento.\nColisionador : Un colisionador es un descendiente tanto de la exposición X como de la respuesta Y. E es un colisionador en el ejemplo DAG."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#cuándo-esperar-asociación",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#cuándo-esperar-asociación",
    "title": "Introducción a Diagramas Causales",
    "section": "Cuándo esperar asociación",
    "text": "Cuándo esperar asociación\n\n\n\n\n\n\n\n\n \n\n\n… a veces por pura buen fortuna"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#sesgo-sistemático-efecto-de-confusión",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#sesgo-sistemático-efecto-de-confusión",
    "title": "Introducción a Diagramas Causales",
    "section": "Sesgo sistemático: efecto de confusión",
    "text": "Sesgo sistemático: efecto de confusión\n\n\n\n\n\n\n\n\n \n\n\nHay sesgo sistemático si hay una asociación entre A e Y que no surge del efecto causal de A sobre Y. Cuando existe una asociación entre A e Y, incluso si A tiene un efecto causal cero sobre Y, se dice que hay sesgo bajo la condición nula."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#sesgo-por-selección",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#sesgo-por-selección",
    "title": "Introducción a Diagramas Causales",
    "section": "Sesgo por Selección",
    "text": "Sesgo por Selección"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#en-un-dag-con-nodos-l-a-e-y-en-este-orden-de-aparición",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#en-un-dag-con-nodos-l-a-e-y-en-este-orden-de-aparición",
    "title": "Introducción a Diagramas Causales",
    "section": "En un DAG con nodos L, A e Y (en este orden de aparición)",
    "text": "En un DAG con nodos L, A e Y (en este orden de aparición)\n¿Qué significa que no haya un arco del nodo A al Y?"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#si-nuestro-conocimiento-en-la-materia-es-insuficiente-para-descartar-la-existencia-de-un-efecto-directo-de-la-variable-d-sobre-la-e.",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#si-nuestro-conocimiento-en-la-materia-es-insuficiente-para-descartar-la-existencia-de-un-efecto-directo-de-la-variable-d-sobre-la-e.",
    "title": "Introducción a Diagramas Causales",
    "section": "Si nuestro conocimiento en la materia es insuficiente para descartar la existencia de un efecto directo de la variable D sobre la E.",
    "text": "Si nuestro conocimiento en la materia es insuficiente para descartar la existencia de un efecto directo de la variable D sobre la E.\n¿Deberíamos incluir un arco de D a E en el diagrama causal?"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#la-inteligencia-reduce-el-tiempo-necesario-de-estudio-para-aprender.-al-mismo-tiempo-la-inteligencia-junto-con-el-tiempo-de-estudio-explican-la-calificación-en-el-examen.-cuál-es-el-dag-que-describe-esta-proposición-causal",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#la-inteligencia-reduce-el-tiempo-necesario-de-estudio-para-aprender.-al-mismo-tiempo-la-inteligencia-junto-con-el-tiempo-de-estudio-explican-la-calificación-en-el-examen.-cuál-es-el-dag-que-describe-esta-proposición-causal",
    "title": "Introducción a Diagramas Causales",
    "section": "La inteligencia reduce el tiempo necesario de estudio para aprender. Al mismo tiempo, la inteligencia, junto con el tiempo de estudio explican la calificación en el examen. ¿Cuál es el DAG que describe esta proposición causal?",
    "text": "La inteligencia reduce el tiempo necesario de estudio para aprender. Al mismo tiempo, la inteligencia, junto con el tiempo de estudio explican la calificación en el examen. ¿Cuál es el DAG que describe esta proposición causal?"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#reglas-de-independencia-condicional",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#reglas-de-independencia-condicional",
    "title": "Introducción a Diagramas Causales",
    "section": "Reglas de independencia condicional",
    "text": "Reglas de independencia condicional\nUn DAG también describe aspectos clave del “flujo de la asociación” a través de la estructura causal.\n\nCuando las variables están conectadas, correlacionan, lo que implica que la información puede fluir entre ellas en cualquier dirección.\nHay tres reglas fundamentales sobre como se puede dar esta interconexión, es decir de como se separan o conectan los nodos."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#regla-1-variable-intermedia",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#regla-1-variable-intermedia",
    "title": "Introducción a Diagramas Causales",
    "section": "Regla 1 “variable intermedia”",
    "text": "Regla 1 “variable intermedia”\n\n\n\nDos variables, X e Y, son condicionalmente independientes dado A , si sólo hay una ruta unidireccional entre X e Y , cuando A es una variable (podrían ser muchas) intercalada en el camino."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#regla-2-causa-común",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#regla-2-causa-común",
    "title": "Introducción a Diagramas Causales",
    "section": "Regla 2 “causa común”",
    "text": "Regla 2 “causa común”\n\n\n\n \n\n\n\n\nSi una variable A es una causa común de las variables X e Y , y solo hay una ruta entre X e Y , entonces X e Y son condicionalmente independientes cuando se consideran como condicionantes los datos de A ."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#regla-3-colisionador",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#regla-3-colisionador",
    "title": "Introducción a Diagramas Causales",
    "section": "Regla 3 “colisionador”",
    "text": "Regla 3 “colisionador”\n\n\n\n \n\n\n\n\nSi una variable A es el nodo de colisión entre dos variables X e Y , y solo hay un camino entre X e Y , entonces X e Y son incondicionalmente independientes pero dependen condicionalmente de A así como de cualquier descendiente de A ."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#separación-direccional-d-separation",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#separación-direccional-d-separation",
    "title": "Introducción a Diagramas Causales",
    "section": "Separación-direccional (d-separation)",
    "text": "Separación-direccional (d-separation)\nEl flujo de información en una ruta p queda bloqueado por un conjunto de nodos Z si y sólo si:\n\np contiene una cadena de nodos A → B → C o una horquilla A ← B → C , de tal manera que el nodo medio B proporciona datos como criterio condicional de observación. Es decir si la ruta es del tipo variable intermedia o causa común, el condicionarlas bloquea.\np contiene un colisionador A → B ← C tal que ni el nodo de colisión B , ni ninguno de sus descendientes, son criterio para condicionar las observaciones. Es decir condicionar sore un colisionador desbloquea ."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#se-puede-medir-el-efecto-sin-sesgos-de-la-aspirina",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#se-puede-medir-el-efecto-sin-sesgos-de-la-aspirina",
    "title": "Introducción a Diagramas Causales",
    "section": "¿Se puede medir el efecto, sin sesgos, de la aspirina?",
    "text": "¿Se puede medir el efecto, sin sesgos, de la aspirina?"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#colisionadores",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#colisionadores",
    "title": "Introducción a Diagramas Causales",
    "section": "Colisionadores",
    "text": "Colisionadores\n\nMcElreath nos ofrece esta proposición:\n\nLos estudios científicos más noticiables son los menos fiables. Cuanto más probable es que te mate, si es cierto, menos probable es que sea cierto. Cuanto más aburrido el tema, más rigurosos los resultados.\n\n\nFuente: The Haunted DAG & The Causal Terror | Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition (bookdown.org)"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#cómo-se-produce-esta-correlación-negativa",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#cómo-se-produce-esta-correlación-negativa",
    "title": "Introducción a Diagramas Causales",
    "section": "¿Cómo se produce esta correlación negativa?",
    "text": "¿Cómo se produce esta correlación negativa?\nEsta asociación NO CAUSAL se produce cuando los revisores se preocupan tanto por el interés “innovador” (pensando en su potencial noticioso), como por la fiabilidad.\nUna fuerte selección induce una correlación negativa entre los criterios utilizados en la selección.\n¿Por qué? Si la única forma de cruzar el umbral es obtener una puntuación alta, es más frecuente obtener una puntuación alta en un criterio que en ambos.\nFuente: The Haunted DAG & The Causal Terror | Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition (bookdown.org)"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#la-paradoja-de-simpson",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#la-paradoja-de-simpson",
    "title": "Introducción a Diagramas Causales",
    "section": "La paradoja de Simpson",
    "text": "La paradoja de Simpson\nEjemplo con datos de COVID-19 sobre mortalidad por raza, tal y como se describe en el blog de Judea Pearl .\nLa paradoja: los blancos no hispanos tienen una mayor mortalidad si nos fijamos en los datos agregados. Pero: Desagregados por edad (relativo a la expectativa de vida, de ahí el arco B), los blancos tienen una mortalidad menor en todos los grupos de edad. El DAG correspondiente:\n\n\n\n\n\n\n\nComo podemos ver en el gráfico, la edad es un factor de confusión para esta relación y, por tanto, mirar los datos observacionales Pr (Muerte|Raza) no dará la respuesta correcta. Una vez que observamos Pr (Muerte|Raza, Edad), el efecto de la variable Raza se invierte. La razón por la que puede ocurrir esto es poco intuitiva."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#la-paradoja-de-berkson",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#la-paradoja-de-berkson",
    "title": "Introducción a Diagramas Causales",
    "section": "La paradoja de Berkson",
    "text": "La paradoja de Berkson\n\n\n\nLa paradoja de Berkson surge al condicionar un colisionador. Esto puede parecer paradójico pero usualmente es un artefacto del diseño del estudio, por ejemplo durante la selección de participantes.\nSupongamos investigas si existe alguna relación entre contraer COVID y padecer alguna otra enfermedad.\nSupongamos además que en la población general la COVID es independiente de otras enfermedades. Ahora bien, si basas tu estudio únicamente en pacientes hospitalizados, encontrarás que Pr(COVID|no Otras enfermedades) = ¡1!\nObviamente hubo algún padecimiento para estar hospitalizados.\nCondicionar a la hospitalización hace que las dos variables resulten asociadas, cuando antes no lo eran.\nEl condicionamiento sobre el colisionador ha desbloqueado la vía causal entre las dos variables."
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#efecto-problemático-de-un-colisionador",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#efecto-problemático-de-un-colisionador",
    "title": "Introducción a Diagramas Causales",
    "section": "Efecto problemático de un “colisionador”",
    "text": "Efecto problemático de un “colisionador”\n\n\n\n Fuente: https://www.nature.com/articles/s41467-020-19478-2"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#cómo-influye-la-edad-sobre-la-felicidad",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#cómo-influye-la-edad-sobre-la-felicidad",
    "title": "Introducción a Diagramas Causales",
    "section": "¿cómo influye la edad sobre la felicidad?",
    "text": "¿cómo influye la edad sobre la felicidad?\nSi disponemos de una amplia encuesta de personas felices, ¿cabría esperar alguna asociación entre la edad y la felicidad?"
  },
  {
    "objectID": "presentaciones/2026-01-28-diagramas-causales/index.html#la-paradoja-del-bajo-peso-al-nacer",
    "href": "presentaciones/2026-01-28-diagramas-causales/index.html#la-paradoja-del-bajo-peso-al-nacer",
    "title": "Introducción a Diagramas Causales",
    "section": "La paradoja del bajo peso al nacer",
    "text": "La paradoja del bajo peso al nacer\nEste es un ejemplo real que desconcertó a la comunidad médica durante muchos años.\nAl estudiar el efecto del tabaco en la mortalidad infantil. Ya se sabía que fumar provocaba un mayor riesgo de bajo peso al nacer y que el bajo peso al nacer aumenta el riesgo de mortalidad infantil.\n¿El tabaquismo tiene algún otro efecto sobre la mortalidad infantil?, aparte de causar bajo peso al nacer.\nLa intuición de los investigadores sugirió condicionar el peso al nacer y entonces observar el efecto del tabaquismo sobre la mortalidad: ¡se descubrió que fumar tenía un efecto protector!\nLa explicación es que ¡se trata de un sesgo del colisionador!\nHay varias causas de bajo peso al nacer. Fumar es una de ellas, pero hay otras.\nLas otras causas de bajo peso al nacer tienen un mayor riesgo negativo sobre la mortalidad infantil, aparte de su efecto sobre el bajo peso al nacer.\nComo reto, dibuja el DAG correspondiente y combina todos estos hechos para averiguar cómo el condicionamiento sobre el peso al nacer puede crear el hallazgo de que fumar tiene un falso efecto protector."
  },
  {
    "objectID": "posts/10-experimentar/index.html",
    "href": "posts/10-experimentar/index.html",
    "title": "Experimentación Ecológica",
    "section": "",
    "text": "La experimentación con diseños adecuadamente aleatorizados es la norma de referencia científica para la exploración de proposiciones causales. Preguntas de gran envergadura para los intereses humanos se resuelven mediante esta aproximación. La experimentación desafía la imaginación y las capacidades materiales y humanas. Exige ingenio y creatividad, pero también está acotada por el marco ético que nos exige evitar dañar a otros seres humanos, así como también evitar hacerlo a otras especies o a la naturaleza misma."
  },
  {
    "objectID": "posts/10-experimentar/index.html#ciencia-abierta",
    "href": "posts/10-experimentar/index.html#ciencia-abierta",
    "title": "Experimentación Ecológica",
    "section": "Ciencia Abierta",
    "text": "Ciencia Abierta\nCentro de Ciencia Abierta\nCiecia abierta - UNESCO\nCiencia Abierta - CEPAL"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html",
    "href": "posts/08-modelos-mixtos/index.html",
    "title": "Modelos de Efectos Mixtos",
    "section": "",
    "text": "Hay situaciones en las que un estudio requiere considerar unidades experimentales múltiples. Por ejemplo, si estamos haciendo un estudio en parcelas forestales y las parcelas son sujetas a tratamientos, claramente esas parcelas son las unidades experimentales de primera mano.\nSin embargo, imaginemos que la variable de respuesta es el contenido de nitrógeno en el suelo, Es poco práctico recolectar la totalidad del suelo hasta, digamos 15cm de profundidad de cada parcela para determinar el contenido de nitrógeno en el suelo de toda la parcela.\n\n\n\n\n\n\nPrecaución¿Qué opciones tenemos?\n\n\n\n\n\n\nExiste ayuda en R para el diseño de experimentos, como podemos ver en este preprint\n\n\n\nLa opción natural sería en este caso tomar una muestra de suelo en cada parcela, y hacer las determinaciones de contenido de nitrógeno en ellas. Al hacer esto, no conoceremos el contenido de nitrógeno de las parcelas, lo estimaremos con un margen de error, es decir con un componente de varianza asociado con el procedimiento de muestreo. Las muestras son lo que podríamos llamar unidades experimentales pequeñas que, además del efecto del tratamiento son afectadas por el procedimiento de muestreo como factor adicional.\n\nOtra situación es, por ejemplo, un experimento sobre el efecto del cambio climático sobre la fotosíntesis de árboles sujetos a distintos niveles de fertilizante. La situación se complica porque lo que interesa es saber si el incremento en la temperatura afecta el contenido de nitrógeno en las hojas, para lo cual se opta por hacerlo mediante un muestreo en el que se eligen ramas en cada árbol para exponerlas a una atmósfera a temperaturas controladas. ¿Cuantas hojas habríamos de utilizar para hacer las determinaciones confiablemente?\nLos árboles son unidades experimentales grandes tratadas con fertilizante y las ramas son unidades experimentales chicas que reciben el tratamiento factorial fertilizante + temperatura. Además hay que notar que muy probablemente hay un efecto “idiosincrático” del árbol que genera variación en el comportamiento de las ramas.\n\n\nCódigo\nparcela_dividida &lt;- dagitty('dag{bb=\"0,0,1,1\"\n                                 \"aleat-1\" [latent,pos=\"0.4, 0.2\"]\n                                 \"aleat-2\" [latent,pos=\"0.6, 0.2\"]\n                                 \"árbol\" [pos=\"0.4, 0.3\"]\n                                 fert [exposure,pos=\"0.2, 0.3\"]\n                                 hojasN [outcome,pos=\"0.8, 0.3\"]\n                                 rama [pos=\"0.6, 0.3\"]\n                                 temp [exposure,pos=\"0.6, 0.4\"]\n                                 \"aleat-1\" -&gt; \"árbol\"\n                                 \"aleat-2\" -&gt; rama\n                                 \"árbol\" -&gt; rama\n                                 fert -&gt; \"árbol\"\n                                 rama -&gt; hojasN\n                                 temp -&gt; rama}')\npar(cex = 0.75, lwd  = 1)\nplot(parcela_dividida)"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#diseños-con-multiples-niveles-de-unidades-experimentales",
    "href": "posts/08-modelos-mixtos/index.html#diseños-con-multiples-niveles-de-unidades-experimentales",
    "title": "Modelos de Efectos Mixtos",
    "section": "",
    "text": "Hay situaciones en las que un estudio requiere considerar unidades experimentales múltiples. Por ejemplo, si estamos haciendo un estudio en parcelas forestales y las parcelas son sujetas a tratamientos, claramente esas parcelas son las unidades experimentales de primera mano.\nSin embargo, imaginemos que la variable de respuesta es el contenido de nitrógeno en el suelo, Es poco práctico recolectar la totalidad del suelo hasta, digamos 15cm de profundidad de cada parcela para determinar el contenido de nitrógeno en el suelo de toda la parcela.\n\n\n\n\n\n\nPrecaución¿Qué opciones tenemos?\n\n\n\n\n\n\nExiste ayuda en R para el diseño de experimentos, como podemos ver en este preprint\n\n\n\nLa opción natural sería en este caso tomar una muestra de suelo en cada parcela, y hacer las determinaciones de contenido de nitrógeno en ellas. Al hacer esto, no conoceremos el contenido de nitrógeno de las parcelas, lo estimaremos con un margen de error, es decir con un componente de varianza asociado con el procedimiento de muestreo. Las muestras son lo que podríamos llamar unidades experimentales pequeñas que, además del efecto del tratamiento son afectadas por el procedimiento de muestreo como factor adicional.\n\nOtra situación es, por ejemplo, un experimento sobre el efecto del cambio climático sobre la fotosíntesis de árboles sujetos a distintos niveles de fertilizante. La situación se complica porque lo que interesa es saber si el incremento en la temperatura afecta el contenido de nitrógeno en las hojas, para lo cual se opta por hacerlo mediante un muestreo en el que se eligen ramas en cada árbol para exponerlas a una atmósfera a temperaturas controladas. ¿Cuantas hojas habríamos de utilizar para hacer las determinaciones confiablemente?\nLos árboles son unidades experimentales grandes tratadas con fertilizante y las ramas son unidades experimentales chicas que reciben el tratamiento factorial fertilizante + temperatura. Además hay que notar que muy probablemente hay un efecto “idiosincrático” del árbol que genera variación en el comportamiento de las ramas.\n\n\nCódigo\nparcela_dividida &lt;- dagitty('dag{bb=\"0,0,1,1\"\n                                 \"aleat-1\" [latent,pos=\"0.4, 0.2\"]\n                                 \"aleat-2\" [latent,pos=\"0.6, 0.2\"]\n                                 \"árbol\" [pos=\"0.4, 0.3\"]\n                                 fert [exposure,pos=\"0.2, 0.3\"]\n                                 hojasN [outcome,pos=\"0.8, 0.3\"]\n                                 rama [pos=\"0.6, 0.3\"]\n                                 temp [exposure,pos=\"0.6, 0.4\"]\n                                 \"aleat-1\" -&gt; \"árbol\"\n                                 \"aleat-2\" -&gt; rama\n                                 \"árbol\" -&gt; rama\n                                 fert -&gt; \"árbol\"\n                                 rama -&gt; hojasN\n                                 temp -&gt; rama}')\npar(cex = 0.75, lwd  = 1)\nplot(parcela_dividida)"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#ejemplo-de-rieles",
    "href": "posts/08-modelos-mixtos/index.html#ejemplo-de-rieles",
    "title": "Modelos de Efectos Mixtos",
    "section": "Ejemplo de rieles",
    "text": "Ejemplo de rieles\n\n\n\n\n\n\nNotaCalidad de rieles de ferrocarril\n\n\n\n\n\nUno de los principales problemas que enfrentan los ferrocarriles es la falla en las vías. Los defectos en los raíles, como parte básica de la vía, pueden provocar accidentes graves. La inspección de los rieles es crítica, considerando el enorme tráfico que soportan actualmente, la mayor velocidad y las cargas más pesadas. La inspección visual sólo puede detectar defectos superficiales y, a veces, signos evidentes de problemas internos, la defectoscopía ultrasónica desempeña un papel insustituible en la inspección de los rieles durante su funcionamiento.\n\nEste ejemplo se explica en este libro.\n\n\n\nEl estudio de las fuerzas y tensiones no destructivas en los materiales proporciona información importante para un diseño de ingeniería eficaz. El artículo Zero-Force Travel-Time Parameters for Ultrasonic Head-Waves in Railroad (Materials Evaluation, 1985: 854-858) reporta un estudio del tiempo de tránsito de un cierto tipo de onda que se obtiene al someter rieles de ferrocarril a esfuerzos de tensión longitudinal. Se realizaron tres mediciones en cada uno de seis rieles seleccionados aleatoriamente de una población más amplia de ellos. Los investigadores buscaban caracterizar la variación en el tiempo de viaje como referencia para describir la variabilidad típica entre los rieles que estaban adquiriendo y usando. Los ingenieros se interesaban en precisar la variabilidad atribuible al ejercicio de realizar las mediciones en un mismo riel y la variabilidad que expresan los distintos rieles. Los datos son valores en nanosegundos, resultado de restar 36.1 \\(\\mu s\\) a cada observación.\nEste ejemplo es un caso simple de efectos aleatorios. En resumen, seis rieles fueron tomados al azar y sometidos a prueba tres veces cada uno mediante la medición del tiempo que le toma a cierto tipo de ondas ultrasónicas viajar a lo largo del riel. La Única condición experimental que cambia entre observaciones es el riel.\nClaramente el estudio tiene un solo criterio de clasificación, como posible condición de contraste. La intención del estudio fue la determinación de:\n\nTiempo de tránsito “típico” de un riel (tiempo esperado de tránsito)\nVariación en el tiempo de tránsito promedio entre los rieles (variabilidad entre rieles)\nVariación al medir el tiempo observado de tránsito en un mismo riel (variabilidad dentro de rieles)\n\n\\[\ny_{ij} = \\mu + \\beta_{1} R_{i} + \\varepsilon_{i(j)}\n\\]\nUtilizaremos la biblioteca nlme (Linear and Nonlinear Mixed Effects Models, de tipo Gausiano o normal) para ajustar los modelos de efectos mixtos.\nComo hemos estado viendo, actualmente resulta casi obligatorio recurrir a ggplot2 para producir gráficas con calidad publicación. Esta biblioteca pone en práctica la propuesta que hacen sus autores de una semántica de graficación, la que Hadley Wickham explica originalmente en su libro publicado en 2009. Actualmente Hadley trabaja con otros dos coautores (Danielle Navarro y Thomas Lin Pedersen) en al 3ra. edición, lo hacen como un preprint que pueden encontrar aquí. La gran influencia de este planteamiento a la producción de gráficas de datos ha dado lugar a muchas ideas y recursos de ayuda que fácilmente se pueden encontrar en la Web.\nlos datos con los que trabajaremos en esta sesión están en la tabla Rail de la biblioteca nlme. Para acomodarlos a mis propósitos los copie a mi espacio de trabajo y los guardé en una variable con un nombre de mi gusto. Los datos de los rieles están ordenados según fueron ensayados.\n\n\nCódigo\nlibrary(nlme)\n\n\n\nAdjuntando el paquete: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nCódigo\nlibrary(ggplot2)\n\nhead(Rail)\n\n\nGrouped Data: travel ~ 1 | Rail\n  Rail travel\n1    1     55\n2    1     53\n3    1     54\n4    2     26\n5    2     37\n6    2     32\n\n\nCódigo\nrieles &lt;- Rail\nnames(rieles) &lt;- c(\"riel\", \"viaje\")\nstr(rieles)\n\n\nClasses 'nffGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame':  18 obs. of  2 variables:\n $ riel : Ord.factor w/ 6 levels \"2\"&lt;\"5\"&lt;\"1\"&lt;\"6\"&lt;..: 3 3 3 1 1 1 5 5 5 6 ...\n $ viaje: num  55 53 54 26 37 32 78 91 85 92 ...\n - attr(*, \"labels\")=List of 1\n  ..$ y: chr \"Zero-force travel time\"\n - attr(*, \"units\")=List of 1\n  ..$ y: chr \"(nanoseconds)\"\n - attr(*, \"formula\")=Class 'formula'  language travel ~ 1 | Rail\n  .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n - attr(*, \"order.groups\")= logi TRUE\n\n\nLa tabla rieles fue creada como una estructura agrupada con la función groupeData de la biblioteca nlme. Veremos más adelante como usar esta función. Esta función agrega metadatos a la tabla. Si interesa hacer cambios a los metadatos de la tabla agrupada hay que usar la función update que ejemplificaré a continuación. Lo primero es explorar los atributos asignados.\n\n\nCódigo\nattributes(rieles)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$class\n[1] \"nffGroupedData\" \"nfGroupedData\"  \"groupedData\"    \"data.frame\"    \n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$labels\n$labels$y\n[1] \"Zero-force travel time\"\n\n\n$units\n$units$y\n[1] \"(nanoseconds)\"\n\n\n$formula\ntravel ~ 1 | Rail\n\n$order.groups\n[1] TRUE\n\n\nAhora cambiemos estos atributos para que todo esté expresado en español y de paso corregir la fórmula, que tal como está, pierde la referencia adecuada a las variables que contiene la tabla, pues yo cambié los nombres de las variables.\n\n\nCódigo\nrieles  &lt;- update(rieles, formula = viaje ~ 1 | riel, FUN = mean,\n                  labels = list(y = \"Tiempo de viaje con fuerza cero\"),\n                  units = list(y = \"(nano segundos)\"))\n\n# Encontré un detallito raro de atributos que se quedan con basura. \n# Aunque no parecen producir ningún problema, esta es una manera de limpiarla.\nattributes(attributes(rieles)$formula)$\".Environment\" &lt;- environment()\nenvironment(attributes(rieles)$FUN) &lt;- environment()\nattributes(rieles)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$class\n[1] \"nffGroupedData\" \"nfGroupedData\"  \"groupedData\"    \"data.frame\"    \n\n$formula\nviaje ~ 1 | riel\n\n$labels\n$labels$y\n[1] \"Tiempo de viaje con fuerza cero\"\n\n\n$units\n$units$y\n[1] \"(nano segundos)\"\n\n\n$FUN\nfunction (x, ...) \nUseMethod(\"mean\")\n\n$order.groups\n[1] TRUE\n\n\nA esta tabla se le ha aplicado la función groupedData con la fórmula:\nviaje ~ 1 | riel\nEsta estrategia permite darle mantenimiento a los metadatos, que incluyen indicaciones sobre el agrupamiento de los datos en la tablas. Para aprovechar esta estructura podemos usar funciones especiales, por cierto, dentro del paquete nmle, puedes averiguar un poco más al respecto con help(plot.nmGroupedData):\n\ngapply - aplica funciones por grupos\ngsummary - calcula los resúmenes de datos por grupos\n\nPor lo pronto veamos los datos en una gráfica con el factor riel que define los renglones cualitativos sobre los que se grafican los datos cuantitativos de velocidad de viaje.\n\n\nCódigo\nggplot(rieles, aes(x = viaje, y = riel, group = riel)) + \n       geom_point(shape = 19, size = 2, color = \"brown\") +\n       labs(title = \"Análisis de integridad estructural de rieles\") +\n       xlab(label = \"tiempo de viaje (ns)\") +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size = 18), \n             axis.text.x = element_text(angle = 0, hjust = 1)) \n\n\n\n\n\n\n\n\n\n¿Cómo se ven estos datos? ¿qué piensas que habría que hacer?\n\n\nCódigo\ngsummary(rieles)\n\n\n  riel    viaje\n2    2 31.66667\n5    5 50.00000\n1    1 54.00000\n6    6 82.66667\n3    3 84.66667\n4    4 96.00000\n\n\n¿Cómo se asigna la estructura de agrupación a una tabla de datos? Como dije al principio, se puede usar la función groupedData de la biblioteca nlme. Hagamos un ahora un ensayo de este proceso.\n\n\nCódigo\nrieles.sg &lt;- as.data.frame(rieles)\nattributes(rieles.sg)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$class\n[1] \"data.frame\"\n\n\nEstructura de la tabla sin información de agrupamiento:\n\n\nCódigo\nstr(rieles.sg) \n\n\n'data.frame':   18 obs. of  2 variables:\n $ riel : Ord.factor w/ 6 levels \"2\"&lt;\"5\"&lt;\"1\"&lt;\"6\"&lt;..: 3 3 3 1 1 1 5 5 5 6 ...\n $ viaje: num  55 53 54 26 37 32 78 91 85 92 ...\n\n\nLos atributos que contiene este objeto son estos:\n\n\nCódigo\nattributes(rieles.sg)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$class\n[1] \"data.frame\"\n\n\nTomo los datos sin agrupamiento y proporciono los metadatos que definen la estructura de agrupamiento que caracterizan a la tabla :\n\n\nCódigo\nrieles.g &lt;- groupedData (viaje ~ 1 | riel, data = rieles.sg, \n                         FUN = mean,\n                         units = list( y = \"(ns)\"),\n                         labels = list(x = \"riel\", \n                                       y = \"tiempo de tránsito de fuerza cero\"),\n                         )\nattributes(rieles.g)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$class\n[1] \"nffGroupedData\" \"nfGroupedData\"  \"groupedData\"    \"data.frame\"    \n\n$formula\nviaje ~ 1 | riel\n\n$labels\n$labels$x\n[1] \"riel\"\n\n$labels$y\n[1] \"tiempo de tránsito de fuerza cero\"\n\n\n$units\n$units$y\n[1] \"(ns)\"\n\n\n$FUN\nfunction (x, ...) \nUseMethod(\"mean\")\n&lt;bytecode: 0x0000018603c54cb0&gt;\n&lt;environment: namespace:base&gt;\n\n$order.groups\n[1] TRUE\n\n\n\n\nCódigo\ndata.frame(sg = rieles.sg, g = rieles.g)\n\n\n   sg.riel sg.viaje g.riel g.viaje\n1        1       55      1      55\n2        1       53      1      53\n3        1       54      1      54\n4        2       26      2      26\n5        2       37      2      37\n6        2       32      2      32\n7        3       78      3      78\n8        3       91      3      91\n9        3       85      3      85\n10       4       92      4      92\n11       4      100      4     100\n12       4       96      4      96\n13       5       49      5      49\n14       5       51      5      51\n15       5       50      5      50\n16       6       80      6      80\n17       6       85      6      85\n18       6       83      6      83\n\n\n\n\nCódigo\ngsummary(rieles.sg)\n\n\n    riel viaje\n26     2    26\n32     2    32\n37     2    37\n49     5    49\n50     5    50\n51     5    51\n53     1    53\n54     1    54\n55     1    55\n78     3    78\n80     6    80\n83     6    83\n85     3    85\n91     3    91\n92     4    92\n96     4    96\n100    4   100\n\n\n\n\nCódigo\ngsummary(rieles.g)\n\n\n  riel    viaje\n2    2 31.66667\n5    5 50.00000\n1    1 54.00000\n6    6 82.66667\n3    3 84.66667\n4    4 96.00000\n\n\n\n\nCódigo\nggplot(rieles.g, aes(x = viaje, y = riel, group = riel)) + \n       geom_point(shape = 19, size = 4, color = \"blue\") +\n       labs(title = \"Análisis de rieles (rieles.g)\") +\n       xlab(label = attr(rieles.g, \"labels\")$y) +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size = 18), \n             axis.text.x = element_text(angle = 0, hjust = 1)) \n\n\n\n\n\n\n\n\n\nComo hemos visto, cambiar los metadatos de la tabla se hace con la función update().\nComo una demostración simple de esto, le cambiaré la etiqueta, que es un atributo asociado a la variable de respuesta en la estructura de agrupamiento. El dato lo puedo recuperar entonces con la función attr para “labels”. En seguida te pongo un ejemplo\n\n\nCódigo\nrieles.g1 &lt;- update(rieles.g, labels = list(y = \"tiempo (ns)\"))\n\nggplot(rieles.g1, aes(x = viaje, y = riel, group = riel)) + \n       geom_point(shape = 19, size = 4, color = \"blue\") +\n       labs(title = \"Análisis de rieles (rieles.g1)\") +\n       xlab(label = attr(rieles.g1, \"labels\")$y) +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size = 18), \n             axis.text.x = element_text(angle = 0, hjust = 1)) \n\n\n\n\n\n\n\n\n\nPrimera posibilidad de análisis. Modelo lineal simple. Es una elección natural en este caso, pues estima la media general. Hay que recordar seleccionar contrastes de tipo “tratamiento” aun para factores ordenados.\n¿Cómo representamos al riel en el modelo?\n\n\nCódigo\noptions ()$contrasts\n\n\n        unordered           ordered \n\"contr.treatment\"      \"contr.poly\" \n\n\nEmpecemos por construir el modelo nulo. ¿qué resultados nos ofrece este modelo?.\n\n\nCódigo\nrieles.m1 &lt;- lm(viaje ~ 1, data = rieles.g)\nsummary(rieles.m1)\n\n\n\nCall:\nlm(formula = viaje ~ 1, data = rieles.g)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-40.50 -16.25   0.00  18.50  33.50 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   66.500      5.573   11.93  1.1e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.65 on 17 degrees of freedom\n\n\nAsí, tengo una estimación del tiempo promedio de tránsito de: 66.5. El error estándar que estimo es: 5.573\n¿cómo quedan los residuos de este modelo?\nEl gráfico de cajas y bigotes o cajas y alambres es interesante para explorar lo que está pasando con los rieles.\n¿Qué piensas de esta gráfica? ¿Te gusta lo que ves?\n\n\nCódigo\nggplot(rieles.g, aes(x = viaje, y = riel, group = riel)) + \n       stat_boxplot(geom ='errorbar', linetype = 2, width = 0.5) + \n       geom_boxplot(shape = 19, size = 0.5, color = \"blue\", notch = FALSE) +\n       labs(title = \"Análisis de rieles (rieles.g)\") +\n       xlab(label = \"tiempo de viaje (ns)\") +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size = 18), \n             axis.text.x = element_text(angle = 0, hjust = 0.5)) \n\n\n\n\n\n\n\n\n\nAl ignorar el efecto de los rieles, dentro de los que repito la prueba para obtener las medidas de interés se produce un defecto que se ve claramente en esta gráfica de residuos.\nLos residuos de cada riel tienen todos el mismo signo. Es decir se mantiene un efecto sistemático importante en ellos.\nTe parecería buena idea agregar el término que representa al riel para resolver este problema?\n¿Es fijo o aleatorio?\nEste nuevo modelo permite que cada riel sea representado por una media diferente. Suponiendo efectos fijos, la estimación del parámetro de interés es esta.\n\n\nCódigo\nrieles.m2 &lt;- lm(viaje ~ riel -1, data = rieles.g)\nsummary(rieles.m2)\n\n\n\nCall:\nlm(formula = viaje ~ riel - 1, data = rieles.g)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6667 -1.0000  0.1667  1.0000  6.3333 \n\nCoefficients:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nriel2   31.667      2.321   13.64 1.15e-08 ***\nriel5   50.000      2.321   21.54 5.86e-11 ***\nriel1   54.000      2.321   23.26 2.37e-11 ***\nriel6   82.667      2.321   35.61 1.54e-13 ***\nriel3   84.667      2.321   36.47 1.16e-13 ***\nriel4   96.000      2.321   41.35 2.59e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.021 on 12 degrees of freedom\nMultiple R-squared:  0.9978,    Adjusted R-squared:  0.9967 \nF-statistic: 916.6 on 6 and 12 DF,  p-value: 2.971e-15\n\n\n\n\nCódigo\nanova(rieles.m2)\n\n\nAnalysis of Variance Table\n\nResponse: viaje\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nriel       6  88911 14818.5  916.61 2.971e-15 ***\nResiduals 12    194    16.2                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCódigo\nsummary(rieles.m2)\n\n\n\nCall:\nlm(formula = viaje ~ riel - 1, data = rieles.g)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6667 -1.0000  0.1667  1.0000  6.3333 \n\nCoefficients:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nriel2   31.667      2.321   13.64 1.15e-08 ***\nriel5   50.000      2.321   21.54 5.86e-11 ***\nriel1   54.000      2.321   23.26 2.37e-11 ***\nriel6   82.667      2.321   35.61 1.54e-13 ***\nriel3   84.667      2.321   36.47 1.16e-13 ***\nriel4   96.000      2.321   41.35 2.59e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.021 on 12 degrees of freedom\nMultiple R-squared:  0.9978,    Adjusted R-squared:  0.9967 \nF-statistic: 916.6 on 6 and 12 DF,  p-value: 2.971e-15\n\n\n¿interpretación de este nuevo resultado?\n……….. ¿y los residuos? ¿cómo se ven ahora?\n\n\nCódigo\nres.m2 &lt;- data.frame(resid = resid(rieles.m2), riel = rieles.g$riel)\nggplot(res.m2, aes(x = resid, y = riel, group = riel)) + \n       stat_boxplot(geom = 'errorbar', linetype = 2, width = 0.5) + \n       geom_boxplot(shape = 19, size = 0.5, color = \"blue\") \n\n\n\n\n\n\n\n\n\nA pesar de que el modelo remueve los efectos sistemáticos asociados a las características particulares de los distintos rieles, no proporciona una representación satisfactoria del problema.\nsi los rieles fueran de efectos fijos ¿qué implicaría este modelo? ¿cuál sería una interpretación razonable del tratamiento riel?\nAl suponer efectos fijos surge el problema de que se modelan de algún modo variantes individuales de los rieles que se usaron para realizar las pruebas. Desafortunadamente, tal clasificación no tiene ningún sentido en el contexto. Lo que interesa es estimar el tiempo de tránsito típico de cualquier riel en la población de rieles de la que se tomó la muestra.\nAdemás, la misma falta de correspondencia conceptual entre el modelo y la estimación que interesa, hace que este nuevo modelo no proporcione una clara estimación de la variación (componente de varianza), entre rieles, que es otra de las preguntas centrales de este estudio. Otro problema de este modelo de efectos fijos es que el número de parámetros crece linealmente con el número de rieles que se usan para realizar la prueba, generando un comportamiento extraño en el modelo respecto de la pregunta.\n\nEl Modelo de efectos aleatorios ¿resuelves estos problemas?.\nEn este enfoque se considera a los rieles como un efecto aleatorio sobre la media general. Hay principalmente dos métodos para ajustar este tipo de modelos el de máxima verosimilitud (ML) y el de máxima verosimilitud restringida (REML, default). La función que utilizaremos para el caso lineal es lme() que se usa de modo muy semejante a lm(). Sin embargo, nótese que ahora el modelo tiene dos grupos de fórmulas, una para describir los efectos fijos (opción fixed) y otra para describir los aleatorios (opción random). Esté último es siempre una fórmula que tiene sólo el lado derecho (no hay interés en predecir medias de alguna variable de respuesta, ¿recuerdas?) y da cuenta de los efectos aleatorios y de la estructura de agrupamiento de los datos. Un agrupamiento se representa mediante el símbolo de barra vertical: |. Ahora, ajustemos un modelo de este tipo para obtener la estimación de máxima verosimilitud restringida para los rieles.\n\n\nCódigo\nrieles.m3 &lt;- lme(fixed = viaje ~ 1, random = ~ 1 | riel, data = rieles.g)\nrieles.m3\n\n\nLinear mixed-effects model fit by REML\n  Data: rieles.g \n  Log-restricted-likelihood: -61.0885\n  Fixed: viaje ~ 1 \n(Intercept) \n       66.5 \n\nRandom effects:\n Formula: ~1 | riel\n        (Intercept) Residual\nStdDev:    24.80547 4.020779\n\nNumber of Observations: 18\nNumber of Groups: 6"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#ayúdame-a-comentar-estos-resultados-qué-te-llama-la-atención",
    "href": "posts/08-modelos-mixtos/index.html#ayúdame-a-comentar-estos-resultados-qué-te-llama-la-atención",
    "title": "Modelos de Efectos Mixtos",
    "section": "Ayúdame a comentar estos resultados ¿qué te llama la atención?",
    "text": "Ayúdame a comentar estos resultados ¿qué te llama la atención?\n\n\nCódigo\nsummary(rieles.m3)\n\n\nLinear mixed-effects model fit by REML\n  Data: rieles.g \n      AIC      BIC   logLik\n  128.177 130.6766 -61.0885\n\nRandom effects:\n Formula: ~1 | riel\n        (Intercept) Residual\nStdDev:    24.80547 4.020779\n\nFixed effects:  viaje ~ 1 \n            Value Std.Error DF  t-value p-value\n(Intercept)  66.5  10.17104 12 6.538173       0\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-1.61882658 -0.28217671  0.03569328  0.21955784  1.61437744 \n\nNumber of Observations: 18\nNumber of Groups: 6"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#control-del-glucógeno-en-hígados-de-rata",
    "href": "posts/08-modelos-mixtos/index.html#control-del-glucógeno-en-hígados-de-rata",
    "title": "Modelos de Efectos Mixtos",
    "section": "Control del glucógeno en hígados de rata",
    "text": "Control del glucógeno en hígados de rata\n\nEste ejemplo fue presentado originalmente en Sokal & Rohlf (1981). Se trata de un experimento con un solo factor con tres dietas: 1 = “control”, 2 = “compuesto 217”, 3 = “compuesto 217 + azúcar”. Fueron administrados a seis ratas, dos por tratamiento. El análisis se complica por el hecho de que, para el análisis, se tomaron tres muestras del hígado de cada rata y se hicieron dos determinaciones de contenido de glucógeno en cada muestra. Podríamos decir, un tanto despectivamente, que hay seis pseudoréplicas por rata para dar un total de 36 lecturas. Pero quizás en lugar de hablar en estos términos deberíamos simplemente reconocer que lo que estamos haciendo es organizar un muestreo dentro del estudio (lo que genera algo de variación aleatoria), para obtener el dato de la variable de respuesta en el experimento, que es distinto a lo usual de hacer una “cosecha total”, que es la práctica ideal (pues evita introducir una fuente de “ruido” adicional).\nEl modelo lineal mixto puede escribirse como:\n\\[\ny_{ijk\\ell} = \\mu + T_i + \\delta_{j(i)} + \\phi_{k(ij)} + \\varepsilon_{ijk\\ell}\n\\]\ndonde:\n\n\\(y_{ijk\\ell}\\) = contenido de glucógeno medido en la medición \\(\\ell\\) de la muestra \\(k\\) del hígado de la rata \\(j\\) bajo dieta \\(i\\).\n\n\\(\\mu\\) = media general.\n\n\\(T_i\\) = efecto fijo de la dieta \\(i\\).\n\n\\(\\delta_{j(i)}\\) = efecto aleatorio de la rata \\(j\\) anidada en dieta \\(i\\), con\n\\[\n\\delta_{j(i)} \\sim N(0, \\sigma^2_\\delta)\n\\]\n\n\\(\\phi_{k(ij)}\\) = efecto aleatorio de la muestra de hígado \\(k\\) dentro de la rata \\(j\\) bajo dieta \\(i\\), con\n\\[\n\\phi_{k(ij)} \\sim N(0, \\sigma^2_\\phi)\n\\]\n\n\\(\\varepsilon_{ijk\\ell}\\) = error residual de la medición \\(\\ell\\), con\n\\[\n\\varepsilon_{ijk\\ell} \\sim N(0, \\sigma^2_\\varepsilon)\n\\]\n\nDatos del experimento\n\n\nCódigo\nratas_g &lt;- read.table(\"hígados-rata.DAT\", col.names = \"glucogeno\")\nratas_g$tratamiento &lt;- factor(rep(c(\"t1\",\"t2\",\"t3\"),each = 12))\nratas_g$rata &lt;- factor(rep(paste(\"r\", 1:6, sep = \"\"), each = 6))\nratas_g$muestraH &lt;- factor(rep(c(\"m1\", \"m2\", \"m3\"), times = 6, each = 2))\n\n\nLe doy estructura de grupos a la tabla\n\n\nCódigo\nratas_g &lt;- groupedData(glucogeno ~  1 | ordered(rata) / muestraH,\n                       data = ratas_g,\n                       labels = list(x = \"rata\", y = \"contenido de glucógeno\" ),\n                       FUN = mean)\nstr(ratas_g)\n\n\nClasses 'nmGroupedData', 'groupedData' and 'data.frame':    36 obs. of  4 variables:\n $ glucogeno  : int  131 130 131 125 136 142 150 148 140 143 ...\n $ tratamiento: Factor w/ 3 levels \"t1\",\"t2\",\"t3\": 1 1 1 1 1 1 1 1 1 1 ...\n $ rata       : Factor w/ 6 levels \"r1\",\"r2\",\"r3\",..: 1 1 1 1 1 1 2 2 2 2 ...\n $ muestraH   : Factor w/ 3 levels \"m1\",\"m2\",\"m3\": 1 1 2 2 3 3 1 1 2 2 ...\n - attr(*, \"formula\")=Class 'formula'  language glucogeno ~ 1 | ordered(rata)/muestraH\n  .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n - attr(*, \"formulaList\")=List of 2\n  ..$ ordered(rata):Class 'formula'  language ~ordered(rata)\n  .. .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n  ..$ muestraH     :Class 'formula'  language ~muestraH\n  .. .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n - attr(*, \"labels\")=List of 2\n  ..$ x: chr \"rata\"\n  ..$ y: chr \"contenido de glucógeno\"\n - attr(*, \"order.groups\")=List of 2\n  ..$ ordered(rata): logi TRUE\n  ..$ muestraH     : logi TRUE\n - attr(*, \"FUN\")=function (x, ...)  \n\n\n\nExploración de los datos\nAprovechando las opciones de estructura de grupos puedo obtener resúmenes exploratorios de manera muy simple.\n\n\nCódigo\ndata.frame(promedio = tapply(ratas_g$glucogeno, ratas_g$rata, function(x) round(mean(x), 2)))\n\n\n   promedio\nr1   132.50\nr2   148.50\nr3   149.67\nr4   152.33\nr5   134.33\nr6   136.00\n\n\nGraficación de los datos aprovechando la estructura agrupada que hemos adoptado.\n\n\nCódigo\nratas_g &lt;- ratas_g |&gt;\n  mutate(r_m = paste0(rata,\"/\", muestraH)) |&gt;\n  arrange(r_m) |&gt;\n  mutate(r_m = ordered(r_m))\n\n\nggplot(ratas_g, aes(x = glucogeno, y = r_m)) + \n       geom_point(shape = 19, size = 2, color = \"blue\") +\n       scale_y_discrete(limits = rev) +\n       labs(title = \"Análisis de efecto de dieta en glucógeno\") +\n       xlab(label = \"glucógeno\") +\n       ylab(label = \"rata/muestra\") +\n       theme(text = element_text(size = 18), \n             axis.text.x = element_text(angle = 0, hjust = 1)) \n\n\n\n\n\n\n\n\n\n\n\nCódigo\nggplot(ratas_g, aes(x = tratamiento, y = glucogeno)) + \n       stat_boxplot(geom = 'errorbar', linetype = 2, width = 0.5) + \n       geom_boxplot(shape = 19, size = 0.5, color = \"blue\", notch = TRUE) \n\n\nNotch went outside hinges\nℹ Do you want `notch = FALSE`?\nNotch went outside hinges\nℹ Do you want `notch = FALSE`?\nNotch went outside hinges\nℹ Do you want `notch = FALSE`?\n\n\n\n\n\n\n\n\n\n\n\nModelación\nVeamos el enfoque con un modelo lineal de efectos mixtos."
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#cual-es-la-estructura-fija-me-puedes-decir-cuál-es-la-ecuación-correspondiente",
    "href": "posts/08-modelos-mixtos/index.html#cual-es-la-estructura-fija-me-puedes-decir-cuál-es-la-ecuación-correspondiente",
    "title": "Modelos de Efectos Mixtos",
    "section": "¿Cual es la estructura fija?, me puedes decir cuál es la ecuación correspondiente",
    "text": "¿Cual es la estructura fija?, me puedes decir cuál es la ecuación correspondiente"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#modelo-de-efectos-mixtos-lme",
    "href": "posts/08-modelos-mixtos/index.html#modelo-de-efectos-mixtos-lme",
    "title": "Modelos de Efectos Mixtos",
    "section": "Modelo de efectos mixtos: lme",
    "text": "Modelo de efectos mixtos: lme\n\n\nCódigo\nratas.lme4.ic &lt;- predict(ratas.lme.m4, level = 0, type = \"predict\")\n\n\n\n\nCódigo\nratas.lme4.ic  &lt;- data.frame(ajustado = as.numeric(ratas.lme4.ic), \n                             tratamiento = ratas_g$tratamiento)\n\n\n\n\nCódigo\nintervals(ratas.lme.m4)$fixed\n\n\n                   lower       est.      upper\n(Intercept)   133.507297 140.500000 147.492703\ntratamientot2  -4.479979  10.500000  25.479979\ntratamientot3 -20.313312  -5.333333   9.646646\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\n\nModelo de regresión convencional: lm\n\n\nCódigo\nratas.lm.ic &lt;- as.data.frame(predict(ratas.completo.lm, interval = 'confidence',\n                                     conf.level = 0.95, ci.fit = TRUE))\n\n\n\n\nCódigo\nratas.lm.ic$tratamiento &lt;- ratas_g$tratamiento\n\n\n\n\nCódigo\ndata.frame(min = tapply(ratas.lm.ic$lwr, ratas.lm.ic$tratamiento, mean),\n           media = tapply(ratas.lm.ic$fit, ratas.lm.ic$tratamiento, mean),\n           max = tapply(ratas.lm.ic$upr, ratas.lm.ic$tratamiento, mean))\n\n\n        min    media      max\nt1 133.6653 140.5000 147.3347\nt2 144.1653 151.0000 157.8347\nt3 128.3319 135.1667 142.0014\n\n\nBueno, veamos los residuos!!! Lo primero es recuperar lo necesario del modelo, con la función residuals\n\n\nCódigo\ndf &lt;- data.frame( resid = residuals(ratas.lme.m4, type = \"pearson\"), \n                  tratamiento = ratas_g$tratamiento, \n                  rata = ratas_g$rata ) \n\n# Gráfica de cajas de residuos por factor (ej. Sexo) \n\nggplot(df, aes(x = resid, y = rata)) + \n  geom_boxplot(fill = \"skyblue\", alpha = 0.6) + \n  facet_wrap(~ tratamiento) +\n  labs(title = \"Residuos del modelo lme para rata/tratamientos\", \n       y = \"rata\", \n       x = \"Residuos (Pearson)\") +\n  theme_gray()\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nplot(ratas.lme.m4)\n\n\n\n\n\n\n\n\n\n\n\nComparaciones múltiples\nVeamos qué está pasando con los efectos de los tratamientos una vez que hemos resuelto con la prueba ómnibus que hay algún efecto de tratamiento.\nEl modelo completo, ¿cambia significativamente al recodifcar los tratamientos de manera que supongamos que el t1 no difiere del t2? Esto equivale a comparar los dos modelos respectivos.\n\n\nCódigo\nlibrary(tidyverse, warn.conflicts = FALSE)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ lubridate 1.9.4     ✔ tibble    3.3.1\n✔ purrr     1.2.1     ✔ tidyr     1.3.2\n✔ readr     2.1.6     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ nlme::collapse() masks dplyr::collapse()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCódigo\nratas_g$trat_v1 &lt;- recode_factor(ratas_g$tratamiento, \"t2\" = \"t1\")\nratas.lme.m4A &lt;- lme(fixed = glucogeno ~ trat_v1,\n                     random = ~ 1 | rata / muestraH, method = \"ML\",\n                     data = ratas_g) \n\nratas_g$trat_v2 &lt;- recode_factor(ratas_g$tratamiento, \"t3\" = \"t2\")\nratas.lme.m4B &lt;- lme(fixed = glucogeno ~ trat_v2,\n                     random = ~ 1 | rata / muestraH, method = \"ML\", \n                     data = ratas_g) \n\nratas_g$trat_v3 &lt;- recode_factor(ratas_g$tratamiento, \"t3\" = \"t1\")\nratas.lme.m4C &lt;- lme(fixed = glucogeno ~ trat_v3,\n                     random = ~ 1 | rata / muestraH, method = \"ML\", \n                     data = ratas_g) \nhead(ratas_g)\n\n\nGrouped Data: glucogeno ~ 1 | ordered(rata)/muestraH\n  glucogeno tratamiento rata muestraH   r_m trat_v1 trat_v2 trat_v3\n1       131          t1   r1       m1 r1/m1      t1      t1      t1\n2       130          t1   r1       m1 r1/m1      t1      t1      t1\n3       131          t1   r1       m2 r1/m2      t1      t1      t1\n4       125          t1   r1       m2 r1/m2      t1      t1      t1\n5       136          t1   r1       m3 r1/m3      t1      t1      t1\n6       142          t1   r1       m3 r1/m3      t1      t1      t1\n\n\n¿Qué sugieren estos resultados estadísticos?\n\n\nCódigo\nanova(ratas.lme.m4A, ratas.lme.m4)\n\n\n              Model df      AIC      BIC    logLik   Test L.Ratio p-value\nratas.lme.m4A     1  5 246.8941 254.8117 -118.4471                       \nratas.lme.m4      2  6 245.2705 254.7716 -116.6353 1 vs 2 3.62358   0.057\n\n\nPreguntémonos lo mismo respecto de los tratamientos t2 y t3. Veamos lo que resulta al comparar los modelos\n\n\nCódigo\nanova(ratas.lme.m4B, ratas.lme.m4)\n\n\n              Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nratas.lme.m4B     1  5 249.6292 257.5467 -119.8146                        \nratas.lme.m4      2  6 245.2705 254.7716 -116.6353 1 vs 2 6.358622  0.0117\n\n\nAhora los tratamientos t1 y t3. ¿qué resulta al comparar los modelos?\n\n\nCódigo\nanova(ratas.lme.m4C, ratas.lme.m4)\n\n\n              Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nratas.lme.m4C     1  5 244.4339 252.3514 -117.2169                        \nratas.lme.m4      2  6 245.2705 254.7716 -116.6353 1 vs 2 1.163313  0.2808\n\n\n\n##¿Qué decisión tomarás?\n\n\nCódigo\nanova(ratas.lme.m4C)\n\n\n            numDF denDF  F-value p-value\n(Intercept)     1    18 4261.316  &lt;.0001\ntrat_v3         1     4    8.116  0.0464\n\n\n\n\nCódigo\nintervals(ratas.lme.m4)$fixed\n\n\n                   lower       est.      upper\n(Intercept)   133.507297 140.500000 147.492703\ntratamientot2  -4.479979  10.500000  25.479979\ntratamientot3 -20.313312  -5.333333   9.646646\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\n\nQuizás es más interesante ver los resultados en términos de los valores estimados para cada tratamiento, en lugar de sobre sus diferencias.\n\n\nCódigo\nt(data.frame(trat_1 = intervals(ratas.lme.m4)$fixed[1,],\n             trat_2 = colSums(intervals(ratas.lme.m4)$fixed[1:2,]),\n             trat_3 = colSums(intervals(ratas.lme.m4)$fixed[1:3,])))\n\n\n          lower     est.    upper\ntrat_1 133.5073 140.5000 147.4927\ntrat_2 129.0273 151.0000 172.9727\ntrat_3 108.7140 145.6667 182.6193\n\n\nSi optáramos por tomar al modelo C como nuestro modelo mínimo adecuado para describir el experimento de glucógeno, los resultados se verían así:\n\n\nCódigo\nanova(ratas.lme.m4C)\n\n\n            numDF denDF  F-value p-value\n(Intercept)     1    18 4261.316  &lt;.0001\ntrat_v3         1     4    8.116  0.0464\n\n\nEste modelo sugiere que es posible argumentar que el tratamiento combinando t1 y t3 difiere en forma apreciable o significativa con respecto del t2. Esto se aprecia al considerar los valores promedio de los tratamientos, pero no es realmente muy evidente. La forma como estoy calculando los valores tiene que considerar el tipo de reparametrización y la configuración del modelo, no olvides eso.\n\n\nCódigo\nnivel_confianza &lt;- 0.90\nt(data.frame(trat_1 = intervals(ratas.lme.m4, level = nivel_confianza)$fixed[1,],\n             trat_2 = colSums(intervals(ratas.lme.m4, level = nivel_confianza)$fixed[1:2,]),\n                 trat_3 = colSums(intervals(ratas.lme.m4, level = nivel_confianza)$fixed[1:3,])))\n\n\n          lower     est.    upper\ntrat_1 134.7283 140.5000 146.2717\ntrat_2 134.1509 151.0000 167.8491\ntrat_3 117.7401 145.6667 173.5932\n\n\n\n\nCódigo\nt(data.frame(trat_1_y_3 = intervals(ratas.lme.m4C, level = nivel_confianza)$fixed[1,],\n             trat_2 = colSums(intervals(ratas.lme.m4C, level = nivel_confianza)$fixed[1:2,])))\n\n\n              lower     est.    upper\ntrat_1_y_3 133.3366 137.8333 142.3300\ntrat_2     136.9281 151.0000 165.0719"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#respuesta-de-cultivares-a-fertilizantes",
    "href": "posts/05-dis-comp-aleat/index.html#respuesta-de-cultivares-a-fertilizantes",
    "title": "Experimentos completamente aleatorizados",
    "section": "Respuesta de Cultivares a fertilizantes",
    "text": "Respuesta de Cultivares a fertilizantes\nEjemplo tomado de Crawley (1998). Glim for Ecologists. Oxford. UK.\nEs un experimento en el que se midió el crecimiento (masa seca al cosechar = y) de plantas tratadas con 10 concentraciones diferentes de suplemento mineral como fertilizante, f. El experimento fue realizado con dos cultivares diferentes, g. Uno fue clonado de plantas de un ambiente árido y el otro de uno húmedo. Todas las plantas de cada tipo, sin restricciones, fueron asignadas aleatoriamente a los distintos niveles de fertilizante.\n\nLectura de datos\n\n\nCódigo\nlibrary(stringr)\n\nurl_fert &lt;- \"https://drive.google.com/file/d/1_545rzA2TMIB5XPFHhwNzoHl3A8SigMT/view?usp=drive_link\"\ndat_fert_id &lt;- str_extract(url_fert, \"(?&lt;=d/)(.*)(?=/view)\")\n\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \nfert_dat &lt;- read.csv(sprintf(url_drive, dat_fert_id), \n                  col.names=c(\"fertilizante\", \"rendimiento_peso\")) \n\nhead(fert_dat)\n\n\n  fertilizante rendimiento_peso\n1            1           2.8215\n2            2           2.3590\n3            3           3.0912\n4            4           2.5297\n5            5           3.4753\n6            6           3.6493\n\n\nA veces hay archivos que contienen datos faltantes o perdidos. Podemos enfrentar eso con la función complete.cases() que revisa linea por linea el archivo y regresa “verdadero” si todas las columnas tienen datos válidos y “falso” si hay huecos. Esta lista de “verdaderos” y “falsos” la podemos usar para elegir que filas del archivo de datos están completas y así podemos eliminarlas del conjunto de datos que vamos a procesar.\nSobre los datos limpios, generamos la variable indicativa del tipo de ambiente del que se tomo la planta que se clonó.\n\n\nCódigo\n# En caso de que haya datos extra, elimino registros leidos como datos erróneos\nfert_dat &lt;- fert_dat[complete.cases(fert_dat), ]\n\n\n\n\nGenera los factores genotipo y fertilizante\n\n\nCódigo\nfert_dat$cultivar &lt;- factor(rep(c(\"seco\",\"humedo\"), each=10))\nfert_dat$fertilizante &lt;- factor(fert_dat$fertilizante) \n\nhead(fert_dat)\n\n\n  fertilizante rendimiento_peso cultivar\n1            1           2.8215     seco\n2            2           2.3590     seco\n3            3           3.0912     seco\n4            4           2.5297     seco\n5            5           3.4753     seco\n6            6           3.6493     seco\n\n\n\n\ngráfica de masa seca contra fertilizante mineral - sin diferenciar tratamientos\nVeamos los datos en una gráfica simple. La función plot hace cosas distintas según el tipo de datos que le demos. Para generar la gráfica simple que queremos aquí, conviene que los valores de fertilizante sean interpretados como valores numéricos. Esto lo logramos con la funnción as.numeric\n\n\nCódigo\nplot(as.numeric(fert_dat$fertilizante), fert_dat$rendimiento_peso, xlab=\"fertilizante\", ylab=\"biomasa\", type=\"p\")\n\n\n\n\n\n\n\n\n\nPara explorar mejor los datos podemos marcar en la gráfica las obsevaciones que pertenecen a cada condición. En este caso, te propongo poner el nombre que le dimos al “tratamiento”.\nGráfica de masa seca contra fertilizante mineral diferenciando por genotipos\n\n\nCódigo\nplot(as.numeric(fert_dat$fertilizante), \n     fert_dat$rendimiento_peso, xlab=\"fertilizante\", ylab=\"biomasa\", type=\"n\")\ntext (fert_dat$fertilizante, fert_dat$rendimiento_peso, labels=fert_dat$cultivar)\n\n\n\n\n\n\n\n\n\nPodemos ver las características estadísticas de lo que pasa con la biomasa que produce cada genotipo\n\n\nResumen de los datos de masa por genotipo\n\n\nCódigo\nby (fert_dat, fert_dat$cultivar, summary)\n\n\nfert_dat$cultivar: humedo\n  fertilizante rendimiento_peso   cultivar \n 1      :1     Min.   : 4.405   humedo:10  \n 2      :1     1st Qu.: 5.617   seco  : 0  \n 3      :1     Median : 8.592              \n 4      :1     Mean   : 8.716              \n 5      :1     3rd Qu.:10.977              \n 6      :1     Max.   :14.502              \n (Other):4                                 \n------------------------------------------------------------ \nfert_dat$cultivar: seco\n  fertilizante rendimiento_peso   cultivar \n 1      :1     Min.   : 2.359   humedo: 0  \n 2      :1     1st Qu.: 2.889   seco  :10  \n 3      :1     Median : 3.562              \n 4      :1     Mean   : 4.866              \n 5      :1     3rd Qu.: 6.355              \n 6      :1     Max.   :10.130              \n (Other):4                                 \n\n\nAhora podemos realizar el análisis estadístico mediante modelos. Hagamos un análisis con el enfoque “tradicional” en R. Lo primero que haremos es configurar el entorno de análisis, esto significa elegir el tipo de contrastes que queremos operar al ajustar modelos reparametrizados. Haremos esto con opción contrasts en la función options(contrasts=...)\nPara asegurarnos de que los estimadores del modelo toman el primer nivel como referencia hay que usar el modo de reparametrización “treatment”. Hay otras formas de reparametrización, como podrás ver en la ayuda de contr.treatment.\n\n\nCódigo\noptions(contrasts=c(\"contr.treatment\", \"contr.poly\"))\n\n\n\n\najusta modelo nulo - sólo la media\n\n\nCódigo\naj1 &lt;- lm (rendimiento_peso ~ 1, data = fert_dat)\nsummary(aj1)\n\n\n\nCall:\nlm(formula = rendimiento_peso ~ 1, data = fert_dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-4.432 -3.185 -1.006  2.555  7.711 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   6.7912     0.8067   8.419 7.79e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.608 on 19 degrees of freedom\n\n\n\n\nCódigo\n# Agregamos el efecto del fertilizante\naj2 &lt;- update(aj1, .~ . + fertilizante)\nanova(aj2)\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n             Df Sum Sq Mean Sq F value Pr(&gt;F)\nfertilizante  9 142.75  15.861  1.5174 0.2622\nResiduals    10 104.53  10.453               \n\n\nNótese que el número de niveles de fertilizante es 10, así que los grados de libertad son 10-1=9. De modo semejante el número de observaciones es 20, así que los grados de libertad del residuo descuenta los grados de libertad del fertilizante y 1 (por la estimación de la media general): 20 - 9 - 1 = 10\n\n\nCódigo\n# agregamos el cultivar\naj3 &lt;- update(aj2,  .~ . + cultivar)\nanova(aj3)\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n             Df  Sum Sq Mean Sq F value   Pr(&gt;F)   \nfertilizante  9 142.747  15.861  4.6953 0.015392 * \ncultivar      1  74.125  74.125 21.9434 0.001145 **\nResiduals     9  30.402   3.378                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPodemos intentar hacer un modelo completo, es decir con todos los posibles factores y combinaciones que pueden producirse. Sin embargo este modelo consume todos los grados de liberta (observaciones) con que contamos pues cada tratamiento fue ensayado una sola vez en este experimento. De todos modos lo podemos intentar para ver que nos dice R.\n\n\nCódigo\n# agregamos una pendiente diferente para cada genotipo\naj4 &lt;- update(aj3,  .~ . + cultivar:fertilizante)\nanova(aj4)\n\n\nWarning in anova.lm(aj4): ANOVA F-tests on an essentially perfect fit are\nunreliable\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n                      Df  Sum Sq Mean Sq F value Pr(&gt;F)\nfertilizante           9 142.747  15.861     NaN    NaN\ncultivar               1  74.125  74.125     NaN    NaN\nfertilizante:cultivar  9  30.402   3.378     NaN    NaN\nResiduals              0   0.000     NaN               \n\n\nLa secuencia de ajustes produce estos cambios en devianza\n\n\nCódigo\nanova(aj1, aj2, aj3)\n\n\nAnalysis of Variance Table\n\nModel 1: rendimiento_peso ~ 1\nModel 2: rendimiento_peso ~ fertilizante\nModel 3: rendimiento_peso ~ fertilizante + cultivar\n  Res.Df     RSS Df Sum of Sq       F   Pr(&gt;F)   \n1     19 247.274                                 \n2     10 104.527  9   142.747  4.6953 0.015392 * \n3      9  30.402  1    74.125 21.9434 0.001145 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nModelo mínimo adecuado\nestos resultados sugieren que el modelo 3 es mínimo adecuado resumen del modelo mínimo adecuado\n\n\nCódigo\nsummary(aj3)\n\n\n\nCall:\nlm(formula = rendimiento_peso ~ fertilizante + cultivar, data = fert_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6653 -0.7855  0.0000  0.7855  2.6653 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)      5.9538     1.3630   4.368  0.00180 **\nfertilizante2   -0.1251     1.8379  -0.068  0.94720   \nfertilizante3    0.5784     1.8379   0.315  0.76014   \nfertilizante4   -0.5615     1.8379  -0.305  0.76695   \nfertilizante5    3.1205     1.8379   1.698  0.12376   \nfertilizante6    2.3382     1.8379   1.272  0.23518   \nfertilizante7    3.3713     1.8379   1.834  0.09981 . \nfertilizante8    5.7776     1.8379   3.144  0.01186 * \nfertilizante9    5.8829     1.8379   3.201  0.01082 * \nfertilizante10   7.2434     1.8379   3.941  0.00340 **\ncultivarseco    -3.8503     0.8219  -4.684  0.00115 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.838 on 9 degrees of freedom\nMultiple R-squared:  0.8771,    Adjusted R-squared:  0.7404 \nF-statistic:  6.42 on 10 and 9 DF,  p-value: 0.004992\n\n\nComo un ejercicio haz el cálculo de los valores de y, a parir de los valores estimados por el modelo. Lo puedes hacer a mano, con ayuda de una calculadora del super, en Excel o equivalente, o quizás con ayuda de R mismo. En este último caso te doy como pista la función coef, con la que tendrás acceso a los coeficientes del modelo.\n¿Podrías escribir un programa/función en R para calcular los valores esperados?\nPara comprender con exactitud que es lo que hace exactamente R al ajustar un modelo de regresión o ANDEVA como este, podemos usar la función model.matrix() aplicada al modelo que nos interese analizar. En este caso lo ejemplificaré con el modelo mínimo adecuado aj3. Así podemos ver en acción el uso de las formas de reparametrización\n\n\nCódigo\nmodel.matrix(aj3)\n\n\n   (Intercept) fertilizante2 fertilizante3 fertilizante4 fertilizante5\n1            1             0             0             0             0\n2            1             1             0             0             0\n3            1             0             1             0             0\n4            1             0             0             1             0\n5            1             0             0             0             1\n6            1             0             0             0             0\n7            1             0             0             0             0\n8            1             0             0             0             0\n9            1             0             0             0             0\n10           1             0             0             0             0\n11           1             0             0             0             0\n12           1             1             0             0             0\n13           1             0             1             0             0\n14           1             0             0             1             0\n15           1             0             0             0             1\n16           1             0             0             0             0\n17           1             0             0             0             0\n18           1             0             0             0             0\n19           1             0             0             0             0\n20           1             0             0             0             0\n   fertilizante6 fertilizante7 fertilizante8 fertilizante9 fertilizante10\n1              0             0             0             0              0\n2              0             0             0             0              0\n3              0             0             0             0              0\n4              0             0             0             0              0\n5              0             0             0             0              0\n6              1             0             0             0              0\n7              0             1             0             0              0\n8              0             0             1             0              0\n9              0             0             0             1              0\n10             0             0             0             0              1\n11             0             0             0             0              0\n12             0             0             0             0              0\n13             0             0             0             0              0\n14             0             0             0             0              0\n15             0             0             0             0              0\n16             1             0             0             0              0\n17             0             1             0             0              0\n18             0             0             1             0              0\n19             0             0             0             1              0\n20             0             0             0             0              1\n   cultivarseco\n1             1\n2             1\n3             1\n4             1\n5             1\n6             1\n7             1\n8             1\n9             1\n10            1\n11            0\n12            0\n13            0\n14            0\n15            0\n16            0\n17            0\n18            0\n19            0\n20            0\nattr(,\"assign\")\n [1] 0 1 1 1 1 1 1 1 1 1 2\nattr(,\"contrasts\")\nattr(,\"contrasts\")$fertilizante\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$cultivar\n[1] \"contr.treatment\"\n\n\n\n\nIntervalos de confianza\nComo hemos visto. La valoración del modelos mínimo adecuado es una declaración de una posible hipótesis alternativa, la más cercana a la muestra que, en esta ocasión obtuvimos. Sin embargo, no hay garantía de ningún tipo de que en otra oportunidad los estimadores serán los mismos. Esto es un recordatorio de que la famosa p nos es en lo que debemos centrar nuestras esperanzas. El asunto es la reflexión sobre las hipótesis alternativas, es decir, las que realmente interesan al investigador y ojalá haga los más explícitas posibles. Una manera de ver el ámbito de estados alternativos del sistema la tenemos cuando visualizamos los intervalos de confianza que nuestro modelo mínimo adecuado produce. En el sitio RPub pueden encontrar ayuda para utilizar R en el análisis de sus datos, aquí encontraran un texto sobre intervalos de confianza. No deja de ser un ejercicio exploratorio y algo subjetivo, pero también potencialmente productivo para acercarnos a comprender mejor el comportamiento del sistema de nuestro interés.\nUn primer conjunto de intervalos de confianza son los asociados con los parámetros del modelo, es decir, la gama de valores de los coeficientes de regresión que podríamos esperar tener en el ajuste del modelo. A continuación les muestro como podemos obtener, con la función confint estos intervalos en R.\n¿Como interpretas estos valores\n\n\nCódigo\nconfint(aj3, level = 0.95)\n\n\n                    2.5 %    97.5 %\n(Intercept)     2.8703275  9.037193\nfertilizante2  -4.2828496  4.032550\nfertilizante3  -3.5792496  4.736150\nfertilizante4  -4.7191496  3.596250\nfertilizante5  -1.0371496  7.278250\nfertilizante6  -1.8194496  6.495950\nfertilizante7  -0.7863496  7.529050\nfertilizante8   1.6199004  9.935300\nfertilizante9   1.7252004 10.040600\nfertilizante10  3.0857004 11.401100\ncultivarseco   -5.7096998 -1.990940\n\n\nOtro intervalo de confianza de interés es el que podemos asociar con lo que puede predecir el modelo. En R este intervalo de confianza lo podemos obtener así:\n\n\nCódigo\npredict(aj3, interval = \"confidence\", level = 0.95)\n\n\n        fit        lwr       upr\n1   2.10344 -0.9799925  5.186873\n2   1.97829 -1.1051425  5.061723\n3   2.68189 -0.4015425  5.765323\n4   1.54199 -1.5414425  4.625423\n5   5.22399  2.1405575  8.307423\n6   4.44169  1.3582575  7.525123\n7   5.47479  2.3913575  8.558223\n8   7.88104  4.7976075 10.964473\n9   7.98634  4.9029075 11.069773\n10  9.34684  6.2634075 12.430273\n11  5.95376  2.8703275  9.037193\n12  5.82861  2.7451775  8.912043\n13  6.53221  3.4487775  9.615643\n14  5.39231  2.3088775  8.475743\n15  9.07431  5.9908775 12.157743\n16  8.29201  5.2085775 11.375443\n17  9.32511  6.2416775 12.408543\n18 11.73136  8.6479275 14.814793\n19 11.83666  8.7532275 14.920093\n20 13.19716 10.1137275 16.280593\n\n\n¿Qué muestran estos valores?\n¿Qé se te ocurre para utilizar en tu reporte de resultados este tipo de intervalos de confianza?\n\n\ncrítica al modelo y recursos diagnósticos\n\n\nCódigo\nplot(aj3)"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#lectura-de-datos-1",
    "href": "posts/05-dis-comp-aleat/index.html#lectura-de-datos-1",
    "title": "Experimentos completamente aleatorizados",
    "section": "Lectura de datos",
    "text": "Lectura de datos\n\n\nCódigo\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ purrr     1.2.1\n✔ forcats   1.0.1     ✔ readr     2.1.6\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCódigo\n#alcal_dat_xls &lt;- read_excel(\"alcal_dat.xlsx\", skip = 0, col_names = TRUE)\n\n\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \nurl_prot &lt;- \"https://drive.google.com/file/d/1b-1binYTUJotvPWX9sCnImwxPctumezn/view?usp=sharing\"\ndat_alcal_id &lt;- str_extract(url_prot, \"(?&lt;=d/)(.*)(?=/view)\")\nalcal_dat &lt;- read.csv(sprintf(url_drive, dat_alcal_id)) \n\n\n#alcal_dat &lt;- read_excel(\"alcal_dat.xlsx\",\n#    col_types = c(\"numeric\", \"numeric\", \"numeric\"),\n#    col_names = TRUE)"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#definición-de-los-factores",
    "href": "posts/05-dis-comp-aleat/index.html#definición-de-los-factores",
    "title": "Experimentos completamente aleatorizados",
    "section": "Definición de los factores",
    "text": "Definición de los factores\nLos datos contienen información cualitativa, así que necesitamos definir esas piezas de información como factores. Aprovecharemos para experimentar con los factores de tipo “ordenado”. Esta variante de factor aprovecha el contenido seminumérico que pudiéramos tener en alguna variable. En este caso lo haremos así para el contenido de proteína.\n\n\nCódigo\n# Uso la función \"ordered\" que genera factores ordenados, \n# útil para aprovechar datos \"semicuantitativos\" y probar polinomios\n\n# Enfoque antiguo con data.frame\n#alcal_dat$proteina &lt;- ordered(alcal_dat$proteina, c(1,2,3), \n#                           c(\"bajo\", \"medio\", \"alto\"))\n#\n#alcal_dat$alcaloide &lt;-factor(alcal_dat$alcaloide, c(1,2), c(\"ausente\", \"presente\"))\n#\n\n# Enfoque actual con tibble\nalcal_dat &lt;- alcal_dat %&gt;% mutate(proteina = ordered(proteina, c(1,2,3), \n                                     c(\"bajo\", \"medio\", \"alto\")),\n                  alcaloide = factor(alcaloide, c(1,2), \n                                      c(\"ausente\", \"presente\")))"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#exploración-de-medias",
    "href": "posts/05-dis-comp-aleat/index.html#exploración-de-medias",
    "title": "Experimentos completamente aleatorizados",
    "section": "exploración de medias",
    "text": "exploración de medias\nSiempre es conveniente hacer una revisión previa de los datos y considerar los patrones que apreciamos en ellos como fuente de ideas o simplemente para verificar que no haya errores de algún tipo.\n\n\nCódigo\n#\n# Enfoque antiguo con data.frame\n# Para simplificar el acceso a los datos uso la función attach\n#attach(alcal_dat)\n#aggregate(list(talla=talla), list(proteina=proteina), mean)\n#aggregate(list(talla=talla), list(alcaloide=alcaloide),mean)\n#tapply(talla, list(proteina, alcaloide), mean)\n\n# Con un tibble es más práctico hacer esto\nalcal_dat %&gt;% group_by(proteina) %&gt;%\n           summarize(promedio = mean(talla, na.rm=TRUE))\n\n\n# A tibble: 3 × 2\n  proteina promedio\n  &lt;ord&gt;       &lt;dbl&gt;\n1 bajo         5.5 \n2 medio        5.25\n3 alto         4.25\n\n\nCódigo\nalcal_dat %&gt;% group_by(alcaloide) %&gt;%\n           summarize(promedio = mean(talla, na.rm=TRUE))\n\n\n# A tibble: 2 × 2\n  alcaloide promedio\n  &lt;fct&gt;        &lt;dbl&gt;\n1 ausente        4.5\n2 presente       5.5\n\n\nCódigo\n# Genero una table resumen de promedios. \n# alcal_dat.res&lt;-aggregate(list(talla=alcal_dat$talla), \n#                      list(proteina=alcal_dat$proteina,\n#                           alcaloide=alcal_dat$alcaloide), mean)\n\nalcal_dat %&gt;% group_by(proteina, alcaloide) %&gt;%\n           summarize(promedio = mean(talla, na.rm=TRUE)) %&gt;%\n           pivot_wider(names_from = proteina, values_from = promedio)\n\n\n`summarise()` has grouped output by 'proteina'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 4\n  alcaloide  bajo medio  alto\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 ausente     4.5   3.5   5.5\n2 presente    6.5   7     3"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#exploración-de-varianzas",
    "href": "posts/05-dis-comp-aleat/index.html#exploración-de-varianzas",
    "title": "Experimentos completamente aleatorizados",
    "section": "Exploración de varianzas",
    "text": "Exploración de varianzas\n\n\nCódigo\n#aggregate(list(talla=alcal_dat$talla),\n#          list(proteina=alcal_dat$proteina),var) \nalcal_dat %&gt;% group_by(proteina) %&gt;%\n           summarize(var = var(talla, na.rm=TRUE))\n\n\n# A tibble: 3 × 2\n  proteina   var\n  &lt;ord&gt;    &lt;dbl&gt;\n1 bajo      2.57\n2 medio     4.5 \n3 alto      3.36\n\n\nCódigo\n#aggregate(list(talla=alcal_dat$talla), \n#          list(alcaloide=alcal_dat$alcaloide), var) \nalcal_dat %&gt;% group_by(alcaloide) %&gt;%\n           summarize(var = var(talla, na.rm=TRUE))\n\n\n# A tibble: 2 × 2\n  alcaloide   var\n  &lt;fct&gt;     &lt;dbl&gt;\n1 ausente    2.09\n2 presente   4.64\n\n\nCódigo\n# tapply(alcal_dat$talla, list(alcal_dat$proteina, alcal_dat$alcaloide), var)\nalcal_dat %&gt;% group_by(proteina, alcaloide) %&gt;%\n           summarize(var = var(talla, na.rm=TRUE)) %&gt;%\n           pivot_wider(names_from = proteina, values_from = var)\n\n\n`summarise()` has grouped output by 'proteina'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 4\n  alcaloide  bajo medio  alto\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 ausente    1.67 1.67   1.67\n2 presente   1.67 0.667  2"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#gráficas-exploratorias",
    "href": "posts/05-dis-comp-aleat/index.html#gráficas-exploratorias",
    "title": "Experimentos completamente aleatorizados",
    "section": "Gráficas exploratorias",
    "text": "Gráficas exploratorias\n\n\nCódigo\ninteraction.plot(alcal_dat$proteina, alcal_dat$alcaloide, alcal_dat$talla) \n\n\n\n\n\n\n\n\n\nCódigo\n#args(interaction.plot)"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#ajuste-de-modelos",
    "href": "posts/05-dis-comp-aleat/index.html#ajuste-de-modelos",
    "title": "Experimentos completamente aleatorizados",
    "section": "Ajuste de modelos",
    "text": "Ajuste de modelos\n\n\nCódigo\nlarvas.nulo &lt;- lm(talla ~ 1, data=alcal_dat)\n\n# defino una simple función que extrae devianza y df de un ajuste y lo despliga\n\n# mediante la función \"cat\"\n\ndevianza &lt;- function(x) \n  { cat(\"devianza=\", deviance(x), \"\\ndf=\",x$df.residual,\"\\n\")}\n\n# devianza del modelo nulo\n\ndevianza(larvas.nulo)\n\n\ndevianza= 80 \ndf= 23 \n\n\nCódigo\n# modelo completo\n\nlarvas.completo &lt;- update(larvas.nulo, . ~ . + proteina + alcaloide + proteina:alcaloide) \n\ndevianza(larvas.completo) \n\n\ndevianza= 28 \ndf= 18 \n\n\nCódigo\ncoefficients(larvas.completo)\n\n\n                 (Intercept)                   proteina.L \n                   4.5000000                    0.7071068 \n                  proteina.Q            alcaloidepresente \n                   1.2247449                    1.0000000 \nproteina.L:alcaloidepresente proteina.Q:alcaloidepresente \n                  -3.1819805                   -3.0618622 \n\n\n\nOtra forma de escribir el modelo completo\n\n\nCódigo\nlarvas.completo &lt;- update(larvas.nulo, . ~ . + proteina * alcaloide) \n\ndevianza(larvas.completo) \n\n\ndevianza= 28 \ndf= 18 \n\n\nCódigo\ncoefficients(larvas.completo)\n\n\n                 (Intercept)                   proteina.L \n                   4.5000000                    0.7071068 \n                  proteina.Q            alcaloidepresente \n                   1.2247449                    1.0000000 \nproteina.L:alcaloidepresente proteina.Q:alcaloidepresente \n                  -3.1819805                   -3.0618622 \n\n\n\n\n¿Significancia de los términos?\n\n\nCódigo\nanova(larvas.completo)\n\n\nAnalysis of Variance Table\n\nResponse: talla\n                   Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nproteina            2      7  3.5000  2.2500 0.1342177    \nalcaloide           1      6  6.0000  3.8571 0.0651695 .  \nproteina:alcaloide  2     39 19.5000 12.5357 0.0003888 ***\nResiduals          18     28  1.5556                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nComparaciones múltiples\nEsto es equivalente a una búsqueda, algo exploratoria, para dar respuesta a la pregunta: ¿Son necesarios todos los niveles de los factores?\n\n\nCódigo\nsummary(larvas.completo)\n\n\n\nCall:\nlm(formula = talla ~ proteina + alcaloide + proteina:alcaloide, \n    data = alcal_dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.500 -1.000  0.000  0.625  2.000 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    4.5000     0.3600  12.499 2.61e-10 ***\nproteina.L                     0.7071     0.6236   1.134  0.27172    \nproteina.Q                     1.2247     0.6236   1.964  0.06517 .  \nalcaloidepresente              1.0000     0.5092   1.964  0.06517 .  \nproteina.L:alcaloidepresente  -3.1820     0.8819  -3.608  0.00201 ** \nproteina.Q:alcaloidepresente  -3.0619     0.8819  -3.472  0.00272 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.247 on 18 degrees of freedom\nMultiple R-squared:   0.65, Adjusted R-squared:  0.5528 \nF-statistic: 6.686 on 5 and 18 DF,  p-value: 0.001103\n\n\nCódigo\n# Generación de un factor re-codificado: tomaré: bame = bajo y medio, alto=alto\n\n# Por supuesto hay que considerar que esta fusión tenga sentido biológico.\n\n# Así podemos recodificar el factor proteína.\n\nalcal_dat$proteinaBM &lt;- alcal_dat$proteina \nlevels(alcal_dat$proteinaBM) &lt;- c(\"bame\", \"bame\", \"alto\") # cuidar el orden\n\n\n\nnuevo ajuste de modelo completo con el factor proteina recodificado.\n\n\nCódigo\nlarvas.protBM &lt;- lm(talla ~ proteinaBM * alcaloide, data = alcal_dat) \n\nsummary(larvas.protBM)\n\n\n\nCall:\nlm(formula = talla ~ proteinaBM * alcaloide, data = alcal_dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n    -2     -1      0      1      2 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      4.7500     0.3781  12.562 6.03e-11 ***\nproteinaBM.L                     1.0607     0.5347   1.984   0.0612 .  \nalcaloidepresente                0.1250     0.5347   0.234   0.8175    \nproteinaBM.L:alcaloidepresente  -3.7123     0.7562  -4.909 8.47e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.235 on 20 degrees of freedom\nMultiple R-squared:  0.6188,    Adjusted R-squared:  0.5616 \nF-statistic: 10.82 on 3 and 20 DF,  p-value: 0.000194\n\n\n\n\n¿qué significancia tiene este cambio en el modelo?\n\n\nCódigo\nanova(larvas.protBM,larvas.completo) \n\n\nAnalysis of Variance Table\n\nModel 1: talla ~ proteinaBM * alcaloide\nModel 2: talla ~ proteina + alcaloide + proteina:alcaloide\n  Res.Df  RSS Df Sum of Sq      F Pr(&gt;F)\n1     20 30.5                           \n2     18 28.0  2       2.5 0.8036 0.4632\n\n\nCódigo\nplot(larvas.protBM) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ntapply(alcal_dat$talla, list(alcal_dat$proteinaBM, alcal_dat$alcaloide), mean) \n\n\n     ausente presente\nbame     4.0     6.75\nalto     5.5     3.00\n\n\nCódigo\nalcal_dat.resBM &lt;- aggregate(list(talla = alcal_dat$talla), \n                          list(proteinaBM= alcal_dat$proteinaBM, \n                               alcaloide = alcal_dat$alcaloide), mean)\n\ninteraction.plot(alcal_dat$proteinaBM, alcal_dat$alcaloide, alcal_dat$talla)"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#conclusiones",
    "href": "posts/05-dis-comp-aleat/index.html#conclusiones",
    "title": "Experimentos completamente aleatorizados",
    "section": "Conclusiones",
    "text": "Conclusiones\nCon base en estos análisis ¿Cual es el modelo mínimo adecuado?. ¿cómo podemos interpretar estos resultados? ¿tienen sentido o relevancia?"
  },
  {
    "objectID": "posts/04-diagramas-causales/index.html",
    "href": "posts/04-diagramas-causales/index.html",
    "title": "Diagramas Causales",
    "section": "",
    "text": "Judea Pearl se ha aproximado a la causalidad desde una perspectiva matemática y computacional. En ese camino retomó y dio un nuevo impulso a los llamados modelos probabilísticos gráficos en su variante de redes Bayesianas. También ha incursionado en los llamados modelos de ecuaciones estructuradas, también de la familia de los modelos gráficos. Todo ello vinculado con los Gráfos Acíclicos Dirigidos, a los que llamaremos DAG (del inglés directed acyclic graphs). Pearl y colaboradores así como otros investigadores ahora, han venido desarrollando la teoría que nos permite analizar tales DAGs para comprender los patrones de dependencia causal así como los de correlación que implica una proposición causal dada. En esta contribución buscamos mostrarles algunos elementos interesantes de esto y con ello, animarlos a estudiar estas ideas con mayor profundidad."
  },
  {
    "objectID": "posts/04-diagramas-causales/index.html#ejemplo-efectos-de-sesgo-en-las-causas",
    "href": "posts/04-diagramas-causales/index.html#ejemplo-efectos-de-sesgo-en-las-causas",
    "title": "Diagramas Causales",
    "section": "Ejemplo: Efectos de sesgo en las causas",
    "text": "Ejemplo: Efectos de sesgo en las causas\nEl ejemplo de simulación que haremos ahora parte de la proposición causal:\n\nEl aprendizaje (X) tiene como efecto el conocimiento (C), y conocer provoca la comprensión (Y),\n\nAdemás actúan algunos factores exógenos (U, son el término de error en el modelo estadístico). En la vida real, el aprendizaje, el conocimiento y la comprensión pueden ser operacionalizados por algún cuestionario y estandarizados para dar la precisión necesaria al análisis.\nEl ejemplo consiste ahora en producir un conjunto de datos que cumpla, por diseño, con la descripción que acabo de hacer. En este caso utilizaremos las ecuaciones siguientes.\n\\[\n\\begin{align}\nX &= U_{X}, \\, U_{X} \\sim N(0, 1) \\\\\nC &= 5 X + U_{C}, \\, U_{C} \\sim N(0, 1) \\\\\nY &= 3 C + U_{Y}, \\, U_{Y} \\sim N(0, 1)\n\\end{align}\n\\]\nen donde N(μ, σ) indica que existen variaciones por causas no observadas que vamos a suponer generan oscilaciones aleatorias o un ruido, cuya distribución es semejante a la que produciría una distribución Normal de probabilidades. Ahora escribimos estas ecuaciones en un escript de R.\n\nset.seed(1896) # Habilita Repetibilidad\nn &lt;- 1000 # Tamaño de muestra\n\naprender &lt;- rnorm(n)\nconocer &lt;- 5 * aprender + rnorm(n)  # Conocer depende del comportamiento de aprender\nentender &lt;- 3 * conocer + rnorm(n)  # entender depende del comportamiento de conocer\n\n# Para comodidad de cálculo junto los datos en una tabla, un \"data.frame\"\ndatos &lt;- data.frame(aprender, conocer, entender)\n\nEl DAG que describe la situación descrita lo podemos producir en R con ayuda de la biblioteca DAGitty. Con las instrucciones siguentes.\n\nlibrary(dagitty)\n\nejemplo_1_DAG &lt;- dagitty('dag{\n                     aprender -&gt; conocer\n                     conocer -&gt; entender\n\n                     aprender[exposure, pos=\"0,0\"]\n                     conocer[pos=\"1,0\"]\n                     entender[outcome, pos=\"2,0\"]}')\noptions(repr.plot.width=10, repr.plot.height=3)\npar(cex=2, lwd = 5)\nplot(ejemplo_1_DAG)\n\n\n\n\n\n\n\n\nSi optamos por no “corregir” la estimación por el efecto del mediador, Supondríamos que el efecto total del aprendizaje sobre el entendimiento no tiene sesgo. La estimación de esta relación la obtenemos con el modelo que calculamos en ejemplo_1_ecuación_1.\n\nejemplo_1_ecuacion_1 &lt;- lm(entender ~ aprender)\nsummary(ejemplo_1_ecuacion_1)$coefficients[,1:2]\n\n               Estimate Std. Error\n(Intercept) -0.02227676 0.09661146\naprender    15.12087585 0.09781602\n\n\n¿Qué piensas de este resultado? ¿El modelo es congruente con la proposición causal? Si ahora optamos por sí “corregir” los efectos considerando que el conocimiento puede estar interfiriendo la estimación del efecto total del aprendizaje sobre el entendimiento. Ahora, el modelo que da cuenta de esta nueva situación es el que calculamos en ejemplo_1_ecuación_2.\n\nejemplo_1_ecuacion_2 &lt;- lm(entender ~ aprender + conocer)\nsummary(ejemplo_1_ecuacion_2)$coefficients[,1:2]\n\n                Estimate Std. Error\n(Intercept) -0.004947807 0.03077153\naprender     0.121514701 0.16253665\nconocer      2.981736249 0.03171170\n\n\nLos resultados de esta exploración produce dos ecuaciones:\n\\[\n\\begin{align}\nX &= U_{X}, \\, U_{X} \\sim N(0, 1) \\\\\nC &= 5 X + U_{C}, \\, U_{C} \\sim N(0, 1) \\\\\nY &= 3 C + U_{Y}, \\, U_{Y} \\sim N(0, 1)\n\\end{align}\n\\]\n\\[\n\\begin{align}\nentender &= -0.022 + 15.12 \\, aprender  + \\varepsilon \\\\\nentender &= -0.005 +  0.122 \\, aprender + 2.98 \\, conocer + \\varepsilon\n\\end{align}\n\\]\n\n¿Puedes explicar qué pasó aquí?\n¿Qué relación tiene esto con lo que cabría esperar de acuerdo con as reglas de la “separación direccional”?\n¿Qué sugieren los datos del ajuste del modelo estadístico lm?\n¿Tienen relevancia el aprendizaje y el conocimiento?\n¿Cuál es el modelo adecuado dada la proposición causal considerada?\n\nPodemos utilizar a dagitty para explorar el DAG directamente de la siguiente manera. Podemos preguntarnos cuales serían las formas de separar el grafo con criterios de independencia condicional. Se trata de aplicar las tres reglas de separación direccional al grafo. Afortunadamente dagitty lo puede hacer por nosotros.\n\nimpliedConditionalIndependencies(ejemplo_1_DAG)\n\naprn _||_ entn | cncr\n\n\n¿Qué indica este resultado?\n\\[\naprender \\,\\, \\ci \\,\\, entender \\,\\, | \\,\\, conocer\n\\]\nAdemás de hacer esto por nosotros, la biblioteca dagitty nos permite poner a prueba la correspondencia de los datos con estas ideas. Lo hacemos con la función localTests.\nLa función localTests calcula el coeficiente de correlación de Pearson para cada condición considerada. El resultado incluye el valor p y el intervalo de confianza del coeficiente de correlación para cada una de las relaciones de independencias condicionales implicadas por la estructura del modelo.\nEl coeficiente de correlación de Pearson varía entre -1 y 1. El valor 0 implica que no hay correlación, mientras que -1 o 1 implica una correlación lineal perfecta.\nEl valor p de la prueba indica la probabilidad de obtener un conjunto de datos como el que se tiene, asumiendo la hipótesis de que la condición de independencia correspondiente es verdadera.\nPor lo tanto, un coeficiente de correlación cercano a 0 con un valor p alto es sugerente de que la independencia condicional indicada es congruente con el patrón detectable en los datos.\nPor el contrario, un valor alto del coeficiente de correlación con un valor p bajo sugiere que la independencia condicional considerada no es congruente con el conjunto de datos.\nLas columnas etiquetadas com 2.5% y 97,5% contienen el intervalo de confianza del 95% para el coeficiente de correlación.\nCuanto más estrecho sea el intervalo de confianza y alejado de cero resulte, más fuerte será la evidencia de que la independencia condicional que implica el DAG no se mantiene en el conjunto de datos disponible para el ensayo.\n\n# El tipo de análisis \"cis\" usa regresión lineal para poner a prueba la correlación\nejemplo_1_analisis_DAG &lt;- localTests(x=ejemplo_1_DAG, data=datos, type=\"cis\") \n\nprint(ejemplo_1_analisis_DAG)\n\n                        estimate   p.value        2.5%      97.5%\naprn _||_ entn | cncr 0.02367054 0.4549614 -0.03840997 0.08556934\n\n\nSi lo preferimos, podemos obtener una representación gráfica de estos resultados.\n\noptions(repr.plot.width=14, repr.plot.height=5)\npar(cex=1.5, lwd = 3, oma = c(1,2,1,1), mar = (c(4,2,1,1) + 0.5))\nplotLocalTestResults(ejemplo_1_analisis_DAG, col = \"blue\")\n\n\n\n\n\n\n\n\n¿Puedes comentar tu interpretación de estos resultados del modelo y los datos sobre aprendizaje y conocimiento?\n\n\n\n\n\n\nNotaDudas sobre puerta trasera\n\n\n\n\n\nLa cuestión que se nos complicó más en este tema el año pasado fue el asunto de la puerta trasera. Aquí retomo el tema alrededor de la pregunta sobre aspirina en la que si dificultó la comprensión del asunto.\nPara referencia esta son la pregunta y DAG asociados:\n\nLos autores de este ejemplo, Hernan & Robins explican lo siguiente:\n\n\nConfusión por indicación o prescripción\nEl contexto de este DAG se relaciona con la práctica farmacoepidemiológica al realizar estudios observacionales del efecto de los medicamentos, con protocolos en los que se comparan los resultados de personas que toman medicamentos específicos contra los de personas que no los toman (aunque pueden, por ejemplo, tomar otro tipo de medicación). En estos estudios, los participantes o sus médicos eligen si van a tomar o no los medicamentos. Por tanto, la asignación del tratamiento dista mucho de ser aleatoria. Se suelen hacer como seguimiento una vez liberado un fármaco en el mercado. La confusión por indicación es un sesgo que se encuentra con frecuencia en estos estudios observacionales farmacoepidemiológicos de los efectos de los fármacos.\nPara obtener más ayuda, les recomendamos acercarse a dagitty, que es un sitio de aprendizaje y uso de DAGs. Ahí hay una herramienta de dibujo de DAGs y permite explorar opciones para el diseño de estudios y recibir consejos sobre la calidad de la estimación que distintos enfoques de diseño pueden ofrecer. Esta herramienta también está disponible como una biblioteca para R. Con esta herramienta produjimos este resultado."
  },
  {
    "objectID": "posts/00-Bienvenida/pacto-contribuyente.html",
    "href": "posts/00-Bienvenida/pacto-contribuyente.html",
    "title": "Pacto del participante",
    "section": "",
    "text": "En el interés de fomentar una comunidad abierta y acogedora, nosotros como contribuyentes y facilitadores nos comprometemos a hacer de la participación en esta oportunidad de aprendizaje y en general en nuestra comunidad una experiencia libre de acoso para todos, independientemente de la edad, dimensión corporal, discapacidad, etnia, identidad y expresión de género, nivel de experiencia, nacionalidad, apariencia física, raza, religión, identidad u orientación sexual.\n\n\n\nEjemplos de comportamiento que contribuyen a crear un ambiente positivo:\n\nUso de lenguaje amable e inclusivo\nRespeto a diferentes puntos de vista y experiencias\nAceptación de críticas constructivas\nEnfocarse en lo que es mejor para la comunidad\nMostrar empatía a otros miembros de la comunidad\n\nEjemplos de comportamiento inaceptable por participantes:\n\nUso de lenguaje o imágenes sexuales y atención sexual no deseada\nComentarios insultantes o despectivos (trolling) y ataques personales o políticos\nAcoso público o privado\nPublicación de información privada de terceros sin su consentimiento, como direcciones físicas o electrónicas\nOtros tipos de conducta que pudieran considerarse inapropiadas en un entorno profesional.\n\n\n\n\nLos facilitadores del programa son responsables de clarificar los estándares de comportamiento aceptable y se espera que tomen medidas correctivas y apropiadas en respuesta a situaciones de conducta inaceptable.\nLos facilitadores del programa tienen el derecho y la responsabilidad de eliminar, editar o rechazar comentarios,código computacional, ediciones de documentación, y otras contribuciones que no estén alineadas con este Código de Conducta, o de excluir temporal o permanentemente a cualquier participante cuyo comportamiento sea inapropiado, amenazante, ofensivo o perjudicial.\n\n\n\nEste código de conducta aplica tanto a espacios del programa como a espacios públicos. Ejemplos de esto incluye el uso de la cuenta oficial de correo electrónico, publicaciones a través de las redes sociales.\n\n\n\nEjemplos de abuso, acoso u otro tipo de comportamiento inaceptable puede ser reportado al equipo del proyecto en M. Equihua. Todas las quejas serán revisadas e investigadas, generando un resultado apropiado a las circunstancias. El equipo del proyecto está obligado a mantener confidencialidad de la persona que reportó el incidente. Detalles específicos acerca de las políticas de aplicación pueden ser publicadas por separado.\nFacilitadores que no sigan o que no hagan cumplir este Código de Conducta pueden ser eliminados de forma temporal o permanente del equipo de gestión.\n\n\n\nEste Código de Conducta es una adaptación del Contributor Covenant, versión 1.4, disponible en https://www.contributor-covenant.org/es/version/1/4/code-of-conduct.html"
  },
  {
    "objectID": "posts/00-Bienvenida/pacto-contribuyente.html#nuestro-compromiso",
    "href": "posts/00-Bienvenida/pacto-contribuyente.html#nuestro-compromiso",
    "title": "Pacto del participante",
    "section": "",
    "text": "En el interés de fomentar una comunidad abierta y acogedora, nosotros como contribuyentes y facilitadores nos comprometemos a hacer de la participación en esta oportunidad de aprendizaje y en general en nuestra comunidad una experiencia libre de acoso para todos, independientemente de la edad, dimensión corporal, discapacidad, etnia, identidad y expresión de género, nivel de experiencia, nacionalidad, apariencia física, raza, religión, identidad u orientación sexual."
  },
  {
    "objectID": "posts/00-Bienvenida/pacto-contribuyente.html#nuestros-estándares",
    "href": "posts/00-Bienvenida/pacto-contribuyente.html#nuestros-estándares",
    "title": "Pacto del participante",
    "section": "",
    "text": "Ejemplos de comportamiento que contribuyen a crear un ambiente positivo:\n\nUso de lenguaje amable e inclusivo\nRespeto a diferentes puntos de vista y experiencias\nAceptación de críticas constructivas\nEnfocarse en lo que es mejor para la comunidad\nMostrar empatía a otros miembros de la comunidad\n\nEjemplos de comportamiento inaceptable por participantes:\n\nUso de lenguaje o imágenes sexuales y atención sexual no deseada\nComentarios insultantes o despectivos (trolling) y ataques personales o políticos\nAcoso público o privado\nPublicación de información privada de terceros sin su consentimiento, como direcciones físicas o electrónicas\nOtros tipos de conducta que pudieran considerarse inapropiadas en un entorno profesional."
  },
  {
    "objectID": "posts/00-Bienvenida/pacto-contribuyente.html#nuestras-responsabilidades",
    "href": "posts/00-Bienvenida/pacto-contribuyente.html#nuestras-responsabilidades",
    "title": "Pacto del participante",
    "section": "",
    "text": "Los facilitadores del programa son responsables de clarificar los estándares de comportamiento aceptable y se espera que tomen medidas correctivas y apropiadas en respuesta a situaciones de conducta inaceptable.\nLos facilitadores del programa tienen el derecho y la responsabilidad de eliminar, editar o rechazar comentarios,código computacional, ediciones de documentación, y otras contribuciones que no estén alineadas con este Código de Conducta, o de excluir temporal o permanentemente a cualquier participante cuyo comportamiento sea inapropiado, amenazante, ofensivo o perjudicial."
  },
  {
    "objectID": "posts/00-Bienvenida/pacto-contribuyente.html#alcance",
    "href": "posts/00-Bienvenida/pacto-contribuyente.html#alcance",
    "title": "Pacto del participante",
    "section": "",
    "text": "Este código de conducta aplica tanto a espacios del programa como a espacios públicos. Ejemplos de esto incluye el uso de la cuenta oficial de correo electrónico, publicaciones a través de las redes sociales."
  },
  {
    "objectID": "posts/00-Bienvenida/pacto-contribuyente.html#aplicación",
    "href": "posts/00-Bienvenida/pacto-contribuyente.html#aplicación",
    "title": "Pacto del participante",
    "section": "",
    "text": "Ejemplos de abuso, acoso u otro tipo de comportamiento inaceptable puede ser reportado al equipo del proyecto en M. Equihua. Todas las quejas serán revisadas e investigadas, generando un resultado apropiado a las circunstancias. El equipo del proyecto está obligado a mantener confidencialidad de la persona que reportó el incidente. Detalles específicos acerca de las políticas de aplicación pueden ser publicadas por separado.\nFacilitadores que no sigan o que no hagan cumplir este Código de Conducta pueden ser eliminados de forma temporal o permanente del equipo de gestión."
  },
  {
    "objectID": "posts/00-Bienvenida/pacto-contribuyente.html#atribución",
    "href": "posts/00-Bienvenida/pacto-contribuyente.html#atribución",
    "title": "Pacto del participante",
    "section": "",
    "text": "Este Código de Conducta es una adaptación del Contributor Covenant, versión 1.4, disponible en https://www.contributor-covenant.org/es/version/1/4/code-of-conduct.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "M3 - Diseño de Experimentos",
    "section": "",
    "text": "Experimentación Ecológica\n\n\n\ntaller\n\n\n\n\n\n\n\n\n\n6 feb 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nModelos de Efectos Mixtos\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n5 feb 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nModelos de medidas repetidas\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n5 feb 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nRestricciones a la aleatorización\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n4 feb 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nAprovechando mi DAG\n\n\n\nDAG\n\n\n\n\n\n\n\n\n\n3 feb 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nExperimentos completamente aleatorizados\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n30 ene 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nDiagramas Causales\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n29 ene 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nConceptos y Modelos en la experimentación\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n26 ene 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nBienvenidos al Módulo 3 de estadística\n\n\n\noperación\n\n\n\n\n\n\n\n\n\n26 ene 2026\n\n\nMiguel Equihua\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "ejercicios/tareas/index.html",
    "href": "ejercicios/tareas/index.html",
    "title": "Tareas M3",
    "section": "",
    "text": "Tarea\nArtículo\nFecha de entrega\n\n\n\n\nlectura-1\nSaltelli et al. (2024)\n28/ene/2026\n\n\nlectura-2\nBorger & Ramesh (2025)\n30/ene/2026\n\n\nlectura-3\nGiraldo (2022)\n4/feb/2026"
  },
  {
    "objectID": "ejercicios/tareas/index.html#lecturas",
    "href": "ejercicios/tareas/index.html#lecturas",
    "title": "Tareas M3",
    "section": "",
    "text": "Tarea\nArtículo\nFecha de entrega\n\n\n\n\nlectura-1\nSaltelli et al. (2024)\n28/ene/2026\n\n\nlectura-2\nBorger & Ramesh (2025)\n30/ene/2026\n\n\nlectura-3\nGiraldo (2022)\n4/feb/2026"
  },
  {
    "objectID": "ejercicios/tareas/index.html#ejercicios",
    "href": "ejercicios/tareas/index.html#ejercicios",
    "title": "Tareas M3",
    "section": "Ejercicios",
    "text": "Ejercicios\n\n\n\nTarea\nActividad\nFecha de entrega\n\n\n\n\nejercicio-1\nMi proyecto. Estado 0\n27/ene/2026\n\n\nejercicio-2\nMi DAG\n3/feb/2026\n\n\nejercicio-3\nControl de Larvas de mosquitos\n6/feb/2026\n\n\nejercicio-4\nMi protocolo revisado\n6/feb/2026"
  },
  {
    "objectID": "ejercicios/tareas/index.html#divertimentos",
    "href": "ejercicios/tareas/index.html#divertimentos",
    "title": "Tareas M3",
    "section": "Divertimentos",
    "text": "Divertimentos\n\n¿Cuál es tu aforismo favorito, por considerarlo vigente y actual, del Novum Organum de Bacon?"
  },
  {
    "objectID": "ejercicios/ejemplo-observacional/index.html",
    "href": "ejercicios/ejemplo-observacional/index.html",
    "title": "Modelación filogeográfica (observacional)",
    "section": "",
    "text": "Queremos analizar si la distancia genética entre poblaciones de una especie (medida como divergencia en secuencias de ADN mitocondrial) está asociada con la distancia geográfica (en kilómetros) entre esas poblaciones. Pensamos que existe una relación positiva que provoca que a mayor distancia geográfica ocurra también una mayor divergencia genética. La razón para pensar así es la la hipótesis de aislamiento por distancia, una proposición común en estudios filogeográficos. En términos biológicos estamos considerando que las poblaciones que están más alejadas físicamente sostienen un menor flujo génico y, por tanto, con el paso del tiempo habrán acumulado mayor cantidad de diferencias genéticas.\nTradicionalmente, al gremio filogeográfico, le gusta analizar este tipo de cuestiones con la llamada prueba de Mantel (enfoque no paramétrico que analiza estadísticamente la correlación entre matrices de distancia genética y geográfica). Además, los resultados de esos análisis se suelen ilustrar con visualizaciones mediante mapas que destacan gradientes que asocian las divergencias.\nLa prueba de Mantel clásica aplicada a matrices de disimilitud (\\(D_{1}\\ \\text{ y } D_{2}\\)), es linealmente equivalente a una regresión lineal (\\(y=\\beta_{0}+\\beta_{1}x\\)), en donde las observaciones o datos, son las parejas que se forman al empatar los valores correspondientes en las matrices. Para contrtuir el enfoque de regresión, consideraríamos que la variable de respuesta (\\(y\\)), son los elementos de la matriz de distancia genética, \\(D_{1}\\). La variable explicaiva (\\(x\\)), serán los elementos de la matriz de distancia geográfica \\(D_{2}\\). El modelo, claramente, explora así la posibilidad de predecir los valores de la matriz \\(D_{1}\\) dados los de la matriz \\(D_{2}\\).\nPara enriquecer el ejemplo, consideremos que además el fenómeno se desarrolla sobre regiones geográficas. En tal caso, habría que evaluar si la relación entre distancia genética y distancia geográfica es igual en los distintoss territorios, o si hay diferencias que reflejen historias evolutivas y ecológicas particulares. ¿Habrá variables adicionales que permitan explorar esas historias? ¿habrá procesos de confusión de efectos que habría que considerar?.\n\n\nSupongamos que estudiamos la especie Mi alegría está distribuida en dos regiones:\n- Región A (bosques húmedos)\n- Región B (zonas áridas)\nQueremos ver si el patrón de aislamiento por distancia (relación entre distancia genética y distancia geográfica) es un fenómeno que está experimentando la especie en cada región.\n\n\n\nPodemos usar una regresión simple extendida con un factor cualitativo de región:\n\\[\n\\begin{align*}\n\\text{Distancia genética} &= \\beta_0 + \\beta_1 \\cdot \\text{Distancia geográfica} + \\beta_2 \\cdot \\text{Región} + \\beta_3 \\cdot (\\text{Distancia geográfica} \\times \\text{Región}) + \\varepsilon \\\\\n\\\\\n\\text{o, en forma más compacta}\\\\  \n\\\\\nD_{gen} &= \\mu + D_{geo} + R + RD_{geo} + \\varepsilon\n\\end{align*}\n\\] En donde:\n\n\\(D{geo}\\): grado de relación entre distancias (genética y geográfica)\n\n\\(R\\): efecto de la región sobre la relación entre distancias.\n\n\\(RD{geo}\\): compotamiento diferencial de la distancia geográfica entre regiones.\n\n\n\n\n\nEn bosques húmedos, las poblaciones están más aisladas y la distancia geográfica se traduce en mayor divergencia genética (probablemente por barreras físicas como montañas o ríos).\n\nEn zonas áridas, el flujo génico puede ser más amplio (quizá por dispersión aérea o menor fragmentación), reduciendo el efecto del aislamiento por distancia.\n\nEl contraste muestra que los procesos filogeográficos no son homogéneos: dependen del paisaje y la ecología regional.\n\n\n\n\n\nRegión A (bosques húmedos):\n\\(D_{geo} = 0.01\\) con un efecto adicional de \\(R = 0.0003\\), imaginamos que está ocurriendo un fuerte aislamiento por distancia: cada 100 km aumenta en 0.03 unidades la divergencia genética.\nRegión B (zonas áridas):\n\\(D_{geo} = 0.02\\) con un efecto adicional de \\(R = 0.0001\\),\nimaginamos que el aislamiento por distancia es más débil aca: cada 100 km aumenta sólo en 0.01 unidades la divergencia genética.\n\n\n\n\nLas matrices de distancia se ven así\n\n\nCódigo\ndatos &lt;- data.frame(\n  distancia_geo = c(50,120,300,80,250,200, 60,150,280,90,260,210),\n  distancia_gen = c(0.01,0.03,0.06,0.02,0.05,0.04, 0.02,0.025,0.04,0.022,0.03,0.028),\n  region = factor(rep(c(\"_bosque_humedo\",\"_zona_arida\"), each = 6))\n)\n\n\nmat_reg_bosque&lt;- matrix(0, nrow = 4, ncol = 4)\nmat_reg_bosque[lower.tri(mat_reg_bosque)] &lt;- datos$distancia_geo[1:6]\nmat_reg_bosque &lt;- mat_reg_bosque + t(mat_reg_bosque)\n\nmat_reg_matorral &lt;- matrix(0, nrow = 4, ncol = 4)\nmat_reg_matorral[lower.tri(mat_reg_matorral)] &lt;- datos$distancia_geo[7:12]\nmat_reg_matorral &lt;- mat_reg_matorral + t(mat_reg_matorral)\n\nmat_gen_reg_bosque &lt;- matrix(0, nrow = 4, ncol = 4)\nmat_gen_reg_bosque[lower.tri(mat_gen_reg_bosque)] &lt;- datos$distancia_gen[1:6]\nmat_gen_reg_bosque &lt;- mat_gen_reg_bosque + t(mat_gen_reg_bosque)\n\nmat_gen_reg_matorral &lt;- matrix(0, nrow = 4, ncol = 4)\nmat_gen_reg_matorral[lower.tri(mat_gen_reg_matorral)] &lt;- datos$distancia_gen [7:12]\nmat_gen_reg_matorral &lt;- mat_gen_reg_matorral + t(mat_gen_reg_matorral)\n\n\n\n\n# --- Heatmap geográfico --- \nlibrary(tidyr)\nmelt_geo &lt;-  mat_reg_bosque |&gt; \n  as_tibble(rownames = \"row\", .name_repair = \"unique\")  |&gt; \n  pivot_longer(-row, names_to = \"col\", values_to = \"valor\") |&gt; \n  mutate(col = rep(1:4, times = 4),\n         row = as.integer(row))\n\nggplot(melt_geo, aes(col, -row, fill = valor)) + \n  geom_tile() + \n  geom_text(aes(label=valor), color=\"white\") + \n  scale_fill_gradient(low=\"lightblue\", high=\"darkblue\", name = \"dist\") + \n  labs(title=\"Matriz de distancia geográfica (km)\",\n       subtitle = \"Bosque húmedo\", x=\"Población\", y=\"Población\") + \n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\nCódigo\nmelt_geo &lt;-  mat_reg_matorral|&gt; \n  as_tibble(rownames = \"row\", .name_repair = \"unique\"  )  |&gt; \n  pivot_longer(-row, names_to = \"col\", values_to = \"valor\") |&gt; \n  mutate(col = rep(1:4, times = 4),\n         row = as.integer(row))\nggplot(melt_geo, aes(col, -row, fill = valor)) + \n  geom_tile() + \n  geom_text(aes(label=valor), color=\"white\") + \n  scale_fill_gradient(low=\"lightblue\", high=\"darkblue\", name = \"dist\") + \n  labs(title=\"Matriz de distancia geográfica (km)\",\n       subtitle = \"Matorral xerófilo\", x=\"Población\", y=\"Población\") + \n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\nCódigo\n# --- Heatmap genético --- \nmelt_geo &lt;-  mat_gen_reg_bosque |&gt; \n  as_tibble(rownames = \"row\", .name_repair = \"unique\")  |&gt; \n  pivot_longer(-row, names_to = \"col\", values_to = \"valor\") |&gt; \n  mutate(col = rep(1:4, times = 4),\n         row = as.integer(row))\n\nggplot(melt_geo, aes(col, -row, fill = valor)) + \n  geom_tile() + \n  geom_text(aes(label=valor), color=\"white\") + \n  scale_fill_gradient(low=\"lightgreen\", high=\"darkgreen\", name = \"dist\") + \n  labs(title=\"Matriz de distancia genética (p-dist)\",\n       subtitle = \"Bosque húmedo\", x=\"Población\", y=\"Población\") + \n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\nCódigo\nmelt_geo &lt;-  mat_gen_reg_matorral|&gt; \n  as_tibble(rownames = \"row\", .name_repair = \"unique\" )  |&gt; \n  pivot_longer(-row, names_to = \"col\", values_to = \"valor\") |&gt; \n  mutate(col = rep(1:4, times = 4),\n         row = as.integer(row))\nggplot(melt_geo, aes(col, -row, fill = valor)) + \n  geom_tile() + \n  geom_text(aes(label=valor), color=\"white\") + \n  scale_fill_gradient(low=\"lightgreen\", high=\"darkgreen\", name = \"dist\") + \n  labs(title=\"Matriz de distancia genética (p-dist)\",\n       subtitle = \"Matorral xerófilo\", x=\"Población\", y=\"Población\") + \n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ndatos |&gt; \n  mutate(reg_alfa = if_else(str_detect(region, \"bosq\"),\n                            \"Bosque húmedo\", \n                            \"Matorral xerófilo\")) |&gt; \n  select(distancia_gen,distancia_geo,reg_alfa) |&gt; \n  flextable() |&gt; \n  add_header_row(values = c(\"Distancia\", \"\"), colwidths = c(2,1)) |&gt; \n  set_header_labels(distancia_gen = \"Genética\",\n                    distancia_geo = \"Geográfica\",\n                    reg_alfa = \"Región\") |&gt; \n  align(i = 1:2, part = \"header\", align = \"center\") |&gt; \n  align(j = 3, align = \"center\") |&gt; \n  border(i = 1, j = 3, part = \"header\", border.bottom = fp_border(color = \"white\", width = 2)) |&gt; \n  width(j = 3, width = 2)\n\n\nDistanciaGenéticaGeográficaRegión0.01050Bosque húmedo0.030120Bosque húmedo0.060300Bosque húmedo0.02080Bosque húmedo0.050250Bosque húmedo0.040200Bosque húmedo0.02060Matorral xerófilo0.025150Matorral xerófilo0.040280Matorral xerófilo0.02290Matorral xerófilo0.030260Matorral xerófilo0.028210Matorral xerófilo\n\n\n\n\nCódigo\n# Modelo con interacción\nmodelo &lt;- lm(distancia_gen ~ distancia_geo * region, data = datos)\nsummary(modelo)\n\n\n\nCall:\nlm(formula = distancia_gen ~ distancia_geo * region, data = datos)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0036523 -0.0014395 -0.0002849  0.0009247  0.0049001 \n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      3.792e-03  2.538e-03   1.494 0.173494    \ndistancia_geo                    1.872e-04  1.338e-05  13.991  6.6e-07 ***\nregion_zona_arida                1.104e-02  3.815e-03   2.894 0.020076 *  \ndistancia_geo:region_zona_arida -1.149e-04  1.990e-05  -5.771 0.000419 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.002967 on 8 degrees of freedom\nMultiple R-squared:  0.9676,    Adjusted R-squared:  0.9555 \nF-statistic: 79.68 on 3 and 8 DF,  p-value: 2.671e-06\n\n\n\n\nCódigo\n# Visualización\nggplot(datos, aes(x=distancia_geo, y=distancia_gen, color=region)) +\n  geom_point(size=3) +\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x=\"Distancia geográfica (km)\", \n       y=\"Distancia genética (p-dist)\",\n       title=\"Contraste de aislamiento por distancia entre regiones\") +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nEn filogeografía, tanto el test de Mantel como la regresión se usan para evaluar la relación entre matrices de distancia genética y geográfica, pero tienen diferencias importantes:\nEl Test de Mantel calcula la correlación entre dos matrices de distancia (ej. genética vs geográfica).\n\nVentajas:\n\nEs el método clásico para probar la hipótesis de aislamiento por distancia.\n\nFunciona directamente con matrices simétricas de distancias.\n\nUsa permutaciones para evaluar significancia, lo que lo hace robusto frente a distribuciones no normales.\n\n\nLimitaciones:\n\nNo estima coeficientes de regresión ni intercepto (solo da una correlación).\n\nPuede ser sensible a la autocorrelación espacial y a estructuras jerárquicas.\n\nMenos flexible si quieres incluir variables adicionales o interacciones.\n\n\nPor su lado, la regresión (ej. regresión lineal o modelos mixtos) se orienta a construir un modelo que prediga la distancia genética como una función de la distancia geográfica (y otras covariables si quieres).\n\nVentajas:\n\nPermite estimar coeficientes de refresión (efectos), intercepto y significancia estadística.\n\nSe puede extender a modelos más complejos (ej. incluir región, ambiente, barreras).\n\nMás interpretativo: puedes decir “cada 100 km aumenta en X unidades la divergencia genética”.\n\nLimitaciones:\n\nRequiere transformar matrices en vectores de pares (lo que rompe la independencia estadística).\nSi no se ajusta con métodos adecuados (ej. modelos mixtos o GLS), puede inflar la significancia.\n\nMenos robusto que Mantel si solo quieres probar correlación simple.\n\n\nAuque generalmente se considera a Matel como más directo y simple, en el ejemplo vemos que, si interesa un contraste entre regiones, la regresión con interacción es más poderosa porque te permite comparar pendientes e interceptos. El Mantel te daría solo una correlación por región, sin mostrar cómo cambia la intensidad del aislamiento por distancia."
  },
  {
    "objectID": "ejercicios/ejemplo-observacional/index.html#pregunta-de-investigación",
    "href": "ejercicios/ejemplo-observacional/index.html#pregunta-de-investigación",
    "title": "Modelación filogeográfica (observacional)",
    "section": "",
    "text": "Queremos analizar si la distancia genética entre poblaciones de una especie (medida como divergencia en secuencias de ADN mitocondrial) está asociada con la distancia geográfica (en kilómetros) entre esas poblaciones. Pensamos que existe una relación positiva que provoca que a mayor distancia geográfica ocurra también una mayor divergencia genética. La razón para pensar así es la la hipótesis de aislamiento por distancia, una proposición común en estudios filogeográficos. En términos biológicos estamos considerando que las poblaciones que están más alejadas físicamente sostienen un menor flujo génico y, por tanto, con el paso del tiempo habrán acumulado mayor cantidad de diferencias genéticas.\nTradicionalmente, al gremio filogeográfico, le gusta analizar este tipo de cuestiones con la llamada prueba de Mantel (enfoque no paramétrico que analiza estadísticamente la correlación entre matrices de distancia genética y geográfica). Además, los resultados de esos análisis se suelen ilustrar con visualizaciones mediante mapas que destacan gradientes que asocian las divergencias.\nLa prueba de Mantel clásica aplicada a matrices de disimilitud (\\(D_{1}\\ \\text{ y } D_{2}\\)), es linealmente equivalente a una regresión lineal (\\(y=\\beta_{0}+\\beta_{1}x\\)), en donde las observaciones o datos, son las parejas que se forman al empatar los valores correspondientes en las matrices. Para contrtuir el enfoque de regresión, consideraríamos que la variable de respuesta (\\(y\\)), son los elementos de la matriz de distancia genética, \\(D_{1}\\). La variable explicaiva (\\(x\\)), serán los elementos de la matriz de distancia geográfica \\(D_{2}\\). El modelo, claramente, explora así la posibilidad de predecir los valores de la matriz \\(D_{1}\\) dados los de la matriz \\(D_{2}\\).\nPara enriquecer el ejemplo, consideremos que además el fenómeno se desarrolla sobre regiones geográficas. En tal caso, habría que evaluar si la relación entre distancia genética y distancia geográfica es igual en los distintoss territorios, o si hay diferencias que reflejen historias evolutivas y ecológicas particulares. ¿Habrá variables adicionales que permitan explorar esas historias? ¿habrá procesos de confusión de efectos que habría que considerar?.\n\n\nSupongamos que estudiamos la especie Mi alegría está distribuida en dos regiones:\n- Región A (bosques húmedos)\n- Región B (zonas áridas)\nQueremos ver si el patrón de aislamiento por distancia (relación entre distancia genética y distancia geográfica) es un fenómeno que está experimentando la especie en cada región.\n\n\n\nPodemos usar una regresión simple extendida con un factor cualitativo de región:\n\\[\n\\begin{align*}\n\\text{Distancia genética} &= \\beta_0 + \\beta_1 \\cdot \\text{Distancia geográfica} + \\beta_2 \\cdot \\text{Región} + \\beta_3 \\cdot (\\text{Distancia geográfica} \\times \\text{Región}) + \\varepsilon \\\\\n\\\\\n\\text{o, en forma más compacta}\\\\  \n\\\\\nD_{gen} &= \\mu + D_{geo} + R + RD_{geo} + \\varepsilon\n\\end{align*}\n\\] En donde:\n\n\\(D{geo}\\): grado de relación entre distancias (genética y geográfica)\n\n\\(R\\): efecto de la región sobre la relación entre distancias.\n\n\\(RD{geo}\\): compotamiento diferencial de la distancia geográfica entre regiones.\n\n\n\n\n\nEn bosques húmedos, las poblaciones están más aisladas y la distancia geográfica se traduce en mayor divergencia genética (probablemente por barreras físicas como montañas o ríos).\n\nEn zonas áridas, el flujo génico puede ser más amplio (quizá por dispersión aérea o menor fragmentación), reduciendo el efecto del aislamiento por distancia.\n\nEl contraste muestra que los procesos filogeográficos no son homogéneos: dependen del paisaje y la ecología regional.\n\n\n\n\n\nRegión A (bosques húmedos):\n\\(D_{geo} = 0.01\\) con un efecto adicional de \\(R = 0.0003\\), imaginamos que está ocurriendo un fuerte aislamiento por distancia: cada 100 km aumenta en 0.03 unidades la divergencia genética.\nRegión B (zonas áridas):\n\\(D_{geo} = 0.02\\) con un efecto adicional de \\(R = 0.0001\\),\nimaginamos que el aislamiento por distancia es más débil aca: cada 100 km aumenta sólo en 0.01 unidades la divergencia genética.\n\n\n\n\nLas matrices de distancia se ven así\n\n\nCódigo\ndatos &lt;- data.frame(\n  distancia_geo = c(50,120,300,80,250,200, 60,150,280,90,260,210),\n  distancia_gen = c(0.01,0.03,0.06,0.02,0.05,0.04, 0.02,0.025,0.04,0.022,0.03,0.028),\n  region = factor(rep(c(\"_bosque_humedo\",\"_zona_arida\"), each = 6))\n)\n\n\nmat_reg_bosque&lt;- matrix(0, nrow = 4, ncol = 4)\nmat_reg_bosque[lower.tri(mat_reg_bosque)] &lt;- datos$distancia_geo[1:6]\nmat_reg_bosque &lt;- mat_reg_bosque + t(mat_reg_bosque)\n\nmat_reg_matorral &lt;- matrix(0, nrow = 4, ncol = 4)\nmat_reg_matorral[lower.tri(mat_reg_matorral)] &lt;- datos$distancia_geo[7:12]\nmat_reg_matorral &lt;- mat_reg_matorral + t(mat_reg_matorral)\n\nmat_gen_reg_bosque &lt;- matrix(0, nrow = 4, ncol = 4)\nmat_gen_reg_bosque[lower.tri(mat_gen_reg_bosque)] &lt;- datos$distancia_gen[1:6]\nmat_gen_reg_bosque &lt;- mat_gen_reg_bosque + t(mat_gen_reg_bosque)\n\nmat_gen_reg_matorral &lt;- matrix(0, nrow = 4, ncol = 4)\nmat_gen_reg_matorral[lower.tri(mat_gen_reg_matorral)] &lt;- datos$distancia_gen [7:12]\nmat_gen_reg_matorral &lt;- mat_gen_reg_matorral + t(mat_gen_reg_matorral)\n\n\n\n\n# --- Heatmap geográfico --- \nlibrary(tidyr)\nmelt_geo &lt;-  mat_reg_bosque |&gt; \n  as_tibble(rownames = \"row\", .name_repair = \"unique\")  |&gt; \n  pivot_longer(-row, names_to = \"col\", values_to = \"valor\") |&gt; \n  mutate(col = rep(1:4, times = 4),\n         row = as.integer(row))\n\nggplot(melt_geo, aes(col, -row, fill = valor)) + \n  geom_tile() + \n  geom_text(aes(label=valor), color=\"white\") + \n  scale_fill_gradient(low=\"lightblue\", high=\"darkblue\", name = \"dist\") + \n  labs(title=\"Matriz de distancia geográfica (km)\",\n       subtitle = \"Bosque húmedo\", x=\"Población\", y=\"Población\") + \n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\nCódigo\nmelt_geo &lt;-  mat_reg_matorral|&gt; \n  as_tibble(rownames = \"row\", .name_repair = \"unique\"  )  |&gt; \n  pivot_longer(-row, names_to = \"col\", values_to = \"valor\") |&gt; \n  mutate(col = rep(1:4, times = 4),\n         row = as.integer(row))\nggplot(melt_geo, aes(col, -row, fill = valor)) + \n  geom_tile() + \n  geom_text(aes(label=valor), color=\"white\") + \n  scale_fill_gradient(low=\"lightblue\", high=\"darkblue\", name = \"dist\") + \n  labs(title=\"Matriz de distancia geográfica (km)\",\n       subtitle = \"Matorral xerófilo\", x=\"Población\", y=\"Población\") + \n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\nCódigo\n# --- Heatmap genético --- \nmelt_geo &lt;-  mat_gen_reg_bosque |&gt; \n  as_tibble(rownames = \"row\", .name_repair = \"unique\")  |&gt; \n  pivot_longer(-row, names_to = \"col\", values_to = \"valor\") |&gt; \n  mutate(col = rep(1:4, times = 4),\n         row = as.integer(row))\n\nggplot(melt_geo, aes(col, -row, fill = valor)) + \n  geom_tile() + \n  geom_text(aes(label=valor), color=\"white\") + \n  scale_fill_gradient(low=\"lightgreen\", high=\"darkgreen\", name = \"dist\") + \n  labs(title=\"Matriz de distancia genética (p-dist)\",\n       subtitle = \"Bosque húmedo\", x=\"Población\", y=\"Población\") + \n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\nCódigo\nmelt_geo &lt;-  mat_gen_reg_matorral|&gt; \n  as_tibble(rownames = \"row\", .name_repair = \"unique\" )  |&gt; \n  pivot_longer(-row, names_to = \"col\", values_to = \"valor\") |&gt; \n  mutate(col = rep(1:4, times = 4),\n         row = as.integer(row))\nggplot(melt_geo, aes(col, -row, fill = valor)) + \n  geom_tile() + \n  geom_text(aes(label=valor), color=\"white\") + \n  scale_fill_gradient(low=\"lightgreen\", high=\"darkgreen\", name = \"dist\") + \n  labs(title=\"Matriz de distancia genética (p-dist)\",\n       subtitle = \"Matorral xerófilo\", x=\"Población\", y=\"Población\") + \n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ndatos |&gt; \n  mutate(reg_alfa = if_else(str_detect(region, \"bosq\"),\n                            \"Bosque húmedo\", \n                            \"Matorral xerófilo\")) |&gt; \n  select(distancia_gen,distancia_geo,reg_alfa) |&gt; \n  flextable() |&gt; \n  add_header_row(values = c(\"Distancia\", \"\"), colwidths = c(2,1)) |&gt; \n  set_header_labels(distancia_gen = \"Genética\",\n                    distancia_geo = \"Geográfica\",\n                    reg_alfa = \"Región\") |&gt; \n  align(i = 1:2, part = \"header\", align = \"center\") |&gt; \n  align(j = 3, align = \"center\") |&gt; \n  border(i = 1, j = 3, part = \"header\", border.bottom = fp_border(color = \"white\", width = 2)) |&gt; \n  width(j = 3, width = 2)\n\n\nDistanciaGenéticaGeográficaRegión0.01050Bosque húmedo0.030120Bosque húmedo0.060300Bosque húmedo0.02080Bosque húmedo0.050250Bosque húmedo0.040200Bosque húmedo0.02060Matorral xerófilo0.025150Matorral xerófilo0.040280Matorral xerófilo0.02290Matorral xerófilo0.030260Matorral xerófilo0.028210Matorral xerófilo\n\n\n\n\nCódigo\n# Modelo con interacción\nmodelo &lt;- lm(distancia_gen ~ distancia_geo * region, data = datos)\nsummary(modelo)\n\n\n\nCall:\nlm(formula = distancia_gen ~ distancia_geo * region, data = datos)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0036523 -0.0014395 -0.0002849  0.0009247  0.0049001 \n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      3.792e-03  2.538e-03   1.494 0.173494    \ndistancia_geo                    1.872e-04  1.338e-05  13.991  6.6e-07 ***\nregion_zona_arida                1.104e-02  3.815e-03   2.894 0.020076 *  \ndistancia_geo:region_zona_arida -1.149e-04  1.990e-05  -5.771 0.000419 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.002967 on 8 degrees of freedom\nMultiple R-squared:  0.9676,    Adjusted R-squared:  0.9555 \nF-statistic: 79.68 on 3 and 8 DF,  p-value: 2.671e-06\n\n\n\n\nCódigo\n# Visualización\nggplot(datos, aes(x=distancia_geo, y=distancia_gen, color=region)) +\n  geom_point(size=3) +\n  geom_smooth(method=\"lm\", se=FALSE) +\n  labs(x=\"Distancia geográfica (km)\", \n       y=\"Distancia genética (p-dist)\",\n       title=\"Contraste de aislamiento por distancia entre regiones\") +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nEn filogeografía, tanto el test de Mantel como la regresión se usan para evaluar la relación entre matrices de distancia genética y geográfica, pero tienen diferencias importantes:\nEl Test de Mantel calcula la correlación entre dos matrices de distancia (ej. genética vs geográfica).\n\nVentajas:\n\nEs el método clásico para probar la hipótesis de aislamiento por distancia.\n\nFunciona directamente con matrices simétricas de distancias.\n\nUsa permutaciones para evaluar significancia, lo que lo hace robusto frente a distribuciones no normales.\n\n\nLimitaciones:\n\nNo estima coeficientes de regresión ni intercepto (solo da una correlación).\n\nPuede ser sensible a la autocorrelación espacial y a estructuras jerárquicas.\n\nMenos flexible si quieres incluir variables adicionales o interacciones.\n\n\nPor su lado, la regresión (ej. regresión lineal o modelos mixtos) se orienta a construir un modelo que prediga la distancia genética como una función de la distancia geográfica (y otras covariables si quieres).\n\nVentajas:\n\nPermite estimar coeficientes de refresión (efectos), intercepto y significancia estadística.\n\nSe puede extender a modelos más complejos (ej. incluir región, ambiente, barreras).\n\nMás interpretativo: puedes decir “cada 100 km aumenta en X unidades la divergencia genética”.\n\nLimitaciones:\n\nRequiere transformar matrices en vectores de pares (lo que rompe la independencia estadística).\nSi no se ajusta con métodos adecuados (ej. modelos mixtos o GLS), puede inflar la significancia.\n\nMenos robusto que Mantel si solo quieres probar correlación simple.\n\n\nAuque generalmente se considera a Matel como más directo y simple, en el ejemplo vemos que, si interesa un contraste entre regiones, la regresión con interacción es más poderosa porque te permite comparar pendientes e interceptos. El Mantel te daría solo una correlación por región, sin mostrar cómo cambia la intensidad del aislamiento por distancia."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Acerca de",
    "section": "",
    "text": "Blog de clase sobre Diseño de experimentos. Es el módulo III del curso de estadística que se imparte en el Inecol."
  },
  {
    "objectID": "ejercicios/control-de-entregas/index.html",
    "href": "ejercicios/control-de-entregas/index.html",
    "title": "Registro de entregas",
    "section": "",
    "text": "El conteo de tareas recibidas hasta el día 27 de febrero, 2026 es el que sigue.\n\n\n\n\n\nNúmero de entregas registradasTipoidCantidadejercicio114ejercicio214ejercicio328ejercicio413lectura115lectura214lectura315lectura1\n\n\n\n\n\nLos documentos que he recibido son los que están en esta lista."
  },
  {
    "objectID": "ejercicios/ejercicio-diseno-y-analisis/index.html#situación-de-investigación",
    "href": "ejercicios/ejercicio-diseno-y-analisis/index.html#situación-de-investigación",
    "title": "Control de larvas de mosquitos",
    "section": "Situación de investigación",
    "text": "Situación de investigación\nQueremos evaluar el efecto de tres pesticidas sobre la supervivencia de larvas de Aedes aegipty. Estamos ensayando el pesticida en una zona en donde sabemos que existen distinta historia de exposición a contaminantes, lo que sospechamos puede afectar su respuesta. Desafortunadamente poco sabemos de los detalles de esas historias de exposición previa por lo que la consideramos como una fuente de variabilidad un poco compleja y no medible."
  },
  {
    "objectID": "ejercicios/ejercicio-diseno-y-analisis/index.html#ideas-de-diseño",
    "href": "ejercicios/ejercicio-diseno-y-analisis/index.html#ideas-de-diseño",
    "title": "Control de larvas de mosquitos",
    "section": "Ideas de diseño",
    "text": "Ideas de diseño\n\nLos Tratamientos\n\nControl\nA: Mezcla deBacillus thuringiensis, Beauveria bassiana, Peacelomyces fumorosae\nB: Temefos\n\nEn la zona de interés se sabe que hay tres grandes territorios. Uno prácticamente en estado natural, seguramente con muy baja exposición a agroquímicos de todo tipo. Hay otra gran proporción del lugar que se dice ha estado medianamente expuesta y finalmente, hay otro territorio muy afectado por actividades humanas que seguramente lo ha expuesto a una larga historia de uso de agroquímicos.\nEl estudio se realizó de la siguiente manera. Se capturaron en cada lugar 100 adultos de Aedes aegipty. Se llevaron esos mosquitos al laboratorio, en donde se les mantuvo en condiciones homogéneas. Se les ofrecieron contenedores de agua limpia, apropiados para su reproducción. Así se obtuvieron 50 larvas producidas por los adultos colectados en cada lugar y se expusieron a cada tratamiento. Finalmente, se tomó nota de la supervivencia resultante al cabo de 48 horas.\n\nEstos son los resultados que se obtuvieron de este ensayo.\n\n\nTratamientoTipo de territorioSupervivencia(%)Controlprístino 77.2Pesticida_Aprístino 58.8Pesticida_Bprístino 57.8Controluso humano medio80.4Pesticida_Auso humano medio60.6Pesticida_Buso humano medio58.6Controlmuy alterado82.3Pesticida_Amuy alterado53.7Pesticida_Bmuy alterado46.6"
  },
  {
    "objectID": "ejercicios/ejercicio-diseno-y-analisis/index.html#usa-quarto-para-escribir-el-reporte",
    "href": "ejercicios/ejercicio-diseno-y-analisis/index.html#usa-quarto-para-escribir-el-reporte",
    "title": "Control de larvas de mosquitos",
    "section": "Usa Quarto para escribir el reporte",
    "text": "Usa Quarto para escribir el reporte\nPara este ejercicio utiliza por favor la opción de crear tu reporte como un Quarto Document. Propongo esto como un ejercicio introductorio. Espero que puedas valorar así el gran potencial que esto está adquiriendo, pues como puedes ver aquí, podrías escribir tus artículos directamente con Quarto. Pero para empezar, te podría interesar más bien este tutorial introductorio. Si sientes que antes o además de entender eso de Quarto, te gustaría saber más sobre R, te sugiero este material básico.\nEn todo caso, mi idea es animarte a brincar al agua. Sigue la figura de abajo y tendrás un embrión de documento listo para que hagas con él lo que tú quieras. Básicamente escribir libremente y de vez en vez, cuando tengas que hacer operaciones con R podrás abrir un espacio para eso (¡un chunk!). En RStudio lo puedes hacer con ayuda del botón verde que está arriba como a la mitad de la pantalla, tiene un signo “+” y una “C”, seguramente de chunk. Eso es todo para empezar. Si quieres “ver en bonito”, lo que has escrito, tienes que apretar el botón Render. Normalmente pasará un momento y te llevará al browser para mostrarte lo que has escrito como una pagina web de tu creación. Al mismo tiempo habrá creado en tu carpeta de trabajo un archivo html con el nombre que le hayas dado al inicio.\n\n\n\n\nHTML como un solo documento\nCuando se genera un html con Quarto el tratamiento simple es poner algunas partes como figuras y cosas así en un directorio anexo que lee el HTML cuando se requiere. Esto es inconveniente para distribuir resultados. Para poner todo en un solo documento fácilmente distribuible te sugiero usar esta forma de preparación de tu documento. En lugar de poner html: default, pon lo siguiente.\nformat:\n  html:\n    embed-resources: true\n\n\nQuiero incluir el render en PDF\nEl Asunto de la incompatibilidad de Quarto al producir PDF en español se puede atender con la especificación de la clase de documento a utilizar. Esto controla los paquetes base que usa LaTex para producir el resultado, así que es un buen camino para atender la problemática. Te sugiero poner esto en la sección de control de tu documento.\nformat:\n    pdf:\n       documentclass: scrartcl     \nEn el cuadro siguiente están las clases de documento disponibles. El paquete base KOMA se desarrolló para ofrecer al usuario escripts de mejor diseño y desempeño que los convencionales de LaTex. Ahora son el default en Quarto. Podemos usar varias de estas clases, pero algunas de ellas dan problemas al utilizarlas en combinación con algunos idiomas (como el español). En el cuadro siguiente anoto lo que yo he encontrado al usarlas.\n\n\n\n\n\n\n\n\n\nClase\nBase\nPropósito\nProblema\n\n\n\n\nscrartcl\nKOMA\nArticle-style documents (default for most PDFs).\nNo\n\n\nscrreprt\nKOMA\nReport-style documents (chapters, sections).\nNo\n\n\nscrbook\nKOMA\nBook-style documents (front matter, chapters, back matter).\nNo\n\n\nscrlttr2\nKOMA\nLetters\nSí\n\n\narticle\nLaTeX\nShort papers, articles.\nNo\n\n\nreport\nLaTeX\nLonger reports with chapters.\nNo\n\n\nbook\nLaTeX\nBooks and theses.\nNo\n\n\nletter\nLaTeX\nLetters.\nSí"
  },
  {
    "objectID": "ejercicios/ejercicio-diseno-y-analisis/index.html#cómo-desarrollar-el-trabajo",
    "href": "ejercicios/ejercicio-diseno-y-analisis/index.html#cómo-desarrollar-el-trabajo",
    "title": "Control de larvas de mosquitos",
    "section": "¿Cómo desarrollar el trabajo?",
    "text": "¿Cómo desarrollar el trabajo?\nComo sugerencia para ayudarte a desarrollar tus ideas te ofrezco los siguientes puntos a considerar.\n\n\n\n¿Diseño experimental?\n¿Arreglo de tratamientos?\n¿Modelo que corresponde a este experimento?\n¿Supuestos que harás para apoyar tu análisis estadístico?\n¿Define tu criterio o nivel de significancia?\nRealiza una exploración de los datos, numérica y gráfica, comenta.\nConstruye los modelos necesarios y selecciona el mínimo adecuado.\nValora la calidad del modelo, incluyendo el análisis de los residuos.\nResuelve que tratamientos difieren de los demás.\nArgumenta tus conclusiones.\nIncluye ilustraciones apropiadas y elocuentes para apoyar tus hallazgos"
  },
  {
    "objectID": "ejercicios.html",
    "href": "ejercicios.html",
    "title": "M3-ejercicios",
    "section": "",
    "text": "Modelación filogeográfica (observacional)\n\n\n\nejemplo\n\n\n\n\n\n\n\n\n\n4 feb 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nControl de larvas de mosquitos\n\n\n\nejercicio\n\n\n\n\n\n\n\n\n\n4 feb 2026\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nRegistro de entregas\n\n\n\n\n\n\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nTareas M3\n\n\n\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#objetivos-del-módulo-3",
    "href": "posts/00-Bienvenida/index.html#objetivos-del-módulo-3",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Objetivos del Módulo 3",
    "text": "Objetivos del Módulo 3\nDurante las últimas semanas revisaron conceptos de probabilidad y matemáticas que necesitamos como un lenguaje eficiente de comunicación. También empezaron a explorar como es que se pueden analizar proposiciones sobre la existencia de asociación o incluso relaciones de dependencia entre dos variables: modelos de regresión simple. Ahora vamos a aplicar y extender estos aprendizajes para abordar el desafío de producir conocimiento que nos permita comprender como funciona el mundo. Asumir un interés en la comprensión causal requiere desarrollar las habilidades de pensamiento crítico, lo que constituye por tanto otro de los propósitos del módulo.\nUtilizaremos el lenguaje de programación R como plataforma de cómputo para el análisis de datos. Aspiramos a ofrecerles así un curso introductorio para su uso. También nos interesa acercarnos a los enfoques formales para el análisis causal actual, mediante la formulación de Grafos Acíclicos Dirigidos (DAG). Los invitamos a hacer explícitas y a dibujar las relaciones causales de sus proyectos para comprenderlas, comunicarlas y analizarlas con mayor eficiencia.\nComo ejercicio inicial les pedimos preparen y nos entreguen en una sola cuartilla la descripción de una de las preguntas de investigación que se han planteado en su proyecto de posgrado, con suficiente detalle como para comprender el asunto y la propuesta sobre como poner a prueba la idea planteada. No se trata de todo el protocolo de su proyecto de investigación. Escojan sólo un aspecto de él. Sólo lo que deseen compartir y explorar en este curso como oportunidad de aprendizaje.\nPacto del participante"
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#plan-de-clase",
    "href": "posts/00-Bienvenida/index.html#plan-de-clase",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Plan de clase",
    "text": "Plan de clase\n\n\n\n\n\n\nImportantePor favor noten que el día 4 de febrero sí será hábil, no así el 2.\n\n\n\n\n\n\nPara llevar el control adecuado de los ejercicios y controles de lectura que me entreguen, les pido por favor sólo usar la cuenta miguel.equihua@inecol.mx. Para poderlos identificar consistentemente anoten en el asunto el código [M3-2026]. Denominen sus trabajos (archivos pdf, docx, qmd o html) utilizando un nombre que indique tipo de actividad (lectura o ejercicio), id numérico y una sola palabra distintiva o abreviatura de su nombre (elijan algo a usar consistentemente). Todo separado por guiones, podría ser en mi caso: lectura-1-migeq. Adjúntenlos al correo que me envíen como forma de entrega. Las fechas de entrega de las lecturas son los días de debate y los de los ejercicios los iremos viemdo según los asigne.\n\n\n\n\n\n\nNotaCalendario\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDíaLecturaTemaLunes 26 Un lenguaje para describir modelos (diseño de experimentos y de tratamientos)Martes 27 Causalidad y modelación gráfica: Grafos Acíclicos Dirigidos (DAG)Miércoles 28debateDiseño de experimentos: hipótesis y la modelación estadísticaJueves 29 Efectos fijos y aleatorios sus implicaciones en los modelos estadísticosViernes 30debateEvitar confusión por variables conocidas: Bloques aleatorizadosMartes 3 Muestreo dentro unidades experimentales: Diseños anidadosMércoles 4debateUnidades experimentales múltinivel y anidadas: Diseños de Parcelas divididasJueves 5 Modelos jerárquicos (incluye medidas repetidas)Viernes 6 Feria del diseño para discutir los protocolos de los estudiantes"
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#lecturas",
    "href": "posts/00-Bienvenida/index.html#lecturas",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Lecturas",
    "text": "Lecturas\nComo parte de las experiencias de aprendizaje que realizaremos tenemos tres lecturas. Les pedimos que hagan una lectura crítica de los textos propuestos y que preparen un comentario que contenga sus apreciaciones en favor o en contra de los argumentos presentados. También esperamos comenten sobre las implicaciones amplias y para la práctica científica en lo general, de los argumentos que exponen los autores. Sus reacciones tendrán oportunidad de ser expuestas y debatidas en un espacio del programa del módulo 3 a lo largo de 60 minutos.\n\n\nBorger, M. J., & Ramesh, A. (2025). Let’s DAG in: How Directed Acyclic Graphs Can Help Behavioural Ecology Be More Transparent. 292, :20250963.\n\n\nGiraldo, O. F. (2022). SABERES CAMPESINOS SITUADOS: FENOMENOLOGÍA DEL SABER VIVIENDO Y DEL SABER ESTANDO. Alter-nativa, 12, 120-138. https://revistas.unc.edu.ar/index.php/alter-nativa/article/view/40975\n\n\nSaltelli, A., Gigerenzer, G., Hulme, M., Katsikopoulos, K. V., Melsen, L. A., Peters, G. P., Pielke, R., Robertson, S., Stirling, A., Tavoni, M., & Puy, A. (2024). Bring digital twins back to Earth. WIREs Climate Change, 15(6), e915. https://doi.org/10.1002/wcc.915\n\n\n\n\n\n\n\n lectura 1: Borger \n\n\n lectura 2: Giraldo \n\n\n lectura 3: Saltelli"
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#evaluación",
    "href": "posts/00-Bienvenida/index.html#evaluación",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Evaluación",
    "text": "Evaluación\n\nEl Módulo 3 será evaluado a través de las tareas y controles de lectura que les pediremos que hagan conforme se desarrolle el curso. La participación en quizzes o cuestionarios en línea vía Vevox también será considerada."
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#instrucciones-para-participar",
    "href": "posts/00-Bienvenida/index.html#instrucciones-para-participar",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Instrucciones para participar",
    "text": "Instrucciones para participar\n\n\n\n\n\n\nTiplo que hay que hacer es\n\n\n\n\nEn tu computadora ir Vevox.app\nPara usar el celular instala Vevox desde la tienda de apps\n\n\n\n\n\n\n\n\n\n\n\n  &lt;/irame&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div id=\"quarto-navigation-envelope\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1zaWRlYmFyLXRpdGxl\"&gt;Curso de Estadística (Inecol 2026)&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1uYXZiYXItdGl0bGU=\"&gt;Curso de Estadística (Inecol 2026)&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWxnbyBtw6Fz\"&gt;Algo más&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1uYXZiYXI6QWNlcmNhIGRl\"&gt;Acerca de&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2Fib3V0Lmh0bWw=\"&gt;/about.html&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1uYXZiYXI6TTMtUHJlc2VudGFjaW9uZXM=\"&gt;M3-Presentaciones&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1uYXZiYXI6L3ByZXNlbnRhY2lvbmVzLmh0bWw=\"&gt;/presentaciones.html&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1uYXZiYXI6TTMtZWplcmNpY2lvcw==\"&gt;M3-ejercicios&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1uYXZiYXI6L2VqZXJjaWNpb3MuaHRtbA==\"&gt;/ejercicios.html&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLWludC1uYXZiYXI6aHR0cHM6Ly9naXRodWIuY29tL2VxdWlodWFtL00zLTIwMjZfY2F1c2FsaWRhZA==\"&gt;https://github.com/equihuam/M3-2026_causalidad&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div id=\"quarto-meta-markdown\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLW1ldGF0aXRsZQ==\"&gt;Bienvenidos al Módulo 3 de estadística – Curso de Estadística (Inecol 2026)&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkdGl0bGU=\"&gt;Bienvenidos al Módulo 3 de estadística – Curso de Estadística (Inecol 2026)&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLW9nY2FyZHRpdGxl\"&gt;Bienvenidos al Módulo 3 de estadística – Curso de Estadística (Inecol 2026)&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLW1ldGFzaXRlbmFtZQ==\"&gt;Curso de Estadística (Inecol 2026)&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLXR3aXR0ZXJjYXJkZGVzYw==\"&gt;&lt;/span&gt; &lt;span class=\"hidden quarto-markdown-envelope-contents\" data-render-id=\"cXVhcnRvLW9nY2FyZGRkZXNj\"&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;/section&gt;\n\n&lt;/main&gt; &lt;!-- /main --&gt;\n&lt;script id = \"quarto-html-after-body\" type=\"application/javascript\"&gt;\n  window.document.addEventListener(\"DOMContentLoaded\", function (event) {\n    // Ensure there is a toggle, if there isn't float one in the top right\n    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {\n      const a = window.document.createElement('a');\n      a.classList.add('top-right');\n      a.classList.add('quarto-color-scheme-toggle');\n      a.href = \"\";\n      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };\n      const i = window.document.createElement(\"i\");\n      i.classList.add('bi');\n      a.appendChild(i);\n      window.document.body.appendChild(a);\n    }\n    setColorSchemeToggle(hasAlternateSentinel())\n    const icon = \"\";\n    const anchorJS = new window.AnchorJS();\n    anchorJS.options = {\n      placement: 'right',\n      icon: icon\n    };\n    anchorJS.add('.anchored');\n    const isCodeAnnotation = (el) =&gt; {\n      for (const clz of el.classList) {\n        if (clz.startsWith('code-annotation-')) {                     \n          return true;\n        }\n      }\n      return false;\n    }\n    const onCopySuccess = function(e) {\n      // button target\n      const button = e.trigger;\n      // don't keep focus\n      button.blur();\n      // flash \"checked\"\n      button.classList.add('code-copy-button-checked');\n      var currentTitle = button.getAttribute(\"title\");\n      button.setAttribute(\"title\", \"Copiado\");\n      let tooltip;\n      if (window.bootstrap) {\n        button.setAttribute(\"data-bs-toggle\", \"tooltip\");\n        button.setAttribute(\"data-bs-placement\", \"left\");\n        button.setAttribute(\"data-bs-title\", \"Copiado\");\n        tooltip = new bootstrap.Tooltip(button, \n          { trigger: \"manual\", \n            customClass: \"code-copy-button-tooltip\",\n            offset: [0, -8]});\n        tooltip.show();    \n      }\n      setTimeout(function() {\n        if (tooltip) {\n          tooltip.hide();\n          button.removeAttribute(\"data-bs-title\");\n          button.removeAttribute(\"data-bs-toggle\");\n          button.removeAttribute(\"data-bs-placement\");\n        }\n        button.setAttribute(\"title\", currentTitle);\n        button.classList.remove('code-copy-button-checked');\n      }, 1000);\n      // clear code selection\n      e.clearSelection();\n    }\n    const getTextToCopy = function(trigger) {\n      const outerScaffold = trigger.parentElement.cloneNode(true);\n      const codeEl = outerScaffold.querySelector('code');\n      for (const childEl of codeEl.children) {\n        if (isCodeAnnotation(childEl)) {\n          childEl.remove();\n        }\n      }\n      return codeEl.innerText;\n    }\n    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {\n      text: getTextToCopy\n    });\n    clipboard.on('success', onCopySuccess);\n    if (window.document.getElementById('quarto-embedded-source-code-modal')) {\n      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {\n        text: getTextToCopy,\n        container: window.document.getElementById('quarto-embedded-source-code-modal')\n      });\n      clipboardModal.on('success', onCopySuccess);\n    }\n      var localhostRegex = new RegExp(/^(?:http|https):\\/\\/localhost\\:?[0-9]*\\//);\n      var mailtoRegex = new RegExp(/^mailto:/);\n        var filterRegex = new RegExp('/' + window.location.host + '/');\n      var isInternal = (href) =&gt; {\n          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);\n      }\n      // Inspect non-navigation links and adorn them if external\n     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');\n      for (var i=0; i&lt;links.length; i++) {\n        const link = links[i];\n        if (!isInternal(link.href)) {\n          // undo the damage that might have been done by quarto-nav.js in the case of\n          // links that we want to consider external\n          if (link.dataset.originalHref !== undefined) {\n            link.href = link.dataset.originalHref;\n          }\n        }\n      }\n    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {\n      const config = {\n        allowHTML: true,\n        maxWidth: 500,\n        delay: 100,\n        arrow: false,\n        appendTo: function(el) {\n            return el.parentElement;\n        },\n        interactive: true,\n        interactiveBorder: 10,\n        theme: 'quarto',\n        placement: 'bottom-start',\n      };\n      if (contentFn) {\n        config.content = contentFn;\n      }\n      if (onTriggerFn) {\n        config.onTrigger = onTriggerFn;\n      }\n      if (onUntriggerFn) {\n        config.onUntrigger = onUntriggerFn;\n      }\n      window.tippy(el, config); \n    }\n    const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]');\n    for (var i=0; i&lt;noterefs.length; i++) {\n      const ref = noterefs[i];\n      tippyHover(ref, function() {\n        // use id or data attribute instead here\n        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');\n        try { href = new URL(href).hash; } catch {}\n        const id = href.replace(/^#\\/?/, \"\");\n        const note = window.document.getElementById(id);\n        if (note) {\n          return note.innerHTML;\n        } else {\n          return \"\";\n        }\n      });\n    }\n    const xrefs = window.document.querySelectorAll('a.quarto-xref');\n    const processXRef = (id, note) =&gt; {\n      // Strip column container classes\n      const stripColumnClz = (el) =&gt; {\n        el.classList.remove(\"page-full\", \"page-columns\");\n        if (el.children) {\n          for (const child of el.children) {\n            stripColumnClz(child);\n          }\n        }\n      }\n      stripColumnClz(note)\n      if (id === null || id.startsWith('sec-')) {\n        // Special case sections, only their first couple elements\n        const container = document.createElement(\"div\");\n        if (note.children && note.children.length &gt; 2) {\n          container.appendChild(note.children[0].cloneNode(true));\n          for (let i = 1; i &lt; note.children.length; i++) {\n            const child = note.children[i];\n            if (child.tagName === \"P\" && child.innerText === \"\") {\n              continue;\n            } else {\n              container.appendChild(child.cloneNode(true));\n              break;\n            }\n          }\n          if (window.Quarto?.typesetMath) {\n            window.Quarto.typesetMath(container);\n          }\n          return container.innerHTML\n        } else {\n          if (window.Quarto?.typesetMath) {\n            window.Quarto.typesetMath(note);\n          }\n          return note.innerHTML;\n        }\n      } else {\n        // Remove any anchor links if they are present\n        const anchorLink = note.querySelector('a.anchorjs-link');\n        if (anchorLink) {\n          anchorLink.remove();\n        }\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(note);\n        }\n        if (note.classList.contains(\"callout\")) {\n          return note.outerHTML;\n        } else {\n          return note.innerHTML;\n        }\n      }\n    }\n    for (var i=0; i&lt;xrefs.length; i++) {\n      const xref = xrefs[i];\n      tippyHover(xref, undefined, function(instance) {\n        instance.disable();\n        let url = xref.getAttribute('href');\n        let hash = undefined; \n        if (url.startsWith('#')) {\n          hash = url;\n        } else {\n          try { hash = new URL(url).hash; } catch {}\n        }\n        if (hash) {\n          const id = hash.replace(/^#\\/?/, \"\");\n          const note = window.document.getElementById(id);\n          if (note !== null) {\n            try {\n              const html = processXRef(id, note.cloneNode(true));\n              instance.setContent(html);\n            } finally {\n              instance.enable();\n              instance.show();\n            }\n          } else {\n            // See if we can fetch this\n            fetch(url.split('#')[0])\n            .then(res =&gt; res.text())\n            .then(html =&gt; {\n              const parser = new DOMParser();\n              const htmlDoc = parser.parseFromString(html, \"text/html\");\n              const note = htmlDoc.getElementById(id);\n              if (note !== null) {\n                const html = processXRef(id, note);\n                instance.setContent(html);\n              } \n            }).finally(() =&gt; {\n              instance.enable();\n              instance.show();\n            });\n          }\n        } else {\n          // See if we can fetch a full url (with no hash to target)\n          // This is a special case and we should probably do some content thinning / targeting\n          fetch(url)\n          .then(res =&gt; res.text())\n          .then(html =&gt; {\n            const parser = new DOMParser();\n            const htmlDoc = parser.parseFromString(html, \"text/html\");\n            const note = htmlDoc.querySelector('main.content');\n            if (note !== null) {\n              // This should only happen for chapter cross references\n              // (since there is no id in the URL)\n              // remove the first header\n              if (note.children.length &gt; 0 && note.children[0].tagName === \"HEADER\") {\n                note.children[0].remove();\n              }\n              const html = processXRef(null, note);\n              instance.setContent(html);\n            } \n          }).finally(() =&gt; {\n            instance.enable();\n            instance.show();\n          });\n        }\n      }, function(instance) {\n      });\n    }\n        let selectedAnnoteEl;\n        const selectorForAnnotation = ( cell, annotation) =&gt; {\n          let cellAttr = 'data-code-cell=\"' + cell + '\"';\n          let lineAttr = 'data-code-annotation=\"' +  annotation + '\"';\n          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';\n          return selector;\n        }\n        const selectCodeLines = (annoteEl) =&gt; {\n          const doc = window.document;\n          const targetCell = annoteEl.getAttribute(\"data-target-cell\");\n          const targetAnnotation = annoteEl.getAttribute(\"data-target-annotation\");\n          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));\n          const lines = annoteSpan.getAttribute(\"data-code-lines\").split(\",\");\n          const lineIds = lines.map((line) =&gt; {\n            return targetCell + \"-\" + line;\n          })\n          let top = null;\n          let height = null;\n          let parent = null;\n          if (lineIds.length &gt; 0) {\n              //compute the position of the single el (top and bottom and make a div)\n              const el = window.document.getElementById(lineIds[0]);\n              top = el.offsetTop;\n              height = el.offsetHeight;\n              parent = el.parentElement.parentElement;\n            if (lineIds.length &gt; 1) {\n              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);\n              const bottom = lastEl.offsetTop + lastEl.offsetHeight;\n              height = bottom - top;\n            }\n            if (top !== null && height !== null && parent !== null) {\n              // cook up a div (if necessary) and position it \n              let div = window.document.getElementById(\"code-annotation-line-highlight\");\n              if (div === null) {\n                div = window.document.createElement(\"div\");\n                div.setAttribute(\"id\", \"code-annotation-line-highlight\");\n                div.style.position = 'absolute';\n                parent.appendChild(div);\n              }\n              div.style.top = top - 2 + \"px\";\n              div.style.height = height + 4 + \"px\";\n              div.style.left = 0;\n              let gutterDiv = window.document.getElementById(\"code-annotation-line-highlight-gutter\");\n              if (gutterDiv === null) {\n                gutterDiv = window.document.createElement(\"div\");\n                gutterDiv.setAttribute(\"id\", \"code-annotation-line-highlight-gutter\");\n                gutterDiv.style.position = 'absolute';\n                const codeCell = window.document.getElementById(targetCell);\n                const gutter = codeCell.querySelector('.code-annotation-gutter');\n                gutter.appendChild(gutterDiv);\n              }\n              gutterDiv.style.top = top - 2 + \"px\";\n              gutterDiv.style.height = height + 4 + \"px\";\n            }\n            selectedAnnoteEl = annoteEl;\n          }\n        };\n        const unselectCodeLines = () =&gt; {\n          const elementsIds = [\"code-annotation-line-highlight\", \"code-annotation-line-highlight-gutter\"];\n          elementsIds.forEach((elId) =&gt; {\n            const div = window.document.getElementById(elId);\n            if (div) {\n              div.remove();\n            }\n          });\n          selectedAnnoteEl = undefined;\n        };\n          // Handle positioning of the toggle\n      window.addEventListener(\n        \"resize\",\n        throttle(() =&gt; {\n          elRect = undefined;\n          if (selectedAnnoteEl) {\n            selectCodeLines(selectedAnnoteEl);\n          }\n        }, 10)\n      );\n      function throttle(fn, ms) {\n      let throttle = false;\n      let timer;\n        return (...args) =&gt; {\n          if(!throttle) { // first call gets through\n              fn.apply(this, args);\n              throttle = true;\n          } else { // all the others get throttled\n              if(timer) clearTimeout(timer); // cancel #2\n              timer = setTimeout(() =&gt; {\n                fn.apply(this, args);\n                timer = throttle = false;\n              }, ms);\n          }\n        };\n      }\n        // Attach click handler to the DT\n        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');\n        for (const annoteDlNode of annoteDls) {\n          annoteDlNode.addEventListener('click', (event) =&gt; {\n            const clickedEl = event.target;\n            if (clickedEl !== selectedAnnoteEl) {\n              unselectCodeLines();\n              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');\n              if (activeEl) {\n                activeEl.classList.remove('code-annotation-active');\n              }\n              selectCodeLines(clickedEl);\n              clickedEl.classList.add('code-annotation-active');\n            } else {\n              // Unselect the line\n              unselectCodeLines();\n              clickedEl.classList.remove('code-annotation-active');\n            }\n          });\n        }\n    const findCites = (el) =&gt; {\n      const parentEl = el.parentElement;\n      if (parentEl) {\n        const cites = parentEl.dataset.cites;\n        if (cites) {\n          return {\n            el,\n            cites: cites.split(' ')\n          };\n        } else {\n          return findCites(el.parentElement)\n        }\n      } else {\n        return undefined;\n      }\n    };\n    var bibliorefs = window.document.querySelectorAll('a[role=\"doc-biblioref\"]');\n    for (var i=0; i&lt;bibliorefs.length; i++) {\n      const ref = bibliorefs[i];\n      const citeInfo = findCites(ref);\n      if (citeInfo) {\n        tippyHover(citeInfo.el, function() {\n          var popup = window.document.createElement('div');\n          citeInfo.cites.forEach(function(cite) {\n            var citeDiv = window.document.createElement('div');\n            citeDiv.classList.add('hanging-indent');\n            citeDiv.classList.add('csl-entry');\n            var biblioDiv = window.document.getElementById('ref-' + cite);\n            if (biblioDiv) {\n              citeDiv.innerHTML = biblioDiv.innerHTML;\n            }\n            popup.appendChild(citeDiv);\n          });\n          return popup.innerHTML;\n        });\n      }\n    }\n  });\n  &lt;/script&gt;\n&lt;/div&gt; &lt;!-- /content --&gt;\n\n&lt;/body&gt;\n\n&lt;/html&gt;"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "",
    "text": "Lógica, probabilidad y heurística son tres ideas centrales en la historia del intelecto humano. A la aspiración de la lógica aristotélica se agregó a mediados del siglo XVII la teoría de las probabilidades, que matizó la certeza de la lógica al aportar una teoría con una postura más modesta en torno a la racionalidad. Su aparición ayudó a reconocer la existencia de una incertidumbre fundamental en la conducta humana. Einstein (1905) revaloró la intuición, con su uso de la noción de heurística,como recurso que recurre a la imaginación creativa y a la perspicacia de los seres humanos para descubrir cosas nuevas. Desde entonces el término ha florecido con matices diversos en todos los campos de la ciencia, la tecnología y las artes. Usamos estas tres herramientas para decidir científicamente, a veces suponiendo que reproducen la forma como opera nuestra mente. Veremos a continuación un ejemplo a este respecto que nos comparte McElreath (2020). Se trata del hipotético ejemplo de la prueba de sangre para vampirismo, que nos ayudaría a decidir si alguien es mortal o vampiro.\nInicia por pedirnos imaginar que hay un análisis de sangre que detecta correctamente 95% de las veces, la afiliación de un individuo al linaje del conde Drácula y los inmortales vampiros. En notación matemática:\n\\[\n{Pr[resultado~ positivo~de~la~prueba|vampiro]= 0.95}\n\\]\nEs una prueba muy precisa, casi siempre identificando vampiros reales. Sin embargo, también falla a veces y reporta falsos positivos. Es así que el uno por ciento de las pruebas realizadas diagnostican incorrectamente a simples mortales como vampiros:\n\\[\n{Pr[resultado~positivo~de~la~prueba|mortal]= 0.01}\n\\]\nLa última pieza de información que necesitamos es saber que los vampiros en realidad son bastante raros. Sólo el 0.1% de la población lo es (esta es la que llamamos probabilidad a priori), lo que anotamos así:\n\\[\n{Pr[vampiro]= 0.001}\n\\]\nA partir de este conocimiento científico, supongamos que un amigo da positivo en el test de vampirismo.\n\n\n\n\n\n\nTip¿Cuál es la probabilidad de que sea un inmortal chupasangre\n\n\n\n\n\nEl enfoque de investigación formal empezaría por usar el teorema de Bayes para deducir la probabilidad \\({Pr(vampiro|positivo)}\\), lo que en cierta forma implica “invertir la probabilidad”, pues lo que ahora sabemos es el valor de \\({Pr(positivo|vampiro)}\\). El cálculo puede presentarse como:\n\\[\nPr[vampiro|positivo]= \\frac{Pr[positivo|vampiro]\\times Pr[vampiro]}{Pr[positivo]}\n\\]\nen donde \\({Pr[positivo]}\\) es la probabilidad promedio de los resultados positivos de la prueba, es decir,\n\\[\nPr[positivo]= Pr[positivo|vampiro]\\times Pr[vampiro] + Pr[positivo|mortal] \\times ({1 − Pr[vampiro]})\n\\]\n\n\n\nTodo esto lo podemos hacer en R.\nPrimero tomamos nota de lo que ya sabemos a partir del enunciado anterior, ¡a priori! Por favor proporciona los datos requeridos en el recuadro siguiente.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSi queremos verificar los datos podemos verlos simplemente anotando el nombre de la tabla, en este caso: pr\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSi quisieras presentarla como una bonita tabla en tu reporte será mejor usar algo comoflextable o gt\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nTomamos la fórmula de Bayes para invertir la probabilidad, pues queremos saber qué está pasando cuando tenemos la fortuna o desgracia de toparnos con un resultado positivo en la prueba de sangre:\nEsto equivale a preguntarnos, dado que ya vimos el resultado científico que significa la prueba de sangre positiva, ¿será vampiro el sujeto de quien se obtuvo esa muestra?. Esta es una manera de estimar la probabilidad de que el amigo sea en realidad un vampiro, dado el conocimiento y la evidencia que tenemos a la mano.\n\\[\nPr[vampiro|positivo]\n\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nTip¿Encuentras este resultado afin o contrario a lo que pensabas antes de hacer los cálculos?\n\n\n\n\n\n\nQuizás para ayudar a apreciar lo que todo esto significa conviene recordar la frase que se atribuye al economista John Maynard Keynes:\n\nCuando las circunstancias cambian, yo cambio de opinión. ¿Tú que haces?”\n\nSi hubiera nueva evidencia disponible, el proceso se aplicaría en secuencia. Lo que lleva a la siguiente expresión que sugiere como se puede generalizar este proceso de razonamiento. Pero por ahora ya no ahondaremos más en esto.\n\\[\nPr[H|E_1,E_2] = \\frac{Pr[E_2|H,E_1] \\times Pr[H|E_1]} {Pr[E_2|E_1]}\n\\]\nEste es un resultado muy importante. Exactamente así, o algo muy parecido, es el procedimiento que se sigue en la realidad al efectuar pruebas diagnósticas: las pruebas de PCR, antígeno o anticuerpos para SarsCov-2, la prueba del VIH la del DNA en un perfil criminal, etc. La prueba de significancia estadística, ¿entrará en este mismo marco conceptual?.\nQuizás ayude a mejorar la intuición que tenemos de las cosas el considerar que siempre que la condición de interés sea muy rara, desarrollar una prueba excelente, capaz de diagnosticar bien todos los casos verdaderos (aunque inevitablemente produzca también algunos falsos positivos), puede no ser garantía suficiente de que un resultado positivo en general conlleve información categóricamente significativa.\nLa razón es que usualmente resulta inevitable tener falsos positivos y por simple aritmética, esos casos serán la mayoría de los resultados que tendremos, incluso si todos los verdaderos positivos fueran detectados correctamente.\nLa regla de Bayes es útil aquí, aunque, como dice McElreath, no es la única manera de razonar en este caso. Podríamos cuestionar que la ecuación que usamos aquí salio de la nada; aunque quizás la recuerdes de algún curso previo, de alguna charla interesante por ahí o incluso de lo que viste con Rosario ¡hace unas semanas!\nQuizás el ejemplo puede verse en forma más intuitiva utilizando otra narrativa para comprender lo que está ocurriendo. Digamos que en lugar de informar sobre las probabilidades, como hicimos arriba, te digo lo siguiente:\n\nEn una población de 100,000 personas, 100 son vampiros.\nDe los 100 que son vampiros 95 darán positivo en la prueba de vampirismo.\nDe los 99,900 simples mortales restantes, 999 darán positivo a la prueba de vampirismo.\n\nAhora piensa en esto, si hacemos pruebas a las 100,000 personas, ¿qué proporción de los que dan positivo en las pruebas de vampirismo son realmente vampiros?\nMuchas personas, aunque ciertamente no todas, encuentran esta forma de contar la historia mucho más fácil de comprender. Sigamos por este camino.\n\n\n\n\n\n\nTip¿Qué tal si contamos el número de personas que dan positivo?\n\n\n\n\n\nAnota los valores que consideres adecuados en el recuadro\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nDe este total de pruebas positivas, sabemos que sólo 95 provienen verdaderamente de vampiros, lo que nos lleva sencillamente a preguntarnos sobre la fracción que significa esa cantidad de vampiros entre la totalidad de pruebas positivas.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n¿Qué valor obtuviste?\nSi todo marcho bien deberías tener exactamente la misma respuesta que por el camino bayesiano que encontramos antes. La diferencia es que ahora, no tuvimos que recordar la “formula mágica” de Bayes, nada más tuvimos que imaginar la situación de otra manera y simplemente contar y pensar con calma.\nEsta forma de presentar el problema mediante el “conteo de los actores” en lugar de recurrir a probabilidades, suele denominarse formato de frecuencia o frecuencias naturales. En todo caso, lo importante es apreciar que el razonamiento puede beneficiarse de adoptar formas de razonamiento frugales e intuitivas (Gigerenzer y Gray 2017; Hicks et al. 2012).\nLas razones propuestas para explicar el por qué el formato de frecuencia ayuda a la gente a intuir el enfoque correcto siguen siendo polémicas. Podría ser que de entrada sólo podemos encontrarnos con conteos en el mundo real. Quizás sea cierto que nadie ha visto nunca una probabilidad andando por ahí. Independientemente de la explicación de este fenómeno, podemos explotarlo en muchas situaciones cotidianas.\n\n\n\nLos eventos muestreados en el análisis de las distribuciones de probabilidades de modelos estadísticos en algún análisis de datos, son los valores de los parámetros. La mayoría de los parámetros no tienen una “materialización” empírica exacta.\nEl formalismo bayesiano trata las distribuciones de los parámetros como una plausibilidad relativa, no como un proceso aleatorio que ocurre en el mundo físico. En cualquier caso, la aleatoriedad es siempre una propiedad de la información, nunca del mundo real. Para continuar explorando esta idea puede interesarte los textos de Gigerenzer sobre la importancia de la intuición.\n\n\n\nEl ejemplo del vampirismo que acabamos de ver tiene la misma estructura lógica que muchos problemas de detección considerando que:\n\nHay algún estado binario al que no tenemos acceso.\nObservamos un indicio imperfecto del estado oculto.\n(Deberíamos/podríamos) usar el teorema de Bayes para deducir lógicamente el impacto del indicio en nuestra incertidumbre (aunque ve lo que salió en el periódico)\n\nLa inferencia científica puede enmarcase en términos similares:\n\nUna hipótesis es verdadera o falsa, pero no lo sabemos todavía;\nObtenemos un indicio estadístico de la falsedad de la hipótesis;\nPodemos utilizar el teorema de Bayes para deducir lógicamente el impacto del indicio en el estado de la hipótesis.\n\nEs el tercer paso el que casi nunca se hace. Sin debatir por lo pronto si debemos o no usar a Bayes, consideremos por un momento la idea como un ejemplo de juguete.\n\n\n\n\n\nSupongamos que la probabilidad de obtener un hallazgo positivo, cuando la hipótesis postulada es cierta, es \\({Pr[señal~detectada | verdadera]=Pr[d | H]= 0.95}\\).\nEse es lo que se suele llamar la potencia de la prueba.\n\n\n\nSupongamos que la probabilidad de un hallazgo positivo, cuando una hipótesis es falsa, es \\({Pr[señal~detectada|falsa]= Pr[d | \\neg H]= 0.05}\\).\nEsa es la tasa de falsos positivos, digamos 5%, de la prueba de significancia que usamos convencionalmente.\n\n\n\nFinalmente, tenemos que establecer la tasa base con la que ocurren las hipótesis que son verdaderas. Supongamos, por ejemplo, que 1 de cada 100 hipótesis resulta ser verdadera. Entonces \\({Pr[verdadero]= Pr(H) = 0.01}\\).\nEn realidad nadie conoce este valor ni se ve posible conocerlo, pero la historia de la ciencia sugiere que es pequeño.\n\n\n\nSe trata de una proposición que hemos aventurado para explicar algo, que resulta ser cierta y que hemos obtenido alguna prueba que calificamos de positiva para reconocerla . Para averiguar esto hay que calcular la probabilidad a posteriori:\n\\[\n\\begin{align*}\nPr[Hipótesis|detección]&= \\frac{Pr[detección|Hipótesis] \\cdot Pr(Hipótesis)} {Pr(detección)} =\\\\\n& = \\frac{Pr[d | H] \\cdot Pr[H)} {Pr(d|H] \\cdot Pr[H]+ Pr[d | \\neg H] \\cdot Pr(\\neg H)} = Pr[H|d]\\\\\n\\end{align*}\n\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAl substituir los valores imaginados y hacer los cálculos obtenemos una esimación de que tan probable es que sea cierta la hipótesis propuesta, dado que observamos un resultado positivo (\\({Pr[H|d]}\\)).\n¿Qué valor obtuviste? Observa que este valor muestra el mismo patrón de baja tasa de base que se aplica en las pruebas médicas (y también en nuestro ejemplo de vampiros).\n\n\n\n\n\n\nAdvertencia¿Podremos mejorar la práctica científica?\n\n\n\n\n\n\n\n\n\n\n\n\nNotaExperimentos pensados\n\n\n\n\n\nUna manera de explorar lo que puede pasar en distintos escenarios asumiendo un razonamiento específico, nos da oportunidad de valorar la utilidad de hacer un escript, algoritmo o programa. Así podemos automatizar una tarea repetitiva y potencialmente aburrida para ver las implicaciones de la idea en todo tipo de situaciones. Quizás podríamos considerarlo semejante a lo que Einstein llamaba experimento pensado. Veamos como hacerlo.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHemos definido un programa como una función en R. Esta función puede tomar datos y procesarlos de acuerdo con la lógica que le hemos especificado.\nAhora podemos experimentar para tener una idea aproximada de lo que está pasando.\n\nElegimos una serie de valores de interés (cada uno sería un escenario)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPreparamos un espacio en la memoria para anotar los resultados.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nVeamos los resultados del experimento con ayuda de una gráfica.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nUna investigación muy exigente que reduce la detección de falsos positivos a 1%, ¿hasta cuánto nos permite llevar la probabilidad posterior de descubrimientos exitosos?\nPodemos pensar que lo que hemos hecho hasta aquí es prácticamente un juego, pero ¿qué tan cercano podría ser a lo que ocurre en la vida real? y si fuera una razonable aproximación ¿a qué nos conduce?\n\n\n\n¿Lo más importante es mejorar la probabilidad de detección base, \\(Pr(H)\\)?\n¿Qué implicaría y cómo se podría lograr mejorar \\(Pr(H)\\)?\n¿Es posible hacer que \\(Pr[H]\\) crezca?\n¿Habrá que incrementar siempre el número de veces que se repite el tratamiento?\n¿Sólo aceptar como significativos resultados muy altamente significativos?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFuente: Stoddart, C. (2016). Is there a reproducibility crisis in science?. Nature\n\n\n\n\n\n\n\n\n\n\nTip¿Ha mejorado la situación?\n\n\n\n\n\n\n\n\nLa falta de reproducibilidad de los experimentos se traduce en artículos que son cuestionados y se ven forzados a retirarse. Claro, no es la única razón para retirar un artículo, pero si la más frecuente. A fines del año pasado salió esta noticia en Nature.\n\n\n\n\n \n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\nSin duda la forma como hemos optado por hacer ciencia está teniendo problemas que debemos afrontar. La cuestión es que podemos o más bien que debemos hacer para enfrentarlos productivamente y así producir una ciencia mejor.\n\n\n\n\n\n\nTipBuscar la verdad\n\n\n\n\n\n\n\n\n\nLa búsqueda de la verdad siempre debería prevalecer sobre el deseo defensivo del ego de tener la razón. Esto no es fácil, porque a la mayoría de la gente le resulta difícil admitir que se equivoca. Y es precisamente por esto por lo que la ciencia resulta tan liberadora. Provee un marco de trabajo para la autocorrección, porque el conocimiento científico siempre es provisional. Un hecho científico aceptado hoy puede ser refutado mañana. Por tanto, el método científico engendra humildad epistemológica.\n\n\n\n \n\n\n\n\n\n\nGad Saad\n\n\n\n\n\n\nReflexión sobre prepublicación\nEcoEvorxiv\npreprints.org\nNature\nOpen Science Facility\nScience"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#estadística-para-mejorar-la-ciencia",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#estadística-para-mejorar-la-ciencia",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "",
    "text": "El ejemplo del vampirismo que acabamos de ver tiene la misma estructura lógica que muchos problemas de detección considerando que:\n\nHay algún estado binario al que no tenemos acceso.\nObservamos un indicio imperfecto del estado oculto.\n(Deberíamos/podríamos) usar el teorema de Bayes para deducir lógicamente el impacto del indicio en nuestra incertidumbre (aunque ve lo que salió en el periódico)\n\nLa inferencia científica puede enmarcase en términos similares:\n\nUna hipótesis es verdadera o falsa, pero no lo sabemos todavía;\nObtenemos un indicio estadístico de la falsedad de la hipótesis;\nPodemos utilizar el teorema de Bayes para deducir lógicamente el impacto del indicio en el estado de la hipótesis.\n\nEs el tercer paso el que casi nunca se hace. Sin debatir por lo pronto si debemos o no usar a Bayes, consideremos por un momento la idea como un ejemplo de juguete.\n\n\n\n\n\nSupongamos que la probabilidad de obtener un hallazgo positivo, cuando la hipótesis postulada es cierta, es \\({Pr[señal~detectada | verdadera]=Pr[d | H]= 0.95}\\).\nEse es lo que se suele llamar la potencia de la prueba.\n\n\n\nSupongamos que la probabilidad de un hallazgo positivo, cuando una hipótesis es falsa, es \\({Pr[señal~detectada|falsa]= Pr[d | \\neg H]= 0.05}\\).\nEsa es la tasa de falsos positivos, digamos 5%, de la prueba de significancia que usamos convencionalmente.\n\n\n\nFinalmente, tenemos que establecer la tasa base con la que ocurren las hipótesis que son verdaderas. Supongamos, por ejemplo, que 1 de cada 100 hipótesis resulta ser verdadera. Entonces \\({Pr[verdadero]= Pr(H) = 0.01}\\).\nEn realidad nadie conoce este valor ni se ve posible conocerlo, pero la historia de la ciencia sugiere que es pequeño.\n\n\n\nSe trata de una proposición que hemos aventurado para explicar algo, que resulta ser cierta y que hemos obtenido alguna prueba que calificamos de positiva para reconocerla . Para averiguar esto hay que calcular la probabilidad a posteriori:\n\\[\n\\begin{align*}\nPr[Hipótesis|detección]&= \\frac{Pr[detección|Hipótesis] \\cdot Pr(Hipótesis)} {Pr(detección)} =\\\\\n& = \\frac{Pr[d | H] \\cdot Pr[H)} {Pr(d|H] \\cdot Pr[H]+ Pr[d | \\neg H] \\cdot Pr(\\neg H)} = Pr[H|d]\\\\\n\\end{align*}\n\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAl substituir los valores imaginados y hacer los cálculos obtenemos una esimación de que tan probable es que sea cierta la hipótesis propuesta, dado que observamos un resultado positivo (\\({Pr[H|d]}\\)).\n¿Qué valor obtuviste? Observa que este valor muestra el mismo patrón de baja tasa de base que se aplica en las pruebas médicas (y también en nuestro ejemplo de vampiros).\n\n\n\n\n\n\nAdvertencia¿Podremos mejorar la práctica científica?\n\n\n\n\n\n\n\n\n\n\n\n\nNotaExperimentos pensados\n\n\n\n\n\nUna manera de explorar lo que puede pasar en distintos escenarios asumiendo un razonamiento específico, nos da oportunidad de valorar la utilidad de hacer un escript, algoritmo o programa. Así podemos automatizar una tarea repetitiva y potencialmente aburrida para ver las implicaciones de la idea en todo tipo de situaciones. Quizás podríamos considerarlo semejante a lo que Einstein llamaba experimento pensado. Veamos como hacerlo.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHemos definido un programa como una función en R. Esta función puede tomar datos y procesarlos de acuerdo con la lógica que le hemos especificado.\nAhora podemos experimentar para tener una idea aproximada de lo que está pasando.\n\nElegimos una serie de valores de interés (cada uno sería un escenario)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPreparamos un espacio en la memoria para anotar los resultados.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nVeamos los resultados del experimento con ayuda de una gráfica.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nUna investigación muy exigente que reduce la detección de falsos positivos a 1%, ¿hasta cuánto nos permite llevar la probabilidad posterior de descubrimientos exitosos?\nPodemos pensar que lo que hemos hecho hasta aquí es prácticamente un juego, pero ¿qué tan cercano podría ser a lo que ocurre en la vida real? y si fuera una razonable aproximación ¿a qué nos conduce?\n\n\n\n¿Lo más importante es mejorar la probabilidad de detección base, \\(Pr(H)\\)?\n¿Qué implicaría y cómo se podría lograr mejorar \\(Pr(H)\\)?\n¿Es posible hacer que \\(Pr[H]\\) crezca?\n¿Habrá que incrementar siempre el número de veces que se repite el tratamiento?\n¿Sólo aceptar como significativos resultados muy altamente significativos?"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#crisis-de-reproducibilidad",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#crisis-de-reproducibilidad",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "",
    "text": "Fuente: Stoddart, C. (2016). Is there a reproducibility crisis in science?. Nature\n\n\n\n\n\n\n\n\n\n\nTip¿Ha mejorado la situación?\n\n\n\n\n\n\n\n\nLa falta de reproducibilidad de los experimentos se traduce en artículos que son cuestionados y se ven forzados a retirarse. Claro, no es la única razón para retirar un artículo, pero si la más frecuente. A fines del año pasado salió esta noticia en Nature.\n\n\n\n\n \n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\nSin duda la forma como hemos optado por hacer ciencia está teniendo problemas que debemos afrontar. La cuestión es que podemos o más bien que debemos hacer para enfrentarlos productivamente y así producir una ciencia mejor.\n\n\n\n\n\n\nTipBuscar la verdad\n\n\n\n\n\n\n\n\n\nLa búsqueda de la verdad siempre debería prevalecer sobre el deseo defensivo del ego de tener la razón. Esto no es fácil, porque a la mayoría de la gente le resulta difícil admitir que se equivoca. Y es precisamente por esto por lo que la ciencia resulta tan liberadora. Provee un marco de trabajo para la autocorrección, porque el conocimiento científico siempre es provisional. Un hecho científico aceptado hoy puede ser refutado mañana. Por tanto, el método científico engendra humildad epistemológica.\n\n\n\n \n\n\n\n\n\n\nGad Saad"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#prerregistro-y-prepublicación",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#prerregistro-y-prepublicación",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "",
    "text": "Reflexión sobre prepublicación\nEcoEvorxiv\npreprints.org\nNature\nOpen Science Facility\nScience"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#anova",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#anova",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "ANOVA",
    "text": "ANOVA\n\nConceptos básicos (modelo de una vía, un criterio, completamente aleatorizado)\nHay situaciones en las que la información que tenemos para predecir una respuesta la tenemos en forma cualitativa, incluso la presencia o ausencia de una categoría. Una variable categórica es una medición discreta y las clases no tienen ningún orden particular. Por ejemplo, consideremos que entre los antropoides algunas especies son simios, mientras que otras son monos del Nuevo Mundo. Podríamos preguntarnos cómo deberían variar las predicciones cuando la especie es un simio en lugar de un mono. El grupo taxonómico es una variable categórica, porque ninguna especie puede ser mitad simio y mitad mono (discreción), y no hay ningún sentido en el que uno sea más grande o más pequeño que el otro (desorden). Otros ejemplos comunes de variables categóricas son:\n\nSexo: macho, hembra\nEstado de desarrollo: lactante, juvenil, adulto\nRegión geográfica: África, Europa, Melanesia\n\nAlgunos de ustedes ya sabrán que variables como esta, llamadas rutinariamente factores, pueden ser fácilmente incluidas en los modelos lineales. Pero lo que no resulta tan intuitivo es la forma cómo se representan estas variables en un modelo. El ordenador hace todo el trabajo por nosotros, ocultando la maquinaria.\nLa hipótesis nula en un análisis de la varianza tipo I común es:\n\\[\nH_0: m_1 = m_2 = m_3 = ... = m_k\n\\]\n\n\n\n\n\n\nTip¿Cómo es que esta hipótesis se pone a prueba en un ANDEVA?\n\n\n\nPor cierto esta es una prueba “ómnibus”, es decir ¡prueba todo (la igualdad de todas las medias) de un jalón!\n\n\nPara ver como es que opera el anova veamos el ejemplo que sigue. Considera un solo factor, “\\(f\\)”, con dos niveles.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nPongamos estos datos en una gráfica simple, según el orden en el que fueron obtenidas las mediciones. Lo primero que haremos es definir la tabla de datos anova.data, como espacio de trabajo. Haremos esto con la función attach(). Esto hace que las variables contenidas en la tabla se puedan llamar directamente sin tener que anteponer el nombre de la estructura que las contiene. Esto es conveniente, pero si olvidamos regresar al espacio general de trabajo, con la función detach(), podemos encontrarnos con situaciones algo extrañas. En caso de que eso ocurra, resulta útil la función search(), que muestra los espacios de trabajo activos.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nTip¿Qué muestra esta gráfica? ¿a que equivale la suma de los trazos verticales?\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nAhora incorporemos la información del factor \\(f\\). Para esto hay que calcular los promedios de “y” que corresponden a los niveles de \\(f\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nGrafiquemos esta nueva estructura de datos.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nTip¿Qué muestra esta gráfica? ¿a que equivale la suma de los trazos verticales?\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nSi las dos medias fueran iguales ¿cómo compararían estas dos gráficas?\n\n\n\n\n\n\n\n\n\nTip¿Qué interpretación tiene la diferencia entre las dos sumas mencionadas arriba?\n\n\n\n\n\nEsta diferencia se asocia con la siguiente gráfica:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAhora la suma de estas líneas verticales es\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nEstas tres formas de calcular las distancias entre datos y promedios se asocia con fuentes de variación\n\nvariaciones en las observaciones o error total\nvariaciones intrínsecas de los sujetos o error residual (componente aleatorio/efecto aleatorio)\nvariaciones por efecto del factor causal o error del modelo (componente sistemático/efecto fijo)\n\nEn el cuadro de análisis de varianza se suele etiquetar a los componentes de error de acuerdo con su fuente. Se les acompaña con los grados de libertad, la suma de cuadrados de las distancias que mostré en las tres gráficas anteriores y luego los llamados cuadrados medios. Para referencia podemos pedirle a R que nos reporte el cuadro de ANOVA de este modelo.\n\n\n\n\n\n\nTipAnaliza la correspondencia entre los valores y las gráficas que vimos arriba con lo que reporta R\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#dag-de-un-diseño-experimental-simple",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#dag-de-un-diseño-experimental-simple",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "DAG de un diseño experimental simple",
    "text": "DAG de un diseño experimental simple\nUn experimento con asignación de tratamientos en forma completamente al azar, garantiza al máximo posible las vías de influencias ocultas o inadvertidas. Por diseño, la respuesta de las unidades experimentales, Y, al tratamiento T sólo tiene a la asignación aleatoria A como única causa que antecede al tratamiento. Esto lo podemos representar con el diagrama acíclico dirigido, DAG, siguiente:\n\\[\n\\fbox{A} \\rightarrow T \\rightarrow Y\n\\]\nEn este DAG, el marco que rodea a la A indica aleatorización, y como sugiere el diagrama, es la única causa que actúa sobre el tratamiento. Si hubiera una vía de influencia alternativa (backdoor), a través de alguna tercera variable como podría ser en un caso de germinación de semillas, la luminosidad del sitio o el grado de humedad en el sustrato; entonces, la aleatorización no sería el único factor que influiría sobre el tratamiento. El recuadro alrededor de A (el proceso de aleatorización) indica que no existen otros factores actuando sobre T, es decir, A es una influencia puramente estocástica. Esta idea y el proceso de realización de un experimento controlado con aleatorización, da cuenta con toda claridad del valor de esta forma de realizar estudios para desentrañar relaciones de causalidad.\nEste DAG nos conduce al modelo linear siguiente\n\\[\ny = \\mu + T +  \\varepsilon\n\\]\nEn donde y son las mediciones de la variable Y en respuesta al efecto de T, \\(\\mu\\) es un valor de referencia general (tradicionalmente la media general de la variable Y, aunque puede elegirse cualquier otro valor de referencia que convenga al estudio) y la épsilon da cuenta del efecto aleatorio inducido por \\(\\fbox{A}\\), por lo que es necesario postular una distribución de probabilidades apropiada para caracterizar su comportamiento."
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#la-tradición-de-prueba-de-hipótesis",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#la-tradición-de-prueba-de-hipótesis",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "La tradición de prueba de hipótesis",
    "text": "La tradición de prueba de hipótesis\nEl planteamiento de la prueba de significancia estadística de hipótesis se pueden encontrar ya en el siglo XIX, su formalización teórica realmente ocurre en los años 20 y 30 del siglo XX con las publicaciones de Sir Ronald Fisher, Jerzy Neyman y Egon Pearson.\nEntre estos autores existieron diferencias filosóficas y conceptuales entre sus planteamientos y posturas. En especial Fisher y Neyman sostuvieron acres debates que sólo se interrumpieron con el fallecimiento de Fisher en 1962. No obstante el debate continua hasta hoy.\nEl resultado es que el uso actual de la prueba estadística de hipótesis se ha conformado como un extraño híbrido surgido de una mezcla más o menos ecléctica de las dos formas de pensar y no tanto una teoría coherente sobre la prueba de hipótesis.\n\nEl procedimiento\nEl objetivo de una prueba de significancia es hacer inferencias sobre un parámetro que el investigador concibe asociado a un atributo numérico relevante de la población que define su objetivo de investigación. El procedimiento utiliza como base los datos de una muestra extraída de esa población. El enfoque se opera específicamente como un instrumento para excluir un valor o una gama de valores específicos como plausibles para el parámetro.\n\nEl paso a paso del formalismo de prueba de hipótesis\n\nConstruir un modelo estadístico. Se trata de un conjunto de supuestos sobre las variables de interés.\nEspecificar la hipótesis nula.\nDefinir un estadístico de contraste (frecuentemente llamada “la prueba estadística”).\nIdentificar la distribución del estadístico de contraste bajo los supuestos del modelo.\nCalcular, bajo el supuesto de la hipótesis nula, el valor del estadístico de contraste en la muestra observada.\nCalcular la probabilidad de tener un valor del estadístico como el resultante o un valor más extremo en la distribución de referencia (el famosos valor p).\nAceptar o rechazar la hipótesis nula. Si el valor p es menor que el criterio α de significancia (especificado a priori), se rechaza la hipótesis nula, en el caso contrario se acepta o por lo menos no se rechaza (por lo pronto).\n\nRechazar la hipótesis nula es algo que quizás produce poca tensión emocional, quizás hasta un alivio, finalmente, el investigador sospecha (desea mostrar) que lo interesante está en otra parte, en su juego de hipótesis alternativas.\n\n\n\n\n\n\n¿Es este procedimiento afín al falsacionismo Popperiano?.\n\n\n\nPara interpretar correctamente un valor p se necesita tener claro que se opera dentro de una marco conceptual frecuentista. Esto lleva a que se conciba a los parámetros del modelo estadístico como constantes en la población objetivo (valor fijo que nunca se conoce en realidad).\nAdemás se asume que, al menos conceptualmente, sería posible repetir el experimento un número infinito de veces. También se asume que siempre se está muestreando la misma población objetivo (universo muestral) así que los parámetros tienen el mismo valor, pero las muestras fluctúan aleatoriamente.\nBajo estos supuestos es aceptable considerar que el estadístico de prueba se distribuye de acuerdo con el modelo de probabilidades propuesto para construir el contraste y por lo tanto da cuenta de las variaciones esperadas entre las diferentes repeticiones del experimento.\nEn la aproximación tradicional a la contrastación estadística de hipótesis (frecuentista) se parte de la formulación de proposiciones hipotéticas que son descritas con referencia a alguna distribución de probabilidades.\nEn este marco conceptual, un componente es la llamada hipótesis nula (\\(H_{0}\\)). Se concibe como un planteamiento que asume la ausencia de efecto de los “factores explicativos”.\nEn contraste se propone una o más hipótesis alternativas (\\(H_{1...n}\\)), en las que se valora algún o algunos efectos de los “factores explicativos”. La proposición hipotética que hacemos se traduce en valores que podemos comparar con un conjunto de valores a los que consideramos observados. La diferencia entre estos dos conjuntos de valores nos permiten valorar la factibilidad de nuestra proposición.\n\nEn la práctica, suele ocurrir que se concentre la atención en la hipótesis nula expresada con la gran simplicidad que implica la ausencia de efectos y se proceda con menor rigurosidad el análisis de la hipótesis alternativa, la que suele procesarse en forma más bien exploratoria mediante procedimientos de comparaciones múltiples.\n\n\nCríticas\nEntre las críticas que se han hecho al procedimiento clásico de prueba de hipótesis está la que señala que el valor p, al excluir el valor de cero como valor plausible para el parámetro, no aporta información completa sobre los valores que sí son plausibles. Esto implica que la significancia estadística no implica relevancia práctica.\n\n\n\n\n\n¿Cómo interpretas esta afirmación?\n\n\n\nEn el mismo razonamiento, un “valor de p extremadamente significativo” no hace otra cosa que excluir el cero como valor plausible para el parámetro no precisamente sobre la calidad del hallazgo.\nOtra crítica señala que interpretar el valor p en términos de evidencia en contra de la hipótesis nula (siguiendo el pensamiento de Fisher) o la plausibilidad de que la hipótesis nula sea falsa a veces se expresan equivocadamente como la probabilidad de que la hipótesis nula sea falsa en consideración de la evidencia (E) disponible. Al plantearlo así, formalmente se enuncia como \\(P(H_{0}|E)\\). Pero esto no es apropiado, formalmente resulta ser una inconsistencia en la lógica del planteamiento.\n\n\n\n\n\n¿Puedes reconocer esta inconsistencia?\n\n\n\nLa inconsistencia está en que, en primer lugar como dije arriba, el valor p se define dentro del marco frecuentista y se concibe que los parámetros son valores constantes, aunque desconocidos (¡supuesto estadístico de efectos fijos!). No se trata de los parámetros de alguna distribución de probabilidades (observada o no). Por tanto, no tiene sentido asignar probabilidades a los distintos valores estimados del parámetro.\nAdemás, el valor p se calcula bajo el supuesto de que la hipótesis nula es cierta; esto hace imposible, por construcción, interpretarlo como la probabilidad de que la hipótesis alternativa sea cierta. La probabilidad a la que se refiere el valor p guarda más relación con la probabilidad inversa, \\(P(E|H{0})\\). ¿Qué tan probable sería tener una muestra como la que tenemos enfrente, si la hipótesis nula considerada fuera cierta?. Esto se conoce como la verosimilitud, es decir, la probabilidad de observar los datos que se han obtenido en un estudio suponiendo que los atributos del modelo fueran ciertos. La verosimilitud valora a la muestra como un resultado condicional a los supuestos hechos en el modelo estadístico y en este caso, la hipótesis nula.\nSin embargo, la probabilidad que realmente interesa es la anteriormente mencionada \\(P(H_{0}|E)\\). Aunque no está definida dentro del marco frecuentista, en el marco Bayesiano sí se define. Las probabilidades \\(P(E|H_{0})\\) y \\(P(H_{0}|E)\\) no son iguales.\n\n\n\n\n\n¿Recuerdas qué representa cada uno de ellas?\n\n\n¿Cuál es la relación entre ambas?\n\n\n\nOtra crítica interesante surge de la llamada paradoja de Lindley (1957), quien mostró, con una formulación Bayesiana, que existe la posibilidad de tener datos congruentes con rechazar una hipótesis nula con un bajo valor p y que al mismo tiempo llevan a una probabilidad posterior alta.\nEncontró que es perfectamente posible, a partir de los mismos datos E, obtener al mismo tiempo una \\(P(E|H_{0})\\) = 0.05 (baja probabilidad de obtener una muestra como la que se observó, si \\(H_{0}\\) fuera cierta) y \\(P(H_{0}|E)\\) = 0.95 (fuerte evidencia en favor de \\(H_{0}\\)). Este resultado contradictorio permite ver lo cuestionable que resulta interpretar el valor p como evidencia en contra de la hipótesis nula.\nSe ha contra argumentado que la paradoja requiere muestras grandes para manifestarse, y se oponen a los supuestos adicionales que requiere el análisis Bayesiano. Se ha defendido que bajo condiciones razonables, un bajo valor p generalmente implica una baja probabilidad posterior, es decir, poca evidencia para la hipótesis nula. Sin embargo, a pesar de esta defensa al enfoque clásico, se ha encontrado que los valores p sistemáticamente sobrestiman la evidencia en contra de la hipótesis nula.\nEn resumen, el valor mismo de p, resultado de una prueba clásica de hipótesis, no aporta mucha información de interés para los investigadores. En caso de optar por la hipótesis alternativa con base en la p, no se favorece llegar a ninguna conclusión sustancial sobre posibles explicaciones alternativas, lo único que queda claro es que la nula probablemente es falsa.\nPara que quede claro, hay que insistir en que si el valor p es juzgado significativo, únicamente nos inclina a excluir un solo valor como estimador plausible para el parámetro. Peor aún, el significado de plausible en la última expresión tiene una relación nebulosa con la probabilidad que sí le interesa a los investigadores: la probabilidad posterior de que la hipótesis nula sea cierta a la luz de la evidencia recopilada \\(P(H_{0}|E)\\).\n\n\n\n\n\n\nTip¿Qué piensas de la paradoja de Lindley y sus implicaciones\n\n\n\n\n\n\n\n\nRemedios y alternativas para la prueba estadística de la hipótesis nula\nPara enfrentar algunos de los inconvenientes del enfoque clásico de prueba de hipótesis se ha recomendado ahora sustituir el valor p por un intervalo de confianza que abarca un conjunto de valores que permiten valorar si es razonable rechazar la hipótesis nula y además, en caso contrario proporciona una gama de valores que caracterizan al parámetro, lo que resulta de mucho interés.\nLa práctica de presentar intervalos de confianza, posiblemente en conjunto con p, constituye una respuesta a la crítica de que sólo se excluye un valor como valor plausible para el parámetro. Además, hacer esto proporciona información sobre significancia. Si el intervalo no incluye el valor de cero, entonces se declararía el resultado como estadísticamente significativo. El intervalo informa también sobre el posible tamaño del efecto.\nA la luz de las críticas, Muchos autores ven necesario actualmente adoptar el marco Bayesiano para enfrentar las deficiencias del enfoque clásico. También queda claro que el falsacionismo no resulta ser un camino inequívoco, cosa que ya advertía el mismo Popper, aunque no al extremo de la tesis Duhem-Quine (Kemeny 1952), que sostiene la imposibilidad de hacer experimentos cruciales.\n\n\nPotencia de la prueba\nEn la práctica, la potencia de la prueba depende del grado de dispersión en los datos. Si se está asumiendo un modelo de probabilidades Gaussiano (distribución normal), el factor de dispersión o escala se relaciona con la varianza. Por lo tanto, es usual notar que el mismo cálculo del error estándar, \\(s_{e}=\\frac{\\sigma}{\\sqrt{n}}\\), sugiere la solución.\n\n\nSe puede incrementar el tamaño de muestra, n,\n\n\n\n\n\n\n\nTip¿Por qué funcionaría esto?\n\n\n\n\n\n\n\nAumentar la precisión con la que se estima \\(\\sigma^2\\),\n\n\n\n\n\n\n\nTip¿Cómo se puede hacer esto?\n\n\n\n\n\n\nEs interesante apreciar, que la búsqueda de un tamaño de muestra apropiado para un estudio que estemos planeando, se puede lograr muy eficazmente haciendo simulaciones como las que hemos estado viendo en este bloque del curso. A través de este camino y haciendo el esfuerzo de especificar hipótesis alternativas relevantes se pueden resolver preguntas como:\n\n¿Cuál es el tamaño de muestra necesario para detectar una cierta diferencia en lo que medimos?\n¿Cuál es la diferencia detectable dada una n o una potencia de la prueba (\\(1-\\beta\\))?\n¿Cuál es la potencia (\\(1-\\beta\\)) dado un n y cierta diferencia con \\(H_{a}\\) de interés?\n\n\n\nQuiz: Prueba estadística de hipótesis\nParticipa: vevox.app ID: 125-688-362"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#disposición-de-tratamientos-e-intereses-sobre-los-factores",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#disposición-de-tratamientos-e-intereses-sobre-los-factores",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "Disposición de tratamientos e intereses sobre los factores",
    "text": "Disposición de tratamientos e intereses sobre los factores\n\nEfectos fijos\nQuizás la forma más simple de identificar las variables explicativas que tienen efectos fijos es pensar en ellas como variables cuyos niveles identifican en forma completa las condiciones de interés para el investigador. Por ejemplo, en el caso de un experimento que analiza el desempeño de larvas de mariposa que toman una dieta rica en proteínas y al mismo tiempo están expuestas a la presencia o no de un alcaloide. Estamos interesados precisamente en esas dietas y en la presencia o no del alcaloide. Estos dos factores son fijos. Es el tipo de variables que normalmente consideramos en nuestros objetivos de investigación. Se asume que su identificación y definición es completa, se asume que no hay más niveles de interés que los definidos y por lo tanto el modelo resultante no puede utilizarse para predecir fuera del ámbito de esas definiciones.\n\n\nEfectos aleatorios\nLas variables de efectos aleatorios surgen cuando se considera que el factor considerado no es sino una muestra de los posibles resultados que se pueden obtener de muestrear la condición que caracteriza el factor. Por ejemplo, si en un experimento para explorar la germinación de Bouteloua gracilis bajo distintas condiciones de temperatura en campo, se distribuyen las semillas en varios sitios de una zona de interés. Los aprecia que hay básicamente dos tipos de ambiente, suelos arenosos y suelos con algo de grava, así que se eligen 5 sitios en cada condición, y en cada uno de ellos se ponen a prueba dos tratamientos, “pisoteo por ganado” y “sin pisoteo por ganado”. Los 10 sitios elegidos estarían definidos como de efectos aleatorios, pues podemos ver que los niveles elegidos son en realidad una muestra de las posibles condiciones que prevalecen en la zona de estudio. Además, claramente el interés de la predicción es ser generalizable para toda la zona. A veces podemos pensar en esta forma de proceder como equivalente a un muestreo estratificado, en este caso, los tipos de ambiente son los estratos. No es el caso del tratamiento pisoteo. aprovechando podemos ver que en este experimento tendremos un mínimo de 4 combinaciones experimentales, y que ese arreglo mínimo se repetirá 5 veces, así que requeriremos 20 unidades experimentales para realizar el estudio.\n\n\n\n\n\n\nTip¿Puedes darnos un ejemplo en el que distingas entre efectos fijos y aleatorios?\n\n\n\n\n\n\n\n\nAnidamiento vs. cruzamiento\nLa anidación o el cruzamiento es otra característica de los datos, o más bien del diseño experimental. Hablamos de que un conjunto de variables están cruzadas en un diseño experimental cuando todos los posibles niveles de las variables están expuestas por igual entre ellas. Podríamos decir que las variables se combinan de “igual a igual”. Es decir, podemos tener tantas posibles combinaciones de las variables como el producto del numero de niveles que tengan. En el caso del experimento de Bouteloua, el experimento sugiere que los sitios y los tratamientos están “cruzados”, de ahí que tengamos necesidad de disponer por lo menos de 4 unidades experimentales.\nEl ejemplo de escuelas que ilustro a continuación debe ayudar a entender mejor estos conceptos. Si las clases son iguales para todas las escuelas, nos estaríamos refiriendo a algo así:\n\nEsto significa que cada clase se imparte por igual y en las mismas condiciones a cada escuela. Algo difícil de imaginar, ¡pero quizás no en los tiempos de la COVID-19!. Este es un diseño cruzado (algunos también podrían llamarlo afiliación múltiple). En R y con las funciones que ajustan modelos estadísticos lineales (lm() y glm()) se produce mediante el operador *.\nEl arreglo anidado se produce cuando las unidades experimentales están subordinadas a algún criterio de clasificación. Un factor B está anidado en otro factor A cuando cada nivel del factor B aparece asociado a un único nivel del factor A (los niveles de B están subordinados a los de A). Aquí tenemos clases anidadas en escuelas, lo cual es un escenario familiar.\n\nEl punto importante aquí es que, entre cada escuela, las clases tienen el mismo identificador, aunque sean distintas si están anidadas. La clase 1 aparece en la escuela 1, la escuela 2 y la escuela 3. Sin embargo, si los datos están anidados, la clase 1 en la escuela 1 no es la misma unidad de medida que la clase 1 en la escuela 2 y la escuela 3.\nNo es posible saber, simplemente inspeccionando los datos, si tenemos efectos aleatorios anidados o cruzados. Esto sólo puede determinarse con el conocimiento de los datos y el diseño experimental. Debido a esto, es muy importante especificar con suficiente claridad el diseño experimental incluyendo las operaciones involucradas para ponerlo en práctica, para poder construir correctamente el modelo estadístico correspondiente, ya que dependiendo de la naturaleza de las variables (fija o aleatoria), los modelos producirán resultados diferentes.\nEl concepto de variables aleatorias no es fácil de comprender, por lo que no hay que preocuparse demasiado por entenderlo completamente en este momento. También es útil tener en cuenta que el hecho de que una variable se considere fija o aleatoria en cierto grado dependerá de la interpretación de la persona que diseña el experimento y realiza el análisis. En R, la operación para incluir efectos anidados es el operador /.\nEn forma específica las interacciones derivadas de cruzamiento se pueden anotar en un modelo como a:b y un anidamiento a %in% b\nNaturalmente podemos encontrar situaciones en las que el experimento combina efectos aleatorios y fijos. Naturalmente, tal diseño se denomina de efectos mixtos."
  },
  {
    "objectID": "posts/04a-dag-dagitty/index.html",
    "href": "posts/04a-dag-dagitty/index.html",
    "title": "Aprovechando mi DAG",
    "section": "",
    "text": "En un DAG, cada tipo de nodo tiene un significado específico que surge de los intereses de la investigación y de la comprensión de la naturaleza misma del sistema que se estudia. A partir de esa información derivamos perspectivas específicas sobre la forma como se expresan los patrones de correlación y sobre la credibilidad de las relaciones causales propuestas. Conviene distinguir entre la o las variables de interés, que se propone responden según lo que hagamos con otro conjunto de variables de nuestro interés que podemos asociar con tratamientos o exposición. Desde luego hay algunas otra variables importantes que podemos reconocer en el sistema de nuestro interés, pero que más bien tienen un papel que nos interesa eliminar, controlar o simplemente reconocer que aunque importantes, no las podemos observar. Esto ayuda a ampliar la capacidad expresiva del DAG, y al mismo tiempo nos ayuda a clarificar acciones de diseño del estudio que habremos de poner en práctica."
  },
  {
    "objectID": "posts/04a-dag-dagitty/index.html#definiciones-clave-en-un-dag",
    "href": "posts/04a-dag-dagitty/index.html#definiciones-clave-en-un-dag",
    "title": "Aprovechando mi DAG",
    "section": "Definiciones clave en un DAG",
    "text": "Definiciones clave en un DAG\n\n\n\n\n\n\n\n\nTérmino\nDefinición\nEjemplo práctico\n\n\n\n\nExposure\nVariable de exposición. Es la causa principal bajo la hipótesis y los objetivos del estudio. Define o forma parte de lo que en algunos contextos se denomina tratamiento.\nSombra del dosel arbóreo.\n\n\nOutcome\nVariable de resultado (respuesta). Es el efecto que, de acuerdo con la hipótesis del estudio, resulta de exponer a las unidades experimentales a la variable de exposición.\nCrecimiento de plantas del sotobosque.\n\n\nAdjusted\nVariables que se incluyen en el modelo para controlar procesos o situaciones de confusión de los efectos. Se opta por incluirlos en el modelo estadístico para evitar que afecten la estimación de la exposición sobre el resultado.\nHumedad del suelo.\n\n\nSelected\nVariables que en el contexto del sistema de estudio representan un sesgo de selección (colicionador) . Dan cuenta de las situaciones en las que la muestra o población está condicionada por criterios que pueden distorsionar las relaciones causales.\nSolo medir plantas en claros accesibles, lo que excluye parcelas más profundas del bosque.\n\n\nUnobserved (Latent)\nVariables no medidas, ocultas o latentes que se postula podrían existir e influir en la relación causal, pero que no están disponibles en los datos.\nPresencia de micorrizas en el suelo que no se midieron, pero que influyen en el crecimiento."
  },
  {
    "objectID": "posts/04a-dag-dagitty/index.html#modalidades-de-estimación-de-efectos-en-un-estudio",
    "href": "posts/04a-dag-dagitty/index.html#modalidades-de-estimación-de-efectos-en-un-estudio",
    "title": "Aprovechando mi DAG",
    "section": "Modalidades de estimación de efectos en un estudio",
    "text": "Modalidades de estimación de efectos en un estudio\nEn un DAG, el efecto total) se refiere al impacto combinado que una variable de exposición tiene sobre un resultado, incluyendo tanto el efecto directo como todos los efectos indirectos que pasan a través de mediadores. Dicho de otra forma: es la suma del efecto directo y de los efectos transmitidos por las rutas intermedias, todos combinados.\n\n\n\n\n\n\n\n\n\n\n\nTipo de efecto\nDefinición\nEjemplo práctico (ecología)\n\n\n\n\nTotal effect\nEl impacto global de la exposición sobre el resultado, considerando todas las rutas (directas e indirectas).\nSombra del dosel → crecimiento reducido de plantas (directo) + sombra → más hojarasca → cambios en nutrientes → crecimiento reducido (indirecto).\n\n\nDirect effect\nEl impacto de la exposición sobre el resultado que no pasa por mediadores.\nSombra → menor fotosíntesis → crecimiento reducido.\n\n\nIndirect effect\nEl impacto que se transmite a través de una o más variables mediadoras.\nSombra → acumulación de hojarasca → alteración de nutrientes → crecimiento reducido."
  },
  {
    "objectID": "posts/04a-dag-dagitty/index.html#cómo-se-interpretan-las-estimaciones-de-efectos",
    "href": "posts/04a-dag-dagitty/index.html#cómo-se-interpretan-las-estimaciones-de-efectos",
    "title": "Aprovechando mi DAG",
    "section": "Cómo se interpretan las estimaciones de efectos",
    "text": "Cómo se interpretan las estimaciones de efectos\n\nIncluye todas las rutas causales: tanto las que van directamente de la exposición al resultado como las que pasan por mediadores.\n\nNo se ajusta por mediadores: si se ajusta por mediadores, se elimina parte del efecto indirecto y se estima solo el efecto directo.\n\nEs útil para preguntas de manejo ecológico o conservación: por ejemplo, si queremos saber el impacto global de abrir claros en el bosque sobre el crecimiento del sotobosque, necesitamos el total effect.\n\n\n\nCódigo\n# Definir  DAG\ndag_ecologia &lt;- dagify(\n  Crec ~ Somb + Hum + Hoj,\n  Somb ~ Hum,\n  Hoj ~ Somb,\n  Sel ~ Crec,   # Sesgo de selección: solo plantas en claros accesibles\n  Lat ~ Crec,   # Variable latente: micorrizas no observadas\n  coords = list(\n    Somb = c(0, 2),\n    Hum = c(0, 0),\n    Hoj = c(1, 1),\n    Crec = c(2, 2),\n    Sel = c(3, 1.5),\n    Lat = c(2, 3)\n  ),\n  exposure = \"Somb\",\n  outcome = \"Crec\",\n  latent =  \"Lat\"\n)\n\n # Asignar roles\nroles &lt;- tibble(\n  name = c(\"Somb\", \"Crec\", \"Hum\", \"Hoj\", \"Sel\", \"Lat\"),\n  rol = c(\"Exposición\", \"Resultado\", \"Confusor\", \"Mediador\", \"Seleccionada\", \"Latente\")\n)\n\n# Graficar con colores y formas\ndag_ecologia %&gt;%\n  tidy_dagitty() %&gt;%\n  left_join(roles, by = \"name\") %&gt;%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges() +\n  geom_dag_point(aes(fill = rol, shape = rol), color = \"black\", size = 20) +\n  geom_dag_text(color = \"black\", size = 4) +\n  scale_fill_manual(values = c(\n    \"Exposición\" = \"steelblue\",\n    \"Resultado\" = \"forestgreen\",\n    \"Confusor\" = \"orange\",\n    \"Mediador\" = \"purple\",\n    \"Seleccionada\" = \"brown\",\n    \"Latente\" = \"grey50\")) +\n  scale_shape_manual(values = c(\n    \"Exposición\"   = 22,     # cuadrado\n    \"Resultado\"    = 21,     # óvalo\n    \"Confusor\"     = 23,     # rombo\n    \"Mediador\"     = 24,     # triángulo\n    \"Seleccionada\" = 25,     # cuadrado\n    \"Latente\"      = 21      # óvalo\n    )) +  \n  guides( fill = guide_legend(),\n          shape = guide_legend(override.aes = list(size = 5))) +\n  theme_dag() +\n  ggtitle(\"DAG ecológico \") +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "posts/04a-dag-dagitty/index.html#triángulo-de-confusión",
    "href": "posts/04a-dag-dagitty/index.html#triángulo-de-confusión",
    "title": "Aprovechando mi DAG",
    "section": "Triángulo de confusión",
    "text": "Triángulo de confusión\nEn ecología, un triángulo de confusión aparece cuando una variable externa afecta tanto al factor de exposición como al resultado, generando un sesgo. En este ejemplo la humedad influye en:\n\nla densidad del dosel (más humedad favorece mayor cobertura).\nEl crecimiento de las plantas (más agua provoca mayor productividad).\n\nAsí se forma el triángulo:\n\\[\nSombra ~ (X) \\leftarrow ~ Humedad~del~suelo~(C) \\rightarrow ~ Crecimiento ~ (Y)\n\\]\n\nPregunta: ¿La sombra reduce el crecimiento de plantas?\n\nProblema: La humedad también afecta sombra y crecimiento.\n\n¿Debería?: Ajustar por humedad en el modelo o controlar humedad en el diseño experimental.\n\n¿Qué ganaría?: Una estimación más válida del efecto causal de la sombra.\n\n\n\n\n\n\nImplicaciones\n\nSesgo en la estimación:\nSi no controlas la humedad, el efecto estimado de la sombra sobre el crecimiento estará mezclado con el efecto de la humedad.\n\nCamino falso:\nLa humedad abre un camino alternativo entre sombra y crecimiento que no es causal, sino confusor.\nInterpretación incorrecta:\nPodrías concluir que la sombra tiene un efecto más fuerte (o más débil) de lo que realmente tiene, porque parte del efecto proviene de la humedad.\n\n\n\nCódigo\n# Asignar roles y marcar el triángulo de confusión\nroles &lt;- tibble(\n  name = c(\"Somb\", \"Crec\", \"Hum\", \"Hoj\", \"Sel\", \"Lat\"),\n  rol = c(\"Exposición\", \"Resultado\", \"Confusor\", \"Mediador\", \"Seleccionada\", \"Latente\"),     \n  conf_triangle = c(\"Dentro\", \"Dentro\", \"Dentro\", \"Fuera\", \"Fuera\", \"Fuera\") \n)\n  \n# Graficar con colores diferenciados\ndag_ecologia %&gt;%\n  tidy_dagitty() %&gt;%\n  left_join(roles, by = \"name\") %&gt;%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges() +\n  geom_dag_point(\n    aes(fill = conf_triangle, shape = rol),\n    color = \"black\", size = 20\n  ) +\n  geom_dag_text(color = \"black\", \n                size = 4) +\n  scale_fill_manual(values = c(\"Dentro\" = \"red\",        # nodos del triángulo de confusión\n                               \"Fuera\" = \"grey70\"),\n                    name = \"¿Triángulo?\") +             # otros nodos\n  scale_shape_manual(values = c(\"Exposición\" = 22,      # cuadrado\n                                \"Resultado\" = 21,       # óvalo\n                                \"Confusor\" = 23,        # rombo\n                                \"Mediador\" = 24,        # triángulo\n                                \"Seleccionada\" = 25,    # cuadrado\n                                \"Latente\" = 21),        # óvalo\n                     name = \"Rol de la variable\") +\n  guides( fill = guide_legend(override.aes = list(size = 5,\n                                                  color = c(\"red\", \"grey70\"))), \n          shape = guide_legend(override.aes = list(size = 5, \n                                                   fill = c(\"red\", \"red\", \"red\", \n                                                            \"grey70\", \"grey70\", \"grey70\")))) +\n  theme_dag() +\n  ggtitle(\"Triángulo de confusión\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nPodemos explorar este sistema ecológico con dagitty y también recurriendo a ensayos por simulación.\nLe podemos pedir a dagitty que nos identifique el conjunto de variables que deberíamos controlar para lograr una estimación de efectos entre exposure y outcome. Lo hacemos así.\n\n\nCódigo\nadjustmentSets(dag_ecologia)\n\n\n{ Hum }\n\n\nPodemos ver con ayuda gráfica de la biblioteca ggdag (integra dagitty con ggplot2) , el patrón de interés cuando nos interesa la relación entre sombra y crecimiento.\n\n\nCódigo\nggdag_adjustment_set(dag_ecologia) + theme_dag()\n\n\n\n\n\n\n\n\n\nAhora, hagamos una simulación de la situación descrita. Empezamos por construir el patrón en los datos, de acuerdo con la misma proposición causal que hemos capturado en el DAG\n\n\nCódigo\nset.seed(1234)\n\n# Número de observaciones\nn &lt;- 500\n\n# Variable confusora: Humedad\nHum &lt;- rnorm(n, mean = 1, sd = 1)\n\n# Exposición: Sombra, influida por Humedad\nSomb &lt;- 0.7 * Hum + rnorm(n, mean = 1, sd = 1)\n\n# Mediador: Hojarasca, influida por Sombra \nHoj &lt;- 0.5 * Somb + rnorm(n, mean = 1, sd = 1)\n\n# Resultado: Crecimiento, influido por Sombra, Humedad y Hojarasca\nCrec &lt;- -0.8 * Somb + 0.6 * Hum - 0.4 * Hoj + rnorm(n, mean = 1, sd = 1)\n\n\nDe acuerdo con estos datos, tenemos un efecto directo del sombreado (el esperado simulado es de 0.8 unidades). Además deberíamos poder obtener una estimación del efecto total asociado con la sombra que sería:\n\n\nCódigo\nsomb_prom = mean(Hum)      \nhoj_prom = mean(Hoj)\nefecto_total &lt;- -0.8 +  (-0.4 * 0.5)\ncat(\"Efecto total esperado: \", efecto_total, \"unidades\")\n\n\nEfecto total esperado:  -1 unidades\n\n\nAhora ajustemos modelos para ver qué pasa.\nPrimero el caso equivocado se intentar estimar directamente el efecto del sombreado. Está equivocado pues existe el efecto de confusión o sesgo que no se ha controlado. No produce una buena estimación ni del efecto directo ni del total.\n\n\nCódigo\n# Modelo sin ajustar por Humedad (sesgado)\nmodelo_sesgado &lt;- lm(Crec ~ Somb)\nsummary(modelo_sesgado)\n\n\n\nCall:\nlm(formula = Crec ~ Somb)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0031 -0.7444  0.0478  0.8406  3.8122 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.64245    0.08672   7.408 5.51e-13 ***\nSomb        -0.66997    0.04199 -15.954  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.171 on 498 degrees of freedom\nMultiple R-squared:  0.3382,    Adjusted R-squared:  0.3369 \nF-statistic: 254.5 on 1 and 498 DF,  p-value: &lt; 2.2e-16\n\n\nAhora hacemos lo que el DAG nos sugiere que es la forma apropiada de obtener el estimador del efecto total. Controlamos el la ruta que está provocando confusión a través del papel de la humedad en el sistema.\n\n\nCódigo\n# Modelo ajustado por Humedad (controla confusión), efecto total \nmodelo_ajustado_hum &lt;- lm(Crec ~ Somb + Hum)\nsummary(modelo_ajustado_hum )\n\n\n\nCall:\nlm(formula = Crec ~ Somb + Hum)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7135 -0.7480  0.0272  0.7317  3.2349 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.57712    0.08141   7.089 4.66e-12 ***\nSomb        -0.95201    0.05127 -18.570  &lt; 2e-16 ***\nHum          0.52867    0.06183   8.551  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.094 on 497 degrees of freedom\nMultiple R-squared:  0.4231,    Adjusted R-squared:  0.4208 \nF-statistic: 182.3 on 2 and 497 DF,  p-value: &lt; 2.2e-16\n\n\nEl efecto total asociado a sombreado resulta bastante cercano al que esperaríamos: -1.\nSi separamos el efecto de la hojarasca, agregando esa variable en el modelo, entonces obtenemos un estimador del efecto directo atribuible al sombreado. El esperado de esto es: -0.8 unidades.\n\n\nCódigo\n# Modelo ajustado por Humedad y hojarasca efecto directo\nmodelo_ajustado_hum_hoj &lt;- lm(Crec ~ Somb + Hum + Hoj)\nsummary(modelo_ajustado_hum_hoj)\n\n\n\nCall:\nlm(formula = Crec ~ Somb + Hum + Hoj)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1290 -0.6768 -0.0315  0.6567  3.0834 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.98045    0.09046  10.839  &lt; 2e-16 ***\nSomb        -0.76095    0.05329 -14.279  &lt; 2e-16 ***\nHum          0.56897    0.05818   9.779  &lt; 2e-16 ***\nHoj         -0.40880    0.04918  -8.313 9.05e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.026 on 496 degrees of freedom\nMultiple R-squared:  0.4936,    Adjusted R-squared:  0.4906 \nF-statistic: 161.2 on 3 and 496 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nPara reflexionar\n\nIdentificación en el DAG\n\nEl DAG permite reconocer que Humedad da origen a un proeso de confusión de efectos, porque influye tanto sobre la exposición (Sombra) como el resultado(Crecimiento).\n\nVisualmente, el triángulo ayuda a ver en dónde está el sesgo.\n\nAjuste estadístico\n\nLo que habría que hacer es incluir la humedad como covariable en el modelo.\n\nAl incluir esta variable bloqueas el camino de confusión y logras estimar e mejor manera el efecto causal de la sombra sobre el crecimiento.\n\nDiseño experimental\n\nControlar la humedad en el diseño (igualación de condiciones) (ej. parcelas con riego homogéneo, o seleccionar sitios con humedad similar).\n\nEsto elimina la variación de humedad como fuente de confusión antes de analizar los datos.\n\nInterpretación conceptual\n\nEl triángulo muestra que no todo lo que correlaciona es causal.\n\nEl DAG ayuda a ver que identificar confusores es clave para separar correlaciones espurias de efectos reales.\n\n\nCon la bibliiteca flextable puedes generar una tabla en formato bonito del ajuste de tus modelos. Te doy un ejemplo en seguida. Uso como parámetro el objeto ajustado con lm.\n\n\nCódigo\n as_flextable(modelo_ajustado_hum_hoj)\n\n\nEstimateStandard Errort valuePr(&gt;|t|)(Intercept)0.9800.09010.8390.0000***Somb-0.7610.053-14.2790.0000***Hum0.5690.0589.7790.0000***Hoj-0.4090.049-8.3130.0000***Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 1.026 on 496 degrees of freedomMultiple R-squared: 0.4936, Adjusted R-squared: 0.4906F-statistic: 161.2 on 496 and 3 DF, p-value: 0.0000"
  },
  {
    "objectID": "posts/06-Restringir-aleatorizacion/index.html#manos",
    "href": "posts/06-Restringir-aleatorizacion/index.html#manos",
    "title": "Restricciones a la aleatorización",
    "section": "Manos",
    "text": "Manos\nConsidera que estamos midiendo la mano izquierda y la derecha de varios individuos, las medidas están emparejadas dentro de cada individuo. Es decir, queremos controlar estadísticamente las diferencias entre individuos, así nos aseguramos que la mano izquierda del individuo A sea analizada en conjunto con la mano derecha del individuo A, ya que suponemos que alguien con una mano izquierda grande tendrá una mano derecha grande. Por lo tanto, la variable Individuo se incluirá en el modelo como una variable aleatoria. Se podría pensar que cada Individuo representa un bloque que incluye una medida para la mano izquierda y una medida para la mano derecha.\n\n\nCódigo\nlibrary(stringr)\nurl_manos &lt;- \"https://drive.google.com/file/d/1GSQMbbX7szydnIMDkWYDBlFBWqTdkC4k/view?usp=drive_link\"\ndat_manos_id &lt;- str_extract(url_manos, \"(?&lt;=d/)(.*)(?=/view)\")\n\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \nmanos &lt;- read.csv(sprintf(url_drive, dat_manos_id)) \n\n\n#manos &lt;- read.table(\"manos.dat\", sep = \",\", header = T, stringsAsFactors = T)\nhead(manos)\n\n\n  Individual Hand Length\n1          A Left   17.5\n2          B Left   18.4\n3          C Left   16.2\n4          D Left   14.5\n5          E Left   13.5\n6          F Left   18.9\n\n\n\nInspección de los datos\n\n\nCódigo\ntapply(manos$Length, list(manos$Hand, manos$Individual), mean)\n\n\n         A    B    C    D    E    F    G    H    I    J    K    L    M    N\nLeft  17.5 18.4 16.2 14.5 13.5 18.9 19.5 21.1 17.8 16.8 18.4 17.3 18.9 16.4\nRight 17.6 18.5 15.9 14.9 13.7 18.9 19.5 21.5 18.5 17.1 18.9 17.5 19.5 16.5\n         O    P\nLeft  17.5 15.0\nRight 17.4 15.6\n\n\n\n\nCódigo\ninteraction.plot(manos$Individual,manos$Hand, manos$Length)\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nmanos_modelo_1 &lt;- lm(Length ~ 1, data = manos)\nsummary(manos_modelo_1)\n\n\n\nCall:\nlm(formula = Length ~ 1, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.975 -1.125  0.025  1.425  4.025 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  17.4750     0.3415   51.16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.932 on 31 degrees of freedom\n\n\n\n\nCódigo\nmanos_modelo_2 &lt;- lm(Length ~ Hand, data = manos)\nsummary(manos_modelo_2)\n\n\n\nCall:\nlm(formula = Length ~ Hand, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.894 -1.109  0.075  1.306  3.906 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  17.3562     0.4900  35.418   &lt;2e-16 ***\nHandRight     0.2375     0.6930   0.343    0.734    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.96 on 30 degrees of freedom\nMultiple R-squared:  0.003899,  Adjusted R-squared:  -0.0293 \nF-statistic: 0.1174 on 1 and 30 DF,  p-value: 0.7342\n\n\n\n\nCódigo\nmanos_modelo_3 &lt;- lm(Length ~ Hand + Individual, data = manos)\nsummary(manos_modelo_3)\n\n\n\nCall:\nlm(formula = Length ~ Hand + Individual, data = manos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.26875 -0.09062  0.00000  0.09062  0.26875 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 17.43125    0.14440 120.714  &lt; 2e-16 ***\nHandRight    0.23750    0.07004   3.391 0.004034 ** \nIndividualB  0.90000    0.19812   4.543 0.000389 ***\nIndividualC -1.50000    0.19812  -7.571 1.69e-06 ***\nIndividualD -2.85000    0.19812 -14.386 3.50e-10 ***\nIndividualE -3.95000    0.19812 -19.938 3.30e-12 ***\nIndividualF  1.35000    0.19812   6.814 5.85e-06 ***\nIndividualG  1.95000    0.19812   9.843 6.15e-08 ***\nIndividualH  3.75000    0.19812  18.928 7.00e-12 ***\nIndividualI  0.60000    0.19812   3.029 0.008466 ** \nIndividualJ -0.60000    0.19812  -3.029 0.008466 ** \nIndividualK  1.10000    0.19812   5.552 5.54e-05 ***\nIndividualL -0.15000    0.19812  -0.757 0.460699    \nIndividualM  1.65000    0.19812   8.328 5.23e-07 ***\nIndividualN -1.10000    0.19812  -5.552 5.54e-05 ***\nIndividualO -0.10000    0.19812  -0.505 0.621065    \nIndividualP -2.25000    0.19812 -11.357 9.14e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1981 on 15 degrees of freedom\nMultiple R-squared:  0.9949,    Adjusted R-squared:  0.9895 \nF-statistic: 183.3 on 16 and 15 DF,  p-value: 2.887e-14\n\n\n\n\nCódigo\nanova(manos_modelo_3)\n\n\nAnalysis of Variance Table\n\nResponse: Length\n           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nHand        1   0.451  0.4513  11.497  0.004034 ** \nIndividual 15 114.680  7.6453 194.786 2.089e-14 ***\nResiduals  15   0.589  0.0392                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEs cierto que el efecto de individuo queda raro en este modelo, pes nos lo reporta en estimadores que tienen sentido como si se tratara de un factor de efectos fijos, es decir que nos interesa decir algo específico sobre esos individuos y ningún otro. Esto obviamente nos es así. El factor individuo es de efectos aleatorios, simplemente que lm no prevé esta situación. Los resultados apuntan en la dirección correcta y los valores del factor Hand son válidos. Lo podemos manejar razonablemente simplemente recordando que el individuo es de efectos aleatorios y que por tanto no tienen mucho sentido, generalmente, hacer referencia a los estimadores puntuales que produce la regresión. Lo que sí tiene interés es la estimación de las varianzas, que permite así corregir e idealmente lograr mayor precisión en la estimación en los tratamientos de interés. En este caso habría que notar que la varianza estimada en el residuo da cuenta tanto de la variación aleatoria que tenemos al medir las unidades experimentales como la del error de restricción asociado con las peculiaridades de, en este caso, cada persona que se midió: \\(\\sigma^{2} + t \\sigma^{2}_{\\delta}\\) . La medición de esta varianza combinada, persona + sus peculiaridades = 7.6453, sugiere que es buena idea controlar su efecto. En esto mismos términos la varianza del factor hand es \\(\\sigma + t\\sigma^{2}_{\\delta} + r\\sigma^{2}_{H}\\), lo qe hace válido probar el efecto fijo de hand.\n\\[\nF = \\frac {Mean Sq Hand} {Mn Sq error} = \\frac {0.4513}{0.0392} = 11.497\n\\] con 1 y 15 grados de libertad. En R tenemos acceso a la distribbución de F con la función qfque calcula la probabilidad acumulada entre el dato q que le doy, así como los grados de libertad asociados.\n\n\nCódigo\nvarianza &lt;- anova(manos_modelo_3)\n\npf(q = varianza$`F value`[1], df1 = 1, df2 = 15, lower.tail = FALSE)\n\n\n[1] 0.004034071\n\n\nAunque la forma como analizamos estos datos no es la ideal para el caso, podemos ver que produce resultados perfectamente adecuados para la variable de interés, siempre y cuando seamos cocientes de que la función usada aquí en R, no maneja apropiadamente los factores de efectos aleatorios y por lo tanto no debemos hacer mayores interpretaciones de los términos correspondientes a esos factores."
  },
  {
    "objectID": "posts/06-Restringir-aleatorizacion/index.html#qué-tanto-tiempo-puede-correr-un-experimento",
    "href": "posts/06-Restringir-aleatorizacion/index.html#qué-tanto-tiempo-puede-correr-un-experimento",
    "title": "Restricciones a la aleatorización",
    "section": "Qué tanto tiempo puede “correr” un experimento",
    "text": "Qué tanto tiempo puede “correr” un experimento\nCuando Fisher concibió hacer experimentos en la estación experimental de Rothamsted en Inglaterra, recurriendo al auxilio del enfoque estadístico que él y otros investigadores de la época idearon, pensaban a largo plazo. Encontré este documento que podría ser de su interés. La estación experimental tiene disponiible los datos de estos experimentos. Por ejemplo Este “dataset” son los rendimientos anuales de trigo de “parcelas selectas” del experimento de trigo que aún hoy corren en Broadbalk . La serie tiene los datos de 1852-1918, tal y como los usó R.A. Fisher para su artículo de 1921 ‘Studies in crop variation’."
  },
  {
    "objectID": "posts/09-medidas-repetidas/index.html",
    "href": "posts/09-medidas-repetidas/index.html",
    "title": "Modelos de medidas repetidas",
    "section": "",
    "text": "El tiempo es una variable problemática en el análisis estadístico, sobre todo por la necesidad de postular el supuesto de independencia entre las observaciones, lo que solemos asegurar aleatorizando las unidades experimentales. Las observaciones arregladas a lo largo del tiempo comúnmente no pueden aleatorizarse, por ejemplo cuando estamos dando seguimiento al crecimiento de un organismo. Por otro lado, también puede ocurrir esta falta de independencia por cercanía geográfica, así que el espacio comparte desafíos estadísticos con el tiempo."
  },
  {
    "objectID": "posts/09-medidas-repetidas/index.html#ejemplo-con-árboles-de-sitka",
    "href": "posts/09-medidas-repetidas/index.html#ejemplo-con-árboles-de-sitka",
    "title": "Modelos de medidas repetidas",
    "section": "Ejemplo con árboles de Sitka",
    "text": "Ejemplo con árboles de Sitka\nFuente: Venables y Ripley (1999, p.206), tabla Sitka de la biblioteca MASS. Datos de Diggle, Liang y Zeger (1994).\nSe trata de mediciones del tamaño-log (que se define como el logaritmo de la altura más dos veces el logaritmo del diámetro), de 79 árboles de Sitka spruce.\nA 54 de ellos se les hizo crecer en cámaras con atmósfera enriquecida con ozono y otros 25 fueron controles. La talla fue medida cinco veces en 1988 a intervalos de aproximadamente un mes (el tiempo se da en días a partir del 1 de enero de 1998). En 1989 se tomaron otras ocho mediciones (que se incluyen en una tabla aparte: Sitka89).\n\n\nCódigo\nlibrary(MASS)\nlibrary(nlme)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::collapse() masks nlme::collapse()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ dplyr::select()   masks MASS::select()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCódigo\nsitka88 &lt;- Sitka\n\n\n\n\nCódigo\nstr(sitka88)\n\n\n'data.frame':   395 obs. of  4 variables:\n $ size : num  4.51 4.98 5.41 5.9 6.15 4.24 4.2 4.68 4.92 4.96 ...\n $ Time : num  152 174 201 227 258 152 174 201 227 258 ...\n $ tree : int  1 1 1 1 1 2 2 2 2 2 ...\n $ treat: Factor w/ 2 levels \"control\",\"ozone\": 2 2 2 2 2 2 2 2 2 2 ...\n\n\nLa estructura de grupos podemos usarla para representar una curva de crecimiento por árbol. Los 79 árboles en los datos “sitka” son demasiados para el ejemplo que quiero ilustrar. Mostraré sólo dos árboles: el 64 y 24.\n\nExploración de los datos de Sitka\n\n\nCódigo\nsitka88 &lt;-groupedData(size ~ Time | tree, data=sitka88)\nplot(sitka88[sitka88$tree == 64 | sitka88$tree == 24, ])\n\n\n\n\n\n\n\n\n\n¿Cómo se ven los número de resumen de los datos en general?\n\n\nCódigo\nformula(sitka88)\n\n\nsize ~ Time | tree\n\n\n\n\nCódigo\nhead(gsummary(sitka88[, c(\"size\",\"Time\")], groups=sitka88$size, omit=TRUE))\n\n\n     size Time\n2.23 2.23  152\n2.79 2.79  152\n2.84 2.84  152\n2.89 2.89  174\n2.96 2.96  152\n2.99 2.99  152\n\n\n\n\nCódigo\nplot.design(size ~ treat, data=sitka88)\n\n\n\n\n\n\n\n\n\nPongo una línea de tendencia en la gráfica con la opción geom_smooth. Tengo multiples opciones, ve la ayuda, pero aquí consideré dos opciones loess con el parámetro span = 1. La otra opción que consideré fue el método gam. Esta solución es demandante en cuanto a número de datos necesarios. En este caso tuve que ajustar el parámetro de número de nudos (knots), pues la aproximación a una curva suave por el método aditivo generalizado usado, gam, requiere por defecto datos para por lo menos calcular 10 nudos y esto no se logra en este conjunto de datos. Usualmente funciona sin mayores problemas cuando se tienen más de 1000 puntos. Para tener una representación un poco más simple opté por eliminar los intervalos de confianza, eso lo controla el parámetro se.\n\n\nCódigo\noptions(repr.plot.width=12, repr.plot.height=6)\nlibrary(ggplot2)\nggplot(sitka88, aes(x=Time, y=size, color = tree)) + \n       geom_smooth(method = \"loess\", span = 1, formula = y ~ x, se = FALSE, show.legend = FALSE) +\n       geom_point(show.legend = FALSE) + facet_grid(. ~ treat) +\n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nggplot(sitka88, aes(x=Time, y=size, color = tree)) + \n       geom_smooth(method = \"gam\", span = 1, formula = y ~ s(x, bs = \"cs\", k = 5), \n                   se = FALSE, show.legend = FALSE) +\n       geom_point(show.legend = FALSE) + facet_grid(. ~ treat) +\n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20))\n\n\n\n\n\n\n\n\n\nAhora ajusto el modelo completo con el tiempo. Fuerzo a que el tiempo sea tratado como un factor ordenado, lo que junto con la opción de contraste usada ajusta polinomios ortogonales en este caso.\n\n\nCódigo\noptions(contrasts=c(\"contr.treatment\", \"contr.poly\"))\n\n\n\n\nCódigo\nsitka.lme1 &lt;- lme(fixed = size ~ treat * ordered(Time),\n                  random = ~ 1 | tree,\n                  data = sitka88)\nsummary(sitka.lme1)$tTable\n\n\n                                 Value  Std.Error  DF    t-value       p-value\n(Intercept)                 4.98512000 0.12286970 308 40.5724123 1.332276e-125\ntreatozone                 -0.21115704 0.14861459  77 -1.4208365  1.594013e-01\nordered(Time).L             1.19711183 0.03221011 308 37.1657221 7.430810e-116\nordered(Time).Q            -0.13405824 0.03221011 308 -4.1619932  4.098121e-05\nordered(Time).C            -0.04085663 0.03221011 308 -1.2684413  2.055983e-01\nordered(Time)^4            -0.02729902 0.03221011 308 -0.8475297  3.973580e-01\ntreatozone:ordered(Time).L -0.17856562 0.03895909 308 -4.5834135  6.656627e-06\ntreatozone:ordered(Time).Q -0.02644698 0.03895909 308 -0.6788399  4.977491e-01\ntreatozone:ordered(Time).C -0.01424899 0.03895909 308 -0.3657423  7.148084e-01\ntreatozone:ordered(Time)^4  0.01240293 0.03895909 308  0.3183578  7.504293e-01\n\n\n\n\nCódigo\nintervals(sitka.lme1, level = 0.95)$fixed\n\n\n                                 lower        est.       upper\n(Intercept)                 4.74334979  4.98512000  5.22689021\ntreatozone                 -0.50708650 -0.21115704  0.08477242\nordered(Time).L             1.13373214  1.19711183  1.26049153\nordered(Time).Q            -0.19743793 -0.13405824 -0.07067854\nordered(Time).C            -0.10423632 -0.04085663  0.02252307\nordered(Time)^4            -0.09067872 -0.02729902  0.03608067\ntreatozone:ordered(Time).L -0.25522527 -0.17856562 -0.10190597\ntreatozone:ordered(Time).Q -0.10310663 -0.02644698  0.05021266\ntreatozone:ordered(Time).C -0.09090864 -0.01424899  0.06241066\ntreatozone:ordered(Time)^4 -0.06425672  0.01240293  0.08906258\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\n\n\nAnaliizando la interección\nNotando la significancia de los términos de interacción: ¿podría simplificar el modelo limitando el ajuste a un efecto lineal de crecimiento que distingue entre los tratamiento? Veamos, calculo un nuevo vector que me permite hacer el ajuste de un efecto lineal a la diferencia entre tratamientos (que es la interacción).\n\n\nCódigo\nsitka88$tratGrad &lt;- sitka88$Time * (sitka88$treat==\"ozone\")\n\n\n\n\nCódigo\ntapply(sitka88$Time,list(sitka88$treat, sitka88$Time), FUN=mean)\n\n\n        152 174 201 227 258\ncontrol 152 174 201 227 258\nozone   152 174 201 227 258\n\n\nCódigo\ntapply(sitka88$tratGrad,list(sitka88$treat, sitka88$Time), FUN=mean)\n\n\n        152 174 201 227 258\ncontrol   0   0   0   0   0\nozone   152 174 201 227 258\n\n\nAhora ajusto un modelo en el que elimino la interacción de tratamiento con tiempo. Al mismo tiempo substituyo este efecto por el modelo con tiempo lineal en interacción con el tratamiento ozono (la variable que acabo de construir).\n\n\nCódigo\nsitka.lme2 &lt;- update(sitka.lme1, \n                     fixed = size ~ ordered(Time) + treat + tratGrad)\nsummary(sitka.lme2)$tTable\n\n\n                      Value    Std.Error  DF    t-value       p-value\n(Intercept)      4.98512000 0.1228696967 311 40.5724123 2.952779e-126\nordered(Time).L  1.19755089 0.0320437966 311 37.3723158 4.821617e-117\nordered(Time).Q -0.14549447 0.0181029428 311 -8.0370620  1.933996e-14\nordered(Time).C -0.05059644 0.0180459272 311 -2.8037597  5.368534e-03\nordered(Time)^4 -0.01672449 0.0180516171 311 -0.9264818  3.549141e-01\ntreatozone       0.22167749 0.1756140543  77  1.2622992  2.106510e-01\ntratGrad        -0.00213851 0.0004622668 311 -4.6261386  5.473912e-06\n\n\nEl resumen del ajuste muestra dos criterios que no hemos comentado mayormente antes. Son útiles para comparar y evaluar modelos. Estas medidas son resultado de la búsqueda de alternativas para valorar modelos que no se centre en el famoso valor de p.\n\nAIC - Criterio de información de Akaike = -2 * logVerosimilitud + 2 numParámetros\nBIC - Criterio de información bayesiano = -2 * logVerosimilitud + numParámetros * log(N)\n\nEs bueno contar con ellos para comparar la calidad general de los modelos ajustados, pero no olvides que centrar nuestra atención en los intervalos de confianza es más informativo y potencialmente interesante.\nEn cualquier caso, “entre más pequeño el valor del criterio, mejor”.\n\n\nCódigo\ndata.frame(AICmodelo_red=summary(sitka.lme2)$AIC, AICmodelo_comp=summary(sitka.lme1)$AIC)\n\n\n  AICmodelo_red AICmodelo_comp\n1       69.2691       79.90098\n\n\nCódigo\ndata.frame(BICmodelo_red=summary(sitka.lme2)$BIC, BICmodelo_comp=summary(sitka.lme1)$BIC)\n\n\n  BICmodelo_red BICmodelo_comp\n1      104.9181       127.3399\n\n\nTanto el criterio AIC como el BIC sugieren que el modelo reducido es preferible al modelo completo inicial. ¿Qué sugiere la comparación, en devianzas, de ambos modelo?\n\n\nCódigo\nanova(sitka.lme1, sitka.lme2)\n\n\nWarning in anova.lme(sitka.lme1, sitka.lme2): fitted objects with different\nfixed effects. REML comparisons are not meaningful.\n\n\n           Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nsitka.lme1     1 12 79.90098 127.3399 -27.95049                        \nsitka.lme2     2  9 69.26910 104.9181 -25.63455 1 vs 2 4.631882  0.2008\n\n\nNotese la advertencia que aparece al intentar esta comparación. Para resolverla, hay que volver a ajustar los modelos de interés, pero ahora con el método “ML”, que si me permite hacer comparaciones entre modelos.\n\n\nCódigo\nsitka.lme1.ML &lt;- lme(fixed = size ~ treat * ordered(Time),\n                 random = ~ 1 | tree,\n                 data = sitka88, method=\"ML\")\n\nsitka.lme2.ML &lt;- update(sitka.lme1.ML, \n                     fixed = size ~ ordered(Time) + treat + tratGrad, method=\"ML\")\n\n\nComparemos los resultados obtenidos hasta aquí\n\n\nCódigo\nanova(sitka.lme1.ML, sitka.lme2.ML)\n\n\n              Model df      AIC      BIC    logLik   Test   L.Ratio p-value\nsitka.lme1.ML     1 12 30.94633 78.69296 -3.473163                         \nsitka.lme2.ML     2  9 25.43446 61.24443 -3.717228 1 vs 2 0.4881304  0.9215\n\n\n\n\nCódigo\nsummary(sitka.lme2.ML)\n\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: sitka88 \n       AIC      BIC    logLik\n  25.43446 61.24443 -3.717228\n\nRandom effects:\n Formula: ~1 | tree\n        (Intercept)  Residual\nStdDev:    0.602333 0.1591217\n\nFixed effects:  size ~ ordered(Time) + treat + tratGrad \n                    Value  Std.Error  DF  t-value p-value\n(Intercept)      4.985120 0.12239376 311 40.73018  0.0000\nordered(Time).L  1.197551 0.03207475 311 37.33625  0.0000\nordered(Time).Q -0.145494 0.01812043 311 -8.02931  0.0000\nordered(Time).C -0.050596 0.01806336 311 -2.80105  0.0054\nordered(Time)^4 -0.016724 0.01806906 311 -0.92559  0.3554\ntreatozone       0.221677 0.17517548  77  1.26546  0.2095\ntratGrad        -0.002139 0.00046271 311 -4.62167  0.0000\n Correlation: \n                (Intr) o(T).L o(T).Q o(T).C o(T)^4 tretzn\nordered(Time).L  0.000                                   \nordered(Time).Q  0.000  0.066                            \nordered(Time).C  0.000  0.000  0.000                     \nordered(Time)^4  0.000  0.021  0.002  0.000              \ntreatozone      -0.699  0.442  0.042  0.000  0.013       \ntratGrad         0.000 -0.826 -0.079  0.000 -0.025 -0.535\n\nStandardized Within-Group Residuals:\n         Min           Q1          Med           Q3          Max \n-2.631308932 -0.525058743  0.009619032  0.514425152  5.968135202 \n\nNumber of Observations: 395\nNumber of Groups: 79"
  },
  {
    "objectID": "posts/09-medidas-repetidas/index.html#selección-del-polinomio",
    "href": "posts/09-medidas-repetidas/index.html#selección-del-polinomio",
    "title": "Modelos de medidas repetidas",
    "section": "Selección del polinomio",
    "text": "Selección del polinomio\nAhora veamos un poco más de cerca el modelo y veamos si la respuesta muestra una curvatura que pueda ser aproximada entonces por un polinomio y en ese caso identificar el polinomio de menor grado que podríamos usar.\nRecuerden que al utilizar factores ordenados le estamos indicando a R que optaremos por contrastes polinomiales ortogonales. Otra manera de obtener estos contrastes es con la función poly. Para ver como funciona esto usemos este comando los datos de tiempo. Del vector Time poly produce cuatro columnas nuevas, que dan cuenta de la tendencia lineal, cuadrática, cúbica, etc., con la peculiaridad de que cada columna es ortogonal a las demás.\n\n\nCódigo\nhead(poly(sitka88$Time, 4))\n\n\n                1           2           3            4\n[1,] -0.067556996  0.05935630 -0.04131435  0.018236996\n[2,] -0.038067831 -0.01959476  0.06928561 -0.059101377\n[3,] -0.001876583 -0.05989079  0.01348825  0.079713367\n[4,]  0.032974248 -0.03974302 -0.07127418 -0.048782834\n[5,]  0.074527162  0.05987226  0.02981468  0.009933848\n[6,] -0.067556996  0.05935630 -0.04131435  0.018236996\n\n\nEl Modelo 2 que hemos ajustado consumió todos los grados de libertad posible y estimó un polinomio de grado 4. Consideremos sólo el polinomio cúbico.\n\n\nCódigo\nsitka.lme3.ML &lt;- lme(fixed = size ~ treat + poly(Time, 3) + tratGrad,\n                 random = ~ 1 | tree,\n                 data = sitka88, method =\"ML\")\n\n\n\n\nCódigo\nsummary(sitka.lme3.ML)$tTable\n\n\n                     Value    Std.Error  DF    t-value       p-value\n(Intercept)     4.98512000 0.1222363435 312  40.782634 4.608733e-127\ntreatozone      0.22167749 0.1752587841  77   1.264858  2.097370e-01\npoly(Time, 3)1 10.55436327 0.2867893021 312  36.801803 1.551949e-115\npoly(Time, 3)2 -1.90581863 0.1613315870 312 -11.813053  7.256641e-27\npoly(Time, 3)3 -0.25924189 0.1613315870 312  -1.606889  1.090903e-01\ntratGrad       -0.00213851 0.0004649641 312  -4.599303  6.169978e-06\n\n\nAhora podemos compararlo con el modelo “2” que ajustamos antes, para explorar si el nuevo modelo pierde una grado importante de capacidad explicativa.\n\n\nCódigo\nanova(sitka.lme2.ML, sitka.lme3.ML)\n\n\n              Model df      AIC      BIC    logLik   Test L.Ratio p-value\nsitka.lme2.ML     1  9 25.43446 61.24443 -3.717228                       \nsitka.lme3.ML     2  8 27.31449 59.14557 -5.657243 1 vs 2 3.88003  0.0489\n\n\nEl crecimiento promedio de los árboles a lo largo del tiempo se puede ver así, aunque esto no considera la variación debida a los árboles en lo individual. No obstante veamos el resultado general.\n\n\nCódigo\ntapply(fitted(sitka.lme3.ML), list(sitka88$treat, sitka88$Time), mean)\n\n\n             152      174      201      227      258\ncontrol 4.169687 4.602721 5.075958 5.427362 5.649872\nozone   4.066311 4.452297 4.867795 5.163598 5.319814\n\n\nMás adecuado es utilizar la función predict() para considerar las particularidades del modelo para hacer las predicciones. Estos resultados los pondremos en una gráfica para ver de mejor manera los resultados.\n\n\nCódigo\nsitka88$ajus &lt;- predict(sitka.lme3.ML)\n\n\n\n\nCódigo\nggplot(sitka88, aes(x=Time, y=ajus, color = tree)) + \n       geom_point(show.legend = FALSE) + facet_grid(. ~ treat) +\n       geom_line(show.legend = FALSE) + \n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20))\n\n\n\n\n\n\n\n\n\n\nComponente aleatorio\nPodemos ahora explorar como mejorar la modelación de los componentes aleatorios en este modelo.\n\n\nCódigo\nVarCorr(sitka.lme1)\n\n\ntree = pdLogChol(1) \n            Variance   StdDev   \n(Intercept) 0.37223660 0.6101120\nResidual    0.02593727 0.1610505\n\n\nLos modelos pueden incorporar una estructura de modelación de los patrones de correlación entre las observaciones. En este caso derivadas del hecho de que las mediciones se realizan a lo largo del tiempo, en intervalos relativamente cortos, sobre el mismo sujeto. Haremos esto aquí solo para ejemplificar el tema, que es amplio. Mi recomendación es más bien recurrir a la literatura existente para profundizar en el tema. Nótese que para la comparación de modelos en donde no estamos cambiando los componentes fijo, puede hacerse aún cuando el método de ajuste sea el REML. Usamos una opción del patrón de correlación que estamos asumiendo mediante la opción cor que recibe una estructura que da cuenta del patrón de correlación que se asume afecta a la forma como se producen las observaciones. En este caso optamos por un proceso de autocorrelación de orden 1 en las observaciones con correlación de 70%, derivado de medir a lo largo del tiempo cada árbol. Esto es lo que hace la función corCAR1, sobre la que pueden encontrar más información en la ayuda de R.\n\n\nCódigo\nsitka.lme4 &lt;- lme(size~ treat * ordered(Time), random = ~ 1 | tree,\n                  data = sitka88, corr=corCAR1(0.7, ~ Time | tree))\n\n\nVeamos como cambian los estadísticos de los modelos. Comparemos el modelo completo inicial, contra el completo considerando la nueva información sobre la correlación que hemos agregado en el modelo 4.\n\n\nCódigo\nanova(sitka.lme1,sitka.lme4)\n\n\n           Model df       AIC      BIC    logLik   Test  L.Ratio p-value\nsitka.lme1     1 12  79.90098 127.3399 -27.95049                        \nsitka.lme4     2 13 -63.17167 -11.7795  44.58583 1 vs 2 145.0727  &lt;.0001\n\n\nSe ve raro que haya AIC y BIC negativos, pero pasa, sí los consideraríamos como valores más pequeños que los positivos, así que aquí, el modelo 4 parece tener un ajuste bastante mejor que el 1.\n¿cómo se ve el modelo ajustado finalmente?\n\n\nCódigo\nsummary(sitka.lme4)$tTable\n\n\n                                 Value  Std.Error  DF    t-value       p-value\n(Intercept)                 4.98512000 0.12635223 308 39.4541523 1.827148e-122\ntreatozone                 -0.21115704 0.15282682  77 -1.3816753  1.710673e-01\nordered(Time).L             1.19711183 0.04907128 308 24.3953674  6.282539e-74\nordered(Time).Q            -0.13405824 0.02642497 308 -5.0731653  6.774439e-07\nordered(Time).C            -0.04085663 0.01978964 308 -2.0645467  3.980280e-02\nordered(Time)^4            -0.02729902 0.01672573 308 -1.6321568  1.036684e-01\ntreatozone:ordered(Time).L -0.17856562 0.05935318 308 -3.0085264  2.841806e-03\ntreatozone:ordered(Time).Q -0.02644698 0.03196179 308 -0.8274562  4.086192e-01\ntreatozone:ordered(Time).C -0.01424899 0.02393616 308 -0.5952914  5.520859e-01\ntreatozone:ordered(Time)^4  0.01240293 0.02023028 308  0.6130875  5.402709e-01\n\n\nCódigo\nsummary(sitka.lme1)$tTable\n\n\n                                 Value  Std.Error  DF    t-value       p-value\n(Intercept)                 4.98512000 0.12286970 308 40.5724123 1.332276e-125\ntreatozone                 -0.21115704 0.14861459  77 -1.4208365  1.594013e-01\nordered(Time).L             1.19711183 0.03221011 308 37.1657221 7.430810e-116\nordered(Time).Q            -0.13405824 0.03221011 308 -4.1619932  4.098121e-05\nordered(Time).C            -0.04085663 0.03221011 308 -1.2684413  2.055983e-01\nordered(Time)^4            -0.02729902 0.03221011 308 -0.8475297  3.973580e-01\ntreatozone:ordered(Time).L -0.17856562 0.03895909 308 -4.5834135  6.656627e-06\ntreatozone:ordered(Time).Q -0.02644698 0.03895909 308 -0.6788399  4.977491e-01\ntreatozone:ordered(Time).C -0.01424899 0.03895909 308 -0.3657423  7.148084e-01\ntreatozone:ordered(Time)^4  0.01240293 0.03895909 308  0.3183578  7.504293e-01\n\n\nAunque hay obviamente una importante correlaciónn entre observaciones, el efecto de considerar esto en el modelo es mínimo en términos de los valores de los coeficientes, aunque la significación valorada en términos de p cambia un poco, pero nada que nos haga modificar la apreciación del modelo. No parece valer la pena incorporar este aspecto de autocorrelación en el ajuste final, si nos atenemos a preferir el modelo más simple. Por otro lado, el asunto de considerar un efecto de autocorrelación en las observaciones parece exigir ser considerado. Tomemos este último camino\nLos intervalos de confianza de los coeficientes del modelo 4 son estos:\n\n\nCódigo\nintervals(sitka.lme4, which = \"fixed\", level = 0.95)$fixed\n\n\n                                 lower        est.        upper\n(Intercept)                 4.73649723  4.98512000  5.233742772\ntreatozone                 -0.51547411 -0.21115704  0.093160032\nordered(Time).L             1.10055448  1.19711183  1.293669187\nordered(Time).Q            -0.18605455 -0.13405824 -0.082061932\nordered(Time).C            -0.07979661 -0.04085663 -0.001916640\nordered(Time)^4            -0.06021018 -0.02729902  0.005612139\ntreatozone:ordered(Time).L -0.29535464 -0.17856562 -0.061776597\ntreatozone:ordered(Time).Q -0.08933808 -0.02644698  0.036444111\ntreatozone:ordered(Time).C -0.06134807 -0.01424899  0.032850096\ntreatozone:ordered(Time)^4 -0.02740411  0.01240293  0.052209970\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\n\n\nCódigo\nsitka.fin &lt;- aggregate(list(ajustado=fitted(sitka.lme4)), \n                       list(tiempo=sitka88$Time, trat=sitka88$treat), FUN=mean)\n\n\n\n\nCódigo\nsitka.fin$tiempo &lt;- as.numeric(sitka.fin$tiempo)\n\n\nUna gráfica de los resultados podría ser así. Ilustra la regresión obtenida para cada tratamiento y añado los puntos observados ( para que se vean un poco mejor use el geoma “jitter” que grafica los puntos pero procurando que no se sobrepongan. Le pedí que lo hicieran en “bandas” de ancho 2.\n\n\nCódigo\nggplot(sitka.fin, aes(x=tiempo, y=ajustado, color = trat)) + \n       geom_line(show.legend = TRUE) + \n       geom_point(show.legend = FALSE) + \n       xlab(label = \"tamaño-log\") +\n       ylab(label = \"tiempo (días)\") + \n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20)) +\n\n       # componente que agrega los datos a la gráfica\n       geom_jitter(data = sitka88, width = 2, \n                   mapping = aes(x = Time, y = size, color = treat)) \n\n\n\n\n\n\n\n\n\nConstruir los intervalos de confianza a partir del modelo de efectos mixtos puede ser un poco más elaborado, así que a continuación muestro como pueden hacerse. Una posibilidad es usar la función intervalscon la opción which = “fixed” para recuperar los resultados que implica sólo a los componentes de efectos fijos del modelo, que son los que se involucran en la predicción (los aleatorios participan en las varianzas).\n\n\nCódigo\nlibrary(tidyverse, warn.conflicts = FALSE)\nsitka_intconf &lt;- tibble(Time = sitka88$Time, treat = sitka88$treat)\nsitka_intconf &lt;- sitka_intconf %&gt;% add_column(ajus = fitted(sitka.lme4, level = 0))\nhead(sitka_intconf)\n\n\n# A tibble: 6 × 3\n   Time treat  ajus\n  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;\n1   152 ozone  4.06\n2   174 ozone  4.47\n3   201 ozone  4.85\n4   227 ozone  5.18\n5   258 ozone  5.31\n6   152 ozone  4.06\n\n\nNecesitaremos la matriz de diseño para calcular los intervalos de confianza asociados con el mmodelo.\n\n\nCódigo\nDesignmat &lt;- model.matrix(eval(eval(sitka.lme4$call$fixed)[-2]), \n                          sitka_intconf[-ncol(sitka_intconf)])\n\n\nAhora calculamos los errores estándar de las predicciones. La matriz diseño contiene las variables indicadoras de todos los términos en el modelo. Al multiplicarla por la matriz de varianzas y covarianzas del modelo (la que está en el componente sitka.lme4$varFix del modelo ajustado), produce los estimadores de varianza requeridos\n\n\nCódigo\npredvar &lt;- diag(Designmat %*% sitka.lme4$varFix %*% t(Designmat))\nsitka_intconf$SE &lt;- sqrt(predvar) \n\n\n\n\nCódigo\nhead(sitka_intconf)\n\n\n# A tibble: 6 × 4\n   Time treat  ajus     SE\n  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   152 ozone  4.06 0.0880\n2   174 ozone  4.47 0.0880\n3   201 ozone  4.85 0.0880\n4   227 ozone  5.18 0.0880\n5   258 ozone  5.31 0.0880\n6   152 ozone  4.06 0.0880\n\n\nSolo resta agregar las bandas de confianza en torno a la egresión. Esto lo haré con el geoma “ribbon” de ggplot2. Esta será una gráfica compleja que se elabora a partir de tres tablas de datos.\n\n\nCódigo\nggplot(sitka.fin, aes(x=tiempo, y=ajustado, color = trat)) + \n       geom_line(show.legend = TRUE) + \n\n       # Etiquetas y formato de despliegue\n       xlab(label = \"tamaño-log\") +\n       ylab(label = \"tiempo (días)\") + \n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20)) +\n\n       # bandas de confianza\n       geom_ribbon(data = sitka_intconf, aes(x = Time, y = ajus, color = treat,\n                                             ymin = ajus - 2 * SE,\n                                             ymax = ajus + 2 * SE),\n                   alpha=0.2, fill = \"blue\") +       \n\n       # componente que agrega los datos a la gráfica\n       geom_jitter(data = sitka88, width = 2, \n                   mapping = aes(x = Time, y = size, color = treat))"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#bacon-y-la-ciencia-occidental",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#bacon-y-la-ciencia-occidental",
    "title": "Contraste de epistemologías",
    "section": "Bacon y la ciencia occidental",
    "text": "Bacon y la ciencia occidental\n\nSir Francis Bacon (1561-1626) clave en el origen de la ciencia occidental.\nEn su Novum Organum (Bacon, 1620) plantea substituir el ya entonces viejo método aristotélico (dominante por más de 1800 años), por un nuevo órgano basado en el estudio inductivo de la naturaleza.\nIntentaba:\n\nIniciar una reconstrucción total de las ciencias, las artes prácticas y todo el conocimiento humano, erigida sobre fundamentos apropiados .\n\nPropone el método de experimentación .\nConcibe que la manipulación deliberada de variables debería reemplazar el limitado empirismo prevaleciente que consistía en “observar y nombrar”."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#consecuencias-baconianas",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#consecuencias-baconianas",
    "title": "Contraste de epistemologías",
    "section": "Consecuencias baconianas",
    "text": "Consecuencias baconianas\n\n\nConsecuencias positivas y negativas de La reconstrucción baconiana sobre la concepción de ciencia iniciadas hace 400 años y que prevalecen hasta hoy.\nEl ideal baconiano de ciencia consiste en lo siguiente:\n\nAl principio de su investigación, los experimentadores habrán de eliminar de sus pensamientos “todos los ‘ídolos’ o ilusiones seculares y las falacias nacidas de las idiosincrasias personales, de sus juicios o de las creencias tradicionales y de los dogmas de su grupo”.\nEn la visión baconiana, las observaciones se realizan en una forma puramente objetiva por individuos que no tienen lealtad alguna a ninguna hipótesis o creencia que les pueda causar ceguera hacia alguna porción de la evidencia empírica.\nLas conclusiones correctas y los principios explicativos emergen de las pruebas en una forma relativamente automática y sin que los preconceptos filosóficos del experimentador jueguen papel alguno.\nLa naturaleza misma dictaría sin ambigüedades, por así decirlo, la adopción de teorías verdaderas. El conjunto total de las ciencia, pensaba, sería puramente objetivo, empírico y racional."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#bacon-hoy.",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#bacon-hoy.",
    "title": "Contraste de epistemologías",
    "section": "Bacon hoy….",
    "text": "Bacon hoy….\nAunque esta visión de la ciencia todavía está presente en algunos círculos, es claro que tiene defectos serios.\n\n\nInevitablemente los juicios personales tienen un papel en la ciencia.\nEn gran parte juegan un papel creativo fundamental.\n\nEstán presentes a cada paso de la creación científica\nSe involucran en el complicado proceso inductivo\nNo los podemos excluir de la forma como explicamos los hallazgos\nNo debemos minimizar las jugarretas que nuestra propia psique nos puede jugar.\nExiste, por ejemplo, el llamado efecto de disponibilidad (¡usamos los conceptos que tenemos a la mano!), o la burbuja algorítmica (Krause et al., 2025).\nNo existe un proceso lógico riguroso para concebir teorías\nNo hay reglas fijas para idear nuevos conceptos"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#legalidad-de-la-naturaleza",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#legalidad-de-la-naturaleza",
    "title": "Contraste de epistemologías",
    "section": "“Legalidad” de la naturaleza",
    "text": "“Legalidad” de la naturaleza\n\nEsta noción, que posiblemente sea un corolario de una suposición filosófica más básica, implica la creencia de que los eventos de la naturaleza presentan cierto apego a reglas y es indudablemente un prerrequisito necesario para la ciencia.\nEsta suposición permite que la tarea de catalogar y entender las regularidades de la naturaleza sea concebible."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#corolarios-comprensibilidad-uniformidad-causalidad",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#corolarios-comprensibilidad-uniformidad-causalidad",
    "title": "Contraste de epistemologías",
    "section": "Corolarios: comprensibilidad, uniformidad, causalidad",
    "text": "Corolarios: comprensibilidad, uniformidad, causalidad\n\nLa naturaleza es comprensible . Einstein afirmaba que: la cosa más incomprensible del universo es que sea comprensible.\nLa naturaleza es uniforme . Es decir los procesos y patrones observados sólo en una escala limitada se mantendrán universalmente (esto es obviamente imprescindible en ciencias como la Astronomía).\n\n¿Qué pasa con este supuesto en ciencias como la Ecología, la Psicología o las Ciencias sociales? De paso, hay que notar que este supuesto implica la homogeneidad del material experimental.\n\nLa causalidad existe . El principio de causalidad es la noción que consiste en que “cada evento (o fenómeno) natural se supone tiene una causa, de modo que si tal situación causal puede ser restituida, el evento será duplicado” (Underwood, 1957).\n\n\nVamos al siguiente bloque"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-1",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-1",
    "title": "Contraste de epistemologías",
    "section": "",
    "text": "¿Hasta qué punto el diseño puede ‘rescatar’ la causalidad?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-y-los-empiristas",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-y-los-empiristas",
    "title": "Contraste de epistemologías",
    "section": "Causalidad y los empiristas",
    "text": "Causalidad y los empiristas\n\nLa posición del filósofo empirista escocés David Hume (1711-1776) tuvo un inmenso peso durante mucho tiempo.\nHume sostenía que la inferencia de relaciones de causalidad entre inobservables carece siempre de justificación lógica (Hume, 1748):\n\nLo que observamos no es un evento causando a otro, sino la correlación entre sus desarrollos .\n\nEn consecuencia, la correlación entre eventos es todo lo que podemos conocer acerca de la causalidad."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#interpretaciónes-causales",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#interpretaciónes-causales",
    "title": "Contraste de epistemologías",
    "section": "Interpretaciónes causales",
    "text": "Interpretaciónes causales\n\nPara los filósofos empiristas es indispensable que las causas y los efectos ocurran en “constante conjunción” , es decir que la causa es necesaria y suficiente para el efecto.\nNaturalmente se concebía que la causalidad en ciencia documentaba procesos deterministas.\n¿Sigue siendo esta nuestra convicción o habrá cambiado?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#cómo-debe-interpretarse-esto",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#cómo-debe-interpretarse-esto",
    "title": "Contraste de epistemologías",
    "section": "1. ¿Cómo debe interpretarse esto?",
    "text": "1. ¿Cómo debe interpretarse esto?\n\nParticipa: vevox.app ID: 144-565-419\n\n\n\n\n \n\n\n\n\n\n90% de las semillas en un grupo tratado germinan.\n20% lo hacen en el grupo control.\n\n\n\n\n\nElije la respuesta que consideres más apropiada"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#bisgra-2",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#bisgra-2",
    "title": "Contraste de epistemologías",
    "section": "",
    "text": "¿Puede haber causalidad sin metafísica?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#positivismo",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#positivismo",
    "title": "Contraste de epistemologías",
    "section": "Positivismo",
    "text": "Positivismo\n\nLas ideas de Hume permean en el positivismo del siglo XIX de Auguste Comte(1798-1857), y más tarde en el neopositivismo o positivismo lógico del Círculo de Viene en el siglo XX.\nLa visión positivista empujó al quehacer científico bajo su influencia a tomar una actitud temerosa para proponer relaciones causales como base de la construcción de hipótesis.\nEn lugar de causas, se buscan relaciones funcionales entre observables o entre términos teóricos, cada uno de los cuales es definido operativamente por un instrumento de medición o conjunto de operaciones en un estudio."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-en-crisis",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-en-crisis",
    "title": "Contraste de epistemologías",
    "section": "Causalidad en crisis",
    "text": "Causalidad en crisis\n\n\n\n\nDurante los últimos 50 años han emergido toda una gama de posiciones en relación con lo que se entiende al decir que un evento causa a otro\nTambién se ha cuestionado si realmente podemos adquirir conocimiento acerca de una relación causal.\nCook y Campbell afirmaban hace casi 50 años que “la epistemología de la causalidad y de los métodos científicos más en general, atravesaban por un productivo estado de casi caos” (Campbell & Cook, 1979; Cook & Campbell, 1986).\n¿Habremos superado ya esta compleja encrucijada?\nActualmente se acepta que la causalidad puede tomar una forma probabilística .\nJudea Pearl y Dana Mackenzie publicaron en 2018 The Book of Why: The New Science of Cause and Effect (Pearl & Mackenzie, 2020)."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#qué-tan-de-acuerdo-estás-con-la-siguiente-aseveración",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#qué-tan-de-acuerdo-estás-con-la-siguiente-aseveración",
    "title": "Contraste de epistemologías",
    "section": "2. ¿Qué tan de acuerdo estás con la siguiente aseveración?",
    "text": "2. ¿Qué tan de acuerdo estás con la siguiente aseveración?\n\nParticipa: vevox.app ID: 144-565-419\n\n“La causalidad implica correlación”"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-hoy",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-hoy",
    "title": "Contraste de epistemologías",
    "section": "Causalidad hoy…",
    "text": "Causalidad hoy…\n\nEstas perspectivas de la causalidad actualmente se reconocen limitadas.\nLa causalidad se considera ahora como algo diferente de la mera correlación .\nEsto puede ser confuso en el uso de técnicas estadísticas que lo mismo se aplican para establecer correlación que para hablar de causas.\nLa fuerza con la que podemos apoyar una relación como causal, depende críticamente de la naturaleza del diseño empleado y no del modelo estadístico empleado ."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#gama-de-relaciones-causales",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#gama-de-relaciones-causales",
    "title": "Contraste de epistemologías",
    "section": "Gama de relaciones causales",
    "text": "Gama de relaciones causales\n\nHay toda una gama de posibilidades acerca de los tipos de relaciones de causalidad que pueden ser descubiertas a través de la experimentación.\nEl suponer el principio de causalidad significa adoptar el determinismo como un paradigma de trabajo en el laboratorio y en el campo.\nDebe notarse que en cualquier situación hay toda una variedad de niveles en los que puede conducirse un análisis causal. Tanto la naturaleza como la ciencia están estratificadas .\nPor ejemplo si apago la luz en una habitación ¿cuál es el conjunto de posibles escenarios causales?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-y-realidad-realismo-vs-positivismo",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-y-realidad-realismo-vs-positivismo",
    "title": "Contraste de epistemologías",
    "section": "Causalidad y realidad (realismo vs positivismo)",
    "text": "Causalidad y realidad (realismo vs positivismo)\n\n\nNos queda meditar el significado de las relaciones de causalidad descubiertas.\nPara los realistas (¡en el sentido filosófico!), se trata de un logro en el camino de la búsqueda de la verdad acerca de mecanismos ocultos, pero reales, cuyas propiedades y relaciones explican los fenómenos observables.\n\nUn físico positivista diría solamente que un globo se encoge como una función del tiempo.\nUn físico realista agregaría que la pérdida de moléculas de gas causaron el encogimiento observado.\n\nEs decir, no se trata sólo de una relación causal construida en la mente del físico, se trata de que existe una relación causal real entre las entidades fuera de la mente humana:\n\n“Las aseveraciones teóricas tienen un contenido objetivo que puede ser cierto o falso”."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-finita",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-finita",
    "title": "Contraste de epistemologías",
    "section": "Causalidad finita",
    "text": "Causalidad finita\n\nLa ciencia no sólo presupone que hay causas naturaleza de los eventos , sino también que esas causas son finitas en número y que pueden ser descubiertas.\nLa ciencia se construye sobre la convicción de que la generalización de algún tipo es posible . Es decir, no es necesario reproducir el prácticamente infinito número de elementos que operan cuando un efecto es observado inicialmente, a fin de tener una causa suficiente para volver a producir el efecto.\nSi la ciencia es posible, debemos suponer que el efecto de un factor no depende de todos los posibles niveles de todas las otras variables presentes cuando se efectúa la observación."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-finita-y-desprecio",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#causalidad-finita-y-desprecio",
    "title": "Contraste de epistemologías",
    "section": "Causalidad finita y desprecio…",
    "text": "Causalidad finita y desprecio…\n\nPara Bachelard (2013), uno de los signos distintivos del espíritu científico y del espíritu filosófico es el derecho a despreciar . Para él, el espíritu científico explicita clara y distintamente este derecho a despreciar lo despreciable\nDerecho que incansablemente el espíritu filosófico le rehúsa.\nPara ilustrar esto, recurre a Friedrich Ostwald:\n\n“Cualquiera que sea el fenómeno considerado, siempre hay un número extremadamente grande de circunstancias que no tienen influencia mesurable sobre él”.\n¿Cómo influye el color de un proyectil en sus propiedades balísticas?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#conoces-alguna-metodología-científica-para-describir-y-analizar-estructuras-de-relación-causa-efecto",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#conoces-alguna-metodología-científica-para-describir-y-analizar-estructuras-de-relación-causa-efecto",
    "title": "Contraste de epistemologías",
    "section": "3. ¿Conoces alguna metodología científica para describir y analizar estructuras de relación causa efecto?",
    "text": "3. ¿Conoces alguna metodología científica para describir y analizar estructuras de relación causa efecto?\n\nParticipa: vevox.app ID: 144-565-419"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#vevox-3",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#vevox-3",
    "title": "Contraste de epistemologías",
    "section": "",
    "text": "Vamos al siguiente bloque"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#simplicidad",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#simplicidad",
    "title": "Contraste de epistemologías",
    "section": "Simplicidad…",
    "text": "Simplicidad…\n\nMuchos científicos, particularmente los físicos, enfatizan la importancia de la fuerte creencia en la simplicidad última de las leyes científicas.\nAlbert Einstein escribió alguna vez\n\n“Nuestras experiencias nos justifican al creer que la naturaleza es la realización de las ideas matemáticas más simples concebibles”.\n\nSin embargo, como cualquier ecólogo sabe, hay una enorme complejidad en los sistemas vivientes, lo que puede hacer cuestionable o por lo menos dificultar grandemente el empleo de modelos simples."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#simplicidad-1",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#simplicidad-1",
    "title": "Contraste de epistemologías",
    "section": "…Simplicidad…",
    "text": "…Simplicidad…\n\nUna buena guía a seguir la encontramos en las palabras del científico Alfred North Whitehead (Whitehead, 2020):\n“Busca la simplicidad y desconfía de ella”\nEl mismo autor afirmaba que la ciencia tiene como meta\n“Buscar la explicación más simple de hechos complejos, tratando al mismo tiempo de evitar el error de concluir que la naturaleza es más simple de lo que realmente es”."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-3",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-3",
    "title": "Contraste de epistemologías",
    "section": "",
    "text": "¿Cuándo es que simplificar se vuelve engañoso?\n\n\n\nVamos al siguiente bloque"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-4",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-4",
    "title": "Contraste de epistemologías",
    "section": "",
    "text": "¿La crítica posmoderna debilita o fortalece a la ciencia?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#ciencia-en-problemas",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#ciencia-en-problemas",
    "title": "Contraste de epistemologías",
    "section": "Ciencia en Problemas",
    "text": "Ciencia en Problemas\n\nAl inicio del siglo XXI la profesión científica enfrenta serios problemas en relación con su postura pública y credibilidad.\nCrisis del posmodernismo. En todas las esferas culturales (arte, literatura, diseño)\n\nLa idea de un estilo superior y las ideas de avance y progreso están siendo cuestionadas\nEl pluralismo y la multiplicidad son preferidos.\n\nLa condición posmodernista implica una pérdida de aprecio a la autoridad.\nExiste también una crisis del determinismo (Lyotard, 1984)\n\n\nFuente: Yearley (2005)."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#verdades-posmodernistas",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#verdades-posmodernistas",
    "title": "Contraste de epistemologías",
    "section": "Verdades posmodernistas",
    "text": "Verdades posmodernistas\n\nEl oficio de la ciencia es construir y defender representaciones de la realidad.\nIrónicamente, el mismo éxito y alto perfil social de la ciencia la han abierto a la reconstrucción y al escepticismo.\nLa ciencia es cada vez más y más una necesidad, pero al mismo tiempo, es menos y menos suficiente para la definición socialmente aglutinadora de verdad (Beck, 1992; Mythen, 2004).\n\n\nFuente: Yearley (2005).\n\n\nVamos al siguiente bloque"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#punto-de-partida-histórico",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#punto-de-partida-histórico",
    "title": "Contraste de epistemologías",
    "section": "Punto de partida histórico",
    "text": "Punto de partida histórico\n\n\n\nLógica clásica → certeza\nProbabilidad moderna → incertidumbre\nCiencia como cálculo del comportamiento humano\n\n\nLa probabilidad es sentido común reducido a cálculo"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#el-proyecto-positivista-comte-1798-1857",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#el-proyecto-positivista-comte-1798-1857",
    "title": "Contraste de epistemologías",
    "section": "El proyecto positivista (Comte 1798-1857)",
    "text": "El proyecto positivista (Comte 1798-1857)\n\nLeyes empíricas universales\nCiencia como base del orden social\nSupresión de la metafísica\nSociedad como objeto gobernable\n\nSupuesto comprometedor:\n\nla ciencia puede gobernar a la sociedad"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#ideal-positivista-de-la-racionalidad",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#ideal-positivista-de-la-racionalidad",
    "title": "Contraste de epistemologías",
    "section": "Ideal positivista de la racionalidad",
    "text": "Ideal positivista de la racionalidad\n\n\n\n\n\n\nRacionalidad universal\nFormalización matemática\nPredicción y control\nNeutralidad del observador"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#positivismo-filosófico-y-positivismo-lógico",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#positivismo-filosófico-y-positivismo-lógico",
    "title": "Contraste de epistemologías",
    "section": "Positivismo filosófico y positivismo lógico",
    "text": "Positivismo filosófico y positivismo lógico\nEl positivismo no es un planteamiento monolítico: ha evolucionado y transformado.\n\n\nPositivismo filosófico (Comte, siglo XIX)\n\nCiencia como motor del orden social\n\nLeyes empíricas y progreso histórico\n\nRechazo de la metafísica especulativa\n\n\n\nPositivismo lógico (Círculo de Viena, siglo XX)\n\nCiencia como sistema lógico–lingüístico\n\nVerificación, formalización, análisis del lenguaje\n\nRechazo de la metafísica por falta de significado empírico\n\n\n\n\n\nComparten el anti-metafisicismo\ndivergen en su concepción de la ciencia y la sociedad."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#positivismo-y-prueba-de-hipótesis",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#positivismo-y-prueba-de-hipótesis",
    "title": "Contraste de epistemologías",
    "section": "Positivismo y prueba de hipótesis",
    "text": "Positivismo y prueba de hipótesis\n\n\n\n\n\n\n\n\n\n\n\n\nAspecto\nCírculo de Viena\nPrueba de hipótesis\nRelación\n\n\n\n\nEpistemología\nPositivismo lógico: la ciencia debe basarse en enunciados verificables\nEstadística inferencial: pruebas de hipótesis y diseño experimental\nAmbos buscan criterios rigurosos de validación científica\n\n\nMetodología\nLógica y análisis del lenguaje científico\nMétodos estadísticos para evaluar datos empíricos\nComplementarios: filosofía del método y técnica de análisis\n\n\nImpacto\nFilosofía de la ciencia y epistemología\nBiología, agricultura, psicología y ciencias sociales\nAmbos marcaron la transición hacia una ciencia más formalizada y cuantitativa\n\n\nObjetivo común\nDepurar teorías y eliminar la metafísica\nValidar hipótesis mediante experimentos controlados\nProyecto compartido: hacer de la ciencia una disciplina verificable y precisa\n\n\n\n\n\nImplicaciones a destacar\nLa discusión contemporánea no abandona el positivismo, hereda su método, rechaza su pretensión totalizante, y corrige su versión lógico-formal extrema."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#gödel-y-el-límite-del-positivismo-lógico",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#gödel-y-el-límite-del-positivismo-lógico",
    "title": "Contraste de epistemologías",
    "section": "Gödel y el límite del positivismo lógico",
    "text": "Gödel y el límite del positivismo lógico\nLos teoremas de incompletitud de Gödel muestran que:\n\nNingún sistema formal consistente y suficientemente potente\npuede ser completo\n\nSiempre existen proposiciones verdaderas\nque no pueden demostrarse dentro del sistema\n\nLa consistencia no puede probarse desde el propio sistema\n\n\nG si, y solo si, G no es demostrable\n\n\n\nLa idea de una ciencia fundada en un sistema lógico completo y autosuficiente es inviable incluso en matemáticas."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#de-un-ideal-lógico-a-la-ciencia-real",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#de-un-ideal-lógico-a-la-ciencia-real",
    "title": "Contraste de epistemologías",
    "section": "De un ideal lógico a la ciencia real",
    "text": "De un ideal lógico a la ciencia real\n\n\n\n\nEl sueño positivista\nPositivismo lógico\n\nLenguaje observacional privilegiado\n\nVerificación como criterio central\n\nExplicación = deducción lógica\n\nIdeal de sistema completo y neutro\n\n\nLo que recuperamos\nCiencia contemporánea\n\nMúltiples niveles de lenguaje\n\nModelos e idealizaciones legítimos\n\nExplicaciones causales, probabilísticas y pragmáticas\n\nRigor sin pretensión de completitud\n\n\n\n\nNo abandonar el rigor al renunciar a la idea de un lenguaje perfecto\nAmpliar la capacidad para describir cómo la ciencia realmente explica y decide.\n\n\n\nDistinguir niveles de lenguaje y explicación significa reconocer que describir datos, construir modelos y reflexionar sobre sus límites son actividades distintas, todas científicamente legítimas.”\nNiveles de lenguaje\nSe refiere a que no todo lo que decimos en ciencia está en el mismo plano lingüístico.\nAl menos tres niveles relevantes:\n\nLenguaje observacional\n\nDescribe datos y mediciones\nEjemplo: “La temperatura aumentó 1.5 °C”\n\nLenguaje teórico / modelístico\n\nIntroduce entidades, relaciones, supuestos\nEjemplo: “El forzamiento radiativo aumenta la probabilidad de olas de calor”\n\nMeta-lenguaje\n\nHabla sobre los modelos, datos y teorías\nEjemplo: “Este modelo asume estacionariedad y tiene alta incertidumbre estructural”\n\n\nNiveles de explicación\nNo todas las explicaciones científicas responden al mismo tipo de “por qué”.\nEjemplos de niveles legítimos:\n\nCausal: qué factores influyen en qué\nMecanístico: cómo se produce un efecto\nEstadístico / probabilístico: con qué frecuencia o tendencia\nFuncional / pragmático: para qué sirve una regla o modelo"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#racionalidad-limitada",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#racionalidad-limitada",
    "title": "Contraste de epistemologías",
    "section": "Racionalidad limitada",
    "text": "Racionalidad limitada\n\n\n\n\n\nInformación incompleta\nTiempo y capacidades finitas\nDecisiones satisfactorias\nUso sistemático de heurísticas\n\n\n\n\n\nLa racionalidad se vuelve empírica"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#heurísticas-y-sesgos",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#heurísticas-y-sesgos",
    "title": "Contraste de epistemologías",
    "section": "Heurísticas y sesgos",
    "text": "Heurísticas y sesgos\n\n\n\n\nReglas simples de decisión\nFuncionan rápido\nProducen errores sistemáticos\nNo son anomalías individuales (Gigerenzer & Gray, 2017)"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#fallamos-al-razonar",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#fallamos-al-razonar",
    "title": "Contraste de epistemologías",
    "section": "¿Fallamos al razonar?",
    "text": "¿Fallamos al razonar?\n\n\n\nDos interpretaciones:\n\nSesgos → desviaciones del modelo normativo\nHeurísticas → adaptaciones a entornos reales\n\n\n\n\n\n\n\nEl error se vuelve estructural"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#límite-del-positivismo-clásico",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#límite-del-positivismo-clásico",
    "title": "Contraste de epistemologías",
    "section": "Límite del positivismo clásico",
    "text": "Límite del positivismo clásico\nEl modelo normativo:\n\nDescribe mal cómo decidimos\nIgnora valores y poder\nNo resuelve conflictos sociales\n\nPregunta clave:\n\n¿Quién define qué es racional?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#la-reacción-al-positivismo",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#la-reacción-al-positivismo",
    "title": "Contraste de epistemologías",
    "section": "La reacción al positivismo",
    "text": "La reacción al positivismo\n\n\n\n\nRechaza los enfoques cuantitativos.\nConcibe métodos de investigación cualitativos.\nLos hallazgos se contextualizan históricamente.\nLa regularidad no es tan importante.\nLa generalización puede no ser posible."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#enfoques-no-positivistas",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#enfoques-no-positivistas",
    "title": "Contraste de epistemologías",
    "section": "Enfoques no positivistas",
    "text": "Enfoques no positivistas\n\n\nTres críticas convergentes:\n\nEl sentido del asunto concreto importa\nLa experiencia importa\nEl poder importa\n\n\n\nLa racionalidad no es solo cálculo"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#hermenéutica",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#hermenéutica",
    "title": "Contraste de epistemologías",
    "section": "Hermenéutica",
    "text": "Hermenéutica\n\n\n\n\nComprensión como proceso iterativo\nLenguaje, historia, tradición\nDecisión como interpretación"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#cognición-encarnada---fenomenología",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#cognición-encarnada---fenomenología",
    "title": "Contraste de epistemologías",
    "section": "Cognición encarnada - Fenomenología",
    "text": "Cognición encarnada - Fenomenología\n\n\nLa experiencia humana es lo central .\n\nCuerpo y mente inseparables\nPercepción–acción unificadas\nConocimiento como experiencia"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#cognición-situada",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#cognición-situada",
    "title": "Contraste de epistemologías",
    "section": "Cognición situada",
    "text": "Cognición situada\n\n\n\n\nSaber inseparable de la acción\nContexto, cultura y ambiente\nCognición como actividad integrada"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#teoría-crítica",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#teoría-crítica",
    "title": "Contraste de epistemologías",
    "section": "Teoría crítica",
    "text": "Teoría crítica\n\nRacionalidad instrumental\nOrientada a eficiencia y control\nModelos como tecnologías de poder\n\n\n\n\nPensamiento sistémico"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#contraste-de-enfoques",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#contraste-de-enfoques",
    "title": "Contraste de epistemologías",
    "section": "Contraste de enfoques",
    "text": "Contraste de enfoques\n\nLa teoría crítica no rechaza la estadística per se.\ncuestiona y problematiza cómo, para qué y bajo qué supuestos se usa.\nLa ve como una herramienta ambivalente: puede emancipar o reproducir dominación, según el marco epistemológico y político que la sostenga."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#estadística-como-tecnología-de-poder",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#estadística-como-tecnología-de-poder",
    "title": "Contraste de epistemologías",
    "section": "Estadística como tecnología de poder",
    "text": "Estadística como tecnología de poder\nInspirada en Michel Foucault, la teoría crítica subraya que la estadística:\n\nEs parte de dispositivos de gubernamentalidad (censos, indicadores, rankings).\nProduce poblaciones legibles para la administración, el control y la intervención.\nDefine “normalidades” (promedios, desviaciones) que disciplinan conductas.\n\n\n\nEl problema aquí no es calcular, sino qué formas de vida se vuelven gobernables a través del número."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#reapropiación-crítica-de-la-estadística",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#reapropiación-crítica-de-la-estadística",
    "title": "Contraste de epistemologías",
    "section": "Reapropiación crítica de la estadística",
    "text": "Reapropiación crítica de la estadística\nLejos de descartarla, muchas corrientes críticas la reapropian\n\nVisibilización de desigualdades (clase, género, raza, territorio).\nDenuncia empírica de injusticias estructurales (salud, ambiente, trabajo).\nContra-indicadores que cuestionan métricas oficiales (p. ej., bienestar más allá del PIB).\n\n\n\nEn esta línea dialogan enfoques como la economía política crítica (Karl Marx), el feminismo cuantitativo (Fraser, 2008) y la crítica de la racionalidad instrumental (Habermas, 1984)."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#tensiones-clave",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#tensiones-clave",
    "title": "Contraste de epistemologías",
    "section": "Tensiones clave",
    "text": "Tensiones clave\n\n\n\n\nDescripción vs. explicación: correlación no sustituye causalidad social.\nPromedios vs. experiencias: lo típico puede ocultar lo injusto.\nIndicadores vs. sentidos: medir no equivale a comprender.\nExperticia vs. democracia: ¿quién decide qué cuenta?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#la-teoría-crítica-propone-una-estadística-reflexiva",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#la-teoría-crítica-propone-una-estadística-reflexiva",
    "title": "Contraste de epistemologías",
    "section": "La teoría crítica propone una estadística reflexiva",
    "text": "La teoría crítica propone una estadística reflexiva\n\nHcer conciencia de sus supuestos y efectos.\nArticularla con teoría social y análisis histórico.\nAbrirla a métodos mixtos y a la deliberación pública."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#síntesis-epistemológica",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#síntesis-epistemológica",
    "title": "Contraste de epistemologías",
    "section": "Síntesis epistemológica",
    "text": "Síntesis epistemológica\n\n\n\n\n\n\nEnfoque\nRacionalidad\nHeurísticas\n\n\n\n\nPositivismo\nMecanismo\nReglas\n\n\nHermenéutica\nComprensión\nPrácticas\n\n\nFenomenología\nExperiencia\nAcción\n\n\nConstructivismo\nProducto social\nRutinas\n\n\nTeoría crítica\nInstrumento\nNormalización\n\n\n\n\nVamos al siguiente bloque"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#fracasó-el-positivismo",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#fracasó-el-positivismo",
    "title": "Contraste de epistemologías",
    "section": "¿Fracasó el positivismo?",
    "text": "¿Fracasó el positivismo?\n\nRespuesta corta:\n\n💀 Como proyecto totalizante\n🗽 Como infraestructura científica"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#la-paradoja",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#la-paradoja",
    "title": "Contraste de epistemologías",
    "section": "La paradoja",
    "text": "La paradoja\n\n\n\nEl positivismo fracasa\nporque tiene demasiado éxito\n\n\n\n\n\n\nAl medir y modelar:\n\nrevela incertidumbre\nexpone límites cognitivos\nmuestra complejidad social"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#emergencia-de-modelos-híbridos",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#emergencia-de-modelos-híbridos",
    "title": "Contraste de epistemologías",
    "section": "Emergencia de modelos híbridos",
    "text": "Emergencia de modelos híbridos\nAparecen cuando:\n\nla incertidumbre es alta\nlos valores están en disputa\nlas decisiones son urgentes\nel riesgo es colectivo\n\n\n\n\nLa ciencia sola no basta\nLa sociedad sola tampoco"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#qué-es-un-modelo-híbrido",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#qué-es-un-modelo-híbrido",
    "title": "Contraste de epistemologías",
    "section": "¿Qué es un modelo híbrido?",
    "text": "¿Qué es un modelo híbrido?\n\n\n\n\n\nLa ciencia informa\nla sociedad delibera\nla decisión emerge de su interacción\n\n\n\n\n\n\nNo es:\n\ndivulgación\nrelativismo\ntecnocracia"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#lógicas-que-se-articulan",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#lógicas-que-se-articulan",
    "title": "Contraste de epistemologías",
    "section": "Lógicas que se articulan",
    "text": "Lógicas que se articulan\n\n\n\n\n\nCiencia\nSociedad\n\n\n\n\nEvidencia\nValores\n\n\nProbabilidad\nExperiencia\n\n\nModelos\nLegitimidad\n\n\nPredicción\nSentido"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#heurísticas-colectivas-diseñadas",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#heurísticas-colectivas-diseñadas",
    "title": "Contraste de epistemologías",
    "section": "Heurísticas colectivas diseñadas",
    "text": "Heurísticas colectivas diseñadas\nEjemplos:\n\numbrales ecológicos\nsemáforos de riesgo\nprincipio de precaución\nescenarios plausibles\n\n\n\nRacionalidad limitada institucionalizada"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-5",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-5",
    "title": "Contraste de epistemologías",
    "section": "",
    "text": "¿Sesgos o adaptaciones?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#desafíos-de-la-ciencia-en-crisis",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#desafíos-de-la-ciencia-en-crisis",
    "title": "Contraste de epistemologías",
    "section": "desafíos de la ciencia en crisis",
    "text": "desafíos de la ciencia en crisis\nLa racionalidad limitada no se corrige, se organiza colectivamente.\n\nnadie entiende todo\n\nnadie controla todo\n\nnadie decide solo\n\n\n\n\n\nHeurísticas explícitas en lugar de una optimización perfecta"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-6",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#bisagra-6",
    "title": "Contraste de epistemologías",
    "section": "",
    "text": "¿Quién debe decidir bajo incertidumbre?"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#oferta-de-la-ciencia-abierta",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#oferta-de-la-ciencia-abierta",
    "title": "Contraste de epistemologías",
    "section": "Oferta de la Ciencia Abierta",
    "text": "Oferta de la Ciencia Abierta\n\nEvidencia como bien común\n\nDatos con supuestos visibles\n\nIncertidumbre explícita\n\nHeurísticas colectivas compartidas \nAprendizaje adaptativo\n\n\n\n\n\nInfraestructura práctica para modelos híbridos ciencia–sociedad"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#qué-cambia-respecto-al-positivismo-de-comte",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#qué-cambia-respecto-al-positivismo-de-comte",
    "title": "Contraste de epistemologías",
    "section": "¿Qué cambia respecto al positivismo de Comte?",
    "text": "¿Qué cambia respecto al positivismo de Comte?\n\n\n\nLa ciencia ya no gobierna sola\nLa racionalidad no es universal\nLa incertidumbre no se elimina\nLos valores se hacen explícitos\n\n\n\n\n\nPero la ciencia sigue siendo indispensable"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#implicación-final",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#implicación-final",
    "title": "Contraste de epistemologías",
    "section": "Implicación final",
    "text": "Implicación final\n\n\n\nUsamos herramientas positivistas\npara decidir en un mundo no positivista"
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#para-una-reflexión-con-calma",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#para-una-reflexión-con-calma",
    "title": "Contraste de epistemologías",
    "section": "Para una reflexión con calma",
    "text": "Para una reflexión con calma\n\n\n\n\n\nGobernar procesos bajo incertidumbre\nno se resuelve sólo con aplicar modelos.\n\nSe requiere articular evidencia, valores y las reglas prácticas (tradiciones) de la cultura involucrada."
  },
  {
    "objectID": "presentaciones/2026-01-28-epistemologia/index.html#referencias",
    "href": "presentaciones/2026-01-28-epistemologia/index.html#referencias",
    "title": "Contraste de epistemologías",
    "section": "Referencias",
    "text": "Referencias\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n\n\n \n\n\n\n\nBachelard, G. (2013). La formación del espíritu científico (2a. ed., 12a. reimp). Siglo XXI.\n\n\nBacon, F. (1620). Novum Organum (1620.ª ed.). Lectorum.\n\n\nBeck, U. (1992). Modem Society as a Risk Society (pp. 199-214). DE GRUYTER. https://doi.org/10.1515/9783110847765.199\n\n\nCampbell, D. T., & Cook, T. D. (1979). Quasi-experimentation. Chicago, IL: Rand Mc-Nally, 1(1), 1384. https://toc.library.ethz.ch/objects/pdf_uzh50/5/978-0-395-30790-8_006226431.pdf\n\n\nCook, T. D., & Campbell, D. T. (1986). The Causal Assumptions of Quasi-Experimental Practice: The Origins of Quasi-Experimental Practice. Synthese, 68(1), 141-180. https://www.jstor.org/stable/20116298\n\n\nFraser, N. (2008). Scales of Justice: Reimagining Political Space in a Globalizing World. Polity Press.\n\n\nGigerenzer, G., & Gray, W. D. (2017). A Simple Heuristic Successfully Used by Humans, Animals, and Machines: The Story of the RAF and Luftwaffe, Hawks and Ducks, Dogs and Frisbees, Baseball Outfielders and Sidewinder MissilesOh My! Topics in Cognitive Science, 9(2), 260-263. https://doi.org/10.1111/tops.12269\n\n\nHabermas, J. (1984). The Theory of Communicative Action, Volume 1: Reason and the Rationalization of Society (T. McCarthy, Trad.). Beacon Press.\n\n\nHume, D. (1748). Philosophical Essays Concerning Human Understanding. A. Millar.\n\n\nKrause, N. M., Freiling, I., & Scheufele, D. A. (2025). Our changing information ecosystem for science and why it matters for effective science communication. Proceedings of the National Academy of Sciences, 122(27), e2400928121. https://doi.org/10.1073/pnas.2400928121\n\n\nLyotard, J.-F. (1984). The Postmodern Condition: A Report on Knowledge. University of Minnesota Press.\n\n\nMythen, G. (2004). Ulrich Beck: A Critical Introduction to the Risk Society (1.ª ed.). Pluto Press. https://doi.org/10.2307/j.ctt18fs3c4\n\n\nPearl, J., & Mackenzie, D. (2020). El libro del porqué. Pasado y Presente. https://www.marcialpons.es/media/pdf/ellibrodelporquejudeapearl.pdf\n\n\nUnderwood, B. J. (1957). Interference and forgetting. Psychological Review, 64(1), 49-60. https://doi.org/10.1037/h0044616\n\n\nWhitehead, A. N. (2020). Process and Reality (pp. 1-3). J.B. Metzler. https://doi.org/10.1007/978-3-476-05728-0_20342-1\n\n\nYearley, S. (2005). Making Sense of Science: Understanding the Social Study of Science. https://doi.org/10.4135/9781446222218"
  }
]